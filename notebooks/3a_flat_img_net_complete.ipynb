{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flat Image Net - Basic Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from utils.data import init_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting /data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting /data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting /data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('/data/fashion/', one_hot=True)\n",
    "class_id2class_name_mapping = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic summary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summaries(name, var):\n",
    "    with tf.name_scope(name):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n",
    "\n",
    "\n",
    "def img_summaries(name, var):\n",
    "    with tf.name_scope(name):\n",
    "        tf.summary.image(name, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_layer(name, input_data, shape, activation='linear'):\n",
    "    w_name = 'w_' + name\n",
    "    b_name = 'b_' + name\n",
    "    if activation == 'relu':\n",
    "        w = tf.get_variable(w_name, shape=shape, initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "    else:\n",
    "        w = tf.get_variable(w_name, shape=shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    bias = tf.get_variable(b_name, initializer=tf.constant_initializer(0.1), shape=shape[1])\n",
    "    \n",
    "    variable_summaries(w_name+'summary', w)\n",
    "    variable_summaries(b_name+'summary', bias)\n",
    "    \n",
    "    output_data = tf.matmul(input_data, w) + bias\n",
    "    if activation == 'relu':\n",
    "        output_data = tf.nn.relu(output_data)\n",
    "    elif activation == 'sigmoid':\n",
    "        output_data = tf.nn.sigmoid(output_data)\n",
    "    elif activation == 'tanh':\n",
    "        output_data = tf.nn.tanh(output_data)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Net Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('flat_image_net_inputs'):\n",
    "        images = tf.placeholder(tf.float32, shape=[None, 784], name='images')\n",
    "        labels = tf.placeholder(tf.float32, shape=[None, 10], name='labels')\n",
    "        keep_dropout_prob = tf.placeholder(tf.float32, name='keep_dropout_prob')\n",
    "\n",
    "    \n",
    "    with tf.variable_scope('simple_layer_1'):\n",
    "        raw_prediction = simple_layer(name='layer1', input_data=images, shape=[784, 64], activation='relu')\n",
    "        \n",
    "    with tf.variable_scope('simple_layer_2'):\n",
    "        raw_prediction = simple_layer(name='layer2', input_data=raw_prediction, shape=[64, 10])\n",
    "        raw_prediction = tf.nn.dropout(raw_prediction, keep_dropout_prob)\n",
    "            \n",
    "    with tf.name_scope('prediction'):\n",
    "        prediction = tf.nn.softmax(raw_prediction)\n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy_vector = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=prediction)\n",
    "        loss = tf.reduce_mean(cross_entropy_vector)\n",
    "        variable_summaries('loss_summary', cross_entropy_vector)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction)\n",
    "        variable_summaries('accuracy_summary', correct_prediction)       \n",
    "        \n",
    "    with tf.name_scope('training'):\n",
    "        train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "            \n",
    "    initialize_vars = tf.global_variables_initializer()\n",
    "    merge_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Model Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_path': '/tensorboard_summaries/flat_image_net/experiment_final/valid/model.ckpt',\n",
       " 'saver': <tensorflow.python.training.saver.Saver at 0x7f647a244e48>,\n",
       " 'train_writer': <tensorflow.python.summary.writer.writer.FileWriter at 0x7f647d5c4c88>,\n",
       " 'train_writer_dir': '/tensorboard_summaries/flat_image_net/experiment_final/train',\n",
       " 'valid_writer': <tensorflow.python.summary.writer.writer.FileWriter at 0x7f647a244e10>,\n",
       " 'valid_writer_dir': '/tensorboard_summaries/flat_image_net/experiment_final/valid'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.data import init_model_logging\n",
    "base_dir = '/tensorboard_summaries/flat_image_net/'\n",
    "\n",
    "logging_meta = init_model_logging(base_dir, 'experiment_final', graph=graph, remove_existing=True)\n",
    "logging_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Iteration 0: loss 2.2709972858428955, accuracy 0.25\n",
      "= Valid Iteration 0: loss 2.284444570541382, accuracy 0.19280000030994415 =\n",
      "Train Iteration 10: loss 2.155974864959717, accuracy 0.4699999988079071\n",
      "Train Iteration 20: loss 2.0102171897888184, accuracy 0.5799999833106995\n",
      "Train Iteration 30: loss 1.9878098964691162, accuracy 0.6200000047683716\n",
      "Train Iteration 40: loss 1.9136526584625244, accuracy 0.6499999761581421\n",
      "Train Iteration 50: loss 1.928338646888733, accuracy 0.6800000071525574\n",
      "Train Iteration 60: loss 1.8527419567108154, accuracy 0.7599999904632568\n",
      "Train Iteration 70: loss 1.8700753450393677, accuracy 0.6700000166893005\n",
      "Train Iteration 80: loss 1.868169903755188, accuracy 0.6899999976158142\n",
      "Train Iteration 90: loss 1.7584320306777954, accuracy 0.8100000023841858\n",
      "Train Iteration 100: loss 1.7553436756134033, accuracy 0.8100000023841858\n",
      "= Valid Iteration 100: loss 1.7972677946090698, accuracy 0.7483999729156494 =\n",
      "Train Iteration 110: loss 1.8584342002868652, accuracy 0.699999988079071\n",
      "Train Iteration 120: loss 1.767337679862976, accuracy 0.7799999713897705\n",
      "Train Iteration 130: loss 1.7899190187454224, accuracy 0.7599999904632568\n",
      "Train Iteration 140: loss 1.767183780670166, accuracy 0.7599999904632568\n",
      "Train Iteration 150: loss 1.8049514293670654, accuracy 0.7300000190734863\n",
      "Train Iteration 160: loss 1.7658382654190063, accuracy 0.7900000214576721\n",
      "Train Iteration 170: loss 1.7506557703018188, accuracy 0.7599999904632568\n",
      "Train Iteration 180: loss 1.7801566123962402, accuracy 0.7400000095367432\n",
      "Train Iteration 190: loss 1.801993727684021, accuracy 0.7200000286102295\n",
      "Train Iteration 200: loss 1.6911636590957642, accuracy 0.8500000238418579\n",
      "= Valid Iteration 200: loss 1.7307254076004028, accuracy 0.7915999889373779 =\n",
      "Train Iteration 210: loss 1.7158883810043335, accuracy 0.8500000238418579\n",
      "Train Iteration 220: loss 1.7536895275115967, accuracy 0.7599999904632568\n",
      "Train Iteration 230: loss 1.7689694166183472, accuracy 0.7300000190734863\n",
      "Train Iteration 240: loss 1.691804051399231, accuracy 0.8399999737739563\n",
      "Train Iteration 250: loss 1.731019139289856, accuracy 0.7699999809265137\n",
      "Train Iteration 260: loss 1.746488332748413, accuracy 0.7400000095367432\n",
      "Train Iteration 270: loss 1.7124967575073242, accuracy 0.7900000214576721\n",
      "Train Iteration 280: loss 1.7007936239242554, accuracy 0.7900000214576721\n",
      "Train Iteration 290: loss 1.7665542364120483, accuracy 0.7099999785423279\n",
      "Train Iteration 300: loss 1.7238364219665527, accuracy 0.7900000214576721\n",
      "= Valid Iteration 300: loss 1.703528881072998, accuracy 0.8113999962806702 =\n",
      "Train Iteration 310: loss 1.6699072122573853, accuracy 0.8600000143051147\n",
      "Train Iteration 320: loss 1.7028799057006836, accuracy 0.800000011920929\n",
      "Train Iteration 330: loss 1.6904592514038086, accuracy 0.8399999737739563\n",
      "Train Iteration 340: loss 1.7415133714675903, accuracy 0.800000011920929\n",
      "Train Iteration 350: loss 1.6355549097061157, accuracy 0.8799999952316284\n",
      "Train Iteration 360: loss 1.7154974937438965, accuracy 0.7900000214576721\n",
      "Train Iteration 370: loss 1.6902003288269043, accuracy 0.8100000023841858\n",
      "Train Iteration 380: loss 1.7664518356323242, accuracy 0.7200000286102295\n",
      "Train Iteration 390: loss 1.6427830457687378, accuracy 0.8700000047683716\n",
      "Train Iteration 400: loss 1.7250747680664062, accuracy 0.7699999809265137\n",
      "= Valid Iteration 400: loss 1.6844066381454468, accuracy 0.8181999921798706 =\n",
      "Train Iteration 410: loss 1.6742914915084839, accuracy 0.8399999737739563\n",
      "Train Iteration 420: loss 1.6886667013168335, accuracy 0.7900000214576721\n",
      "Train Iteration 430: loss 1.686466097831726, accuracy 0.7900000214576721\n",
      "Train Iteration 440: loss 1.6574853658676147, accuracy 0.8600000143051147\n",
      "Train Iteration 450: loss 1.6831473112106323, accuracy 0.8500000238418579\n",
      "Train Iteration 460: loss 1.6832035779953003, accuracy 0.7900000214576721\n",
      "Train Iteration 470: loss 1.736159324645996, accuracy 0.7599999904632568\n",
      "Train Iteration 480: loss 1.6510566473007202, accuracy 0.8500000238418579\n",
      "Train Iteration 490: loss 1.6375839710235596, accuracy 0.8700000047683716\n",
      "Train Iteration 500: loss 1.6314058303833008, accuracy 0.8700000047683716\n",
      "= Valid Iteration 500: loss 1.6817779541015625, accuracy 0.8109999895095825 =\n",
      "Train Iteration 510: loss 1.6800957918167114, accuracy 0.8199999928474426\n",
      "Train Iteration 520: loss 1.7281771898269653, accuracy 0.8100000023841858\n",
      "Train Iteration 530: loss 1.6548664569854736, accuracy 0.8600000143051147\n",
      "Train Iteration 540: loss 1.674794316291809, accuracy 0.8199999928474426\n",
      "Train Iteration 550: loss 1.6229314804077148, accuracy 0.8799999952316284\n",
      "Train Iteration 560: loss 1.6876301765441895, accuracy 0.8199999928474426\n",
      "Train Iteration 570: loss 1.6622686386108398, accuracy 0.8199999928474426\n",
      "Train Iteration 580: loss 1.6307308673858643, accuracy 0.8799999952316284\n",
      "Train Iteration 590: loss 1.6667627096176147, accuracy 0.8199999928474426\n",
      "Train Iteration 600: loss 1.6725640296936035, accuracy 0.8100000023841858\n",
      "= Valid Iteration 600: loss 1.6604324579238892, accuracy 0.8324000239372253 =\n",
      "Train Iteration 610: loss 1.6924444437026978, accuracy 0.7900000214576721\n",
      "Train Iteration 620: loss 1.656270146369934, accuracy 0.8100000023841858\n",
      "Train Iteration 630: loss 1.7152148485183716, accuracy 0.7699999809265137\n",
      "Train Iteration 640: loss 1.6219640970230103, accuracy 0.9100000262260437\n",
      "Train Iteration 650: loss 1.6163318157196045, accuracy 0.8700000047683716\n",
      "Train Iteration 660: loss 1.6505393981933594, accuracy 0.8299999833106995\n",
      "Train Iteration 670: loss 1.6816494464874268, accuracy 0.800000011920929\n",
      "Train Iteration 680: loss 1.7101263999938965, accuracy 0.7699999809265137\n",
      "Train Iteration 690: loss 1.6672157049179077, accuracy 0.8199999928474426\n",
      "Train Iteration 700: loss 1.6989904642105103, accuracy 0.7699999809265137\n",
      "= Valid Iteration 700: loss 1.6611707210540771, accuracy 0.8240000009536743 =\n",
      "Train Iteration 710: loss 1.6070563793182373, accuracy 0.8799999952316284\n",
      "Train Iteration 720: loss 1.6108078956604004, accuracy 0.8799999952316284\n",
      "Train Iteration 730: loss 1.6611982583999634, accuracy 0.8299999833106995\n",
      "Train Iteration 740: loss 1.6614550352096558, accuracy 0.8199999928474426\n",
      "Train Iteration 750: loss 1.6512771844863892, accuracy 0.8600000143051147\n",
      "Train Iteration 760: loss 1.6311053037643433, accuracy 0.8399999737739563\n",
      "Train Iteration 770: loss 1.6432539224624634, accuracy 0.8500000238418579\n",
      "Train Iteration 780: loss 1.686866044998169, accuracy 0.7799999713897705\n",
      "Train Iteration 790: loss 1.6949266195297241, accuracy 0.800000011920929\n",
      "Train Iteration 800: loss 1.6940927505493164, accuracy 0.7699999809265137\n",
      "= Valid Iteration 800: loss 1.6583884954452515, accuracy 0.8256000280380249 =\n",
      "Train Iteration 810: loss 1.6576586961746216, accuracy 0.8199999928474426\n",
      "Train Iteration 820: loss 1.682993769645691, accuracy 0.800000011920929\n",
      "Train Iteration 830: loss 1.6572692394256592, accuracy 0.8299999833106995\n",
      "Train Iteration 840: loss 1.6641895771026611, accuracy 0.8199999928474426\n",
      "Train Iteration 850: loss 1.726657748222351, accuracy 0.7400000095367432\n",
      "Train Iteration 860: loss 1.6178091764450073, accuracy 0.8799999952316284\n",
      "Train Iteration 870: loss 1.7138866186141968, accuracy 0.7599999904632568\n",
      "Train Iteration 880: loss 1.6504707336425781, accuracy 0.8199999928474426\n",
      "Train Iteration 890: loss 1.640762448310852, accuracy 0.8299999833106995\n",
      "Train Iteration 900: loss 1.5968573093414307, accuracy 0.8700000047683716\n",
      "= Valid Iteration 900: loss 1.6419183015823364, accuracy 0.8420000076293945 =\n",
      "Train Iteration 910: loss 1.5905276536941528, accuracy 0.8899999856948853\n",
      "Train Iteration 920: loss 1.7012099027633667, accuracy 0.7699999809265137\n",
      "Train Iteration 930: loss 1.6540530920028687, accuracy 0.8299999833106995\n",
      "Train Iteration 940: loss 1.6517313718795776, accuracy 0.8299999833106995\n",
      "Train Iteration 950: loss 1.6898565292358398, accuracy 0.7799999713897705\n",
      "Train Iteration 960: loss 1.6539753675460815, accuracy 0.8399999737739563\n",
      "Train Iteration 970: loss 1.6599539518356323, accuracy 0.8199999928474426\n",
      "Train Iteration 980: loss 1.6304374933242798, accuracy 0.8600000143051147\n",
      "Train Iteration 990: loss 1.6328424215316772, accuracy 0.8299999833106995\n",
      "Train Iteration 1000: loss 1.6068764925003052, accuracy 0.8700000047683716\n",
      "= Valid Iteration 1000: loss 1.6418509483337402, accuracy 0.8396000266075134 =\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Iteration 1010: loss 1.625801682472229, accuracy 0.8700000047683716\n",
      "Train Iteration 1020: loss 1.6776559352874756, accuracy 0.7900000214576721\n",
      "Train Iteration 1030: loss 1.6533770561218262, accuracy 0.8199999928474426\n",
      "Train Iteration 1040: loss 1.6938087940216064, accuracy 0.7900000214576721\n",
      "Train Iteration 1050: loss 1.6208652257919312, accuracy 0.8999999761581421\n",
      "Train Iteration 1060: loss 1.6786025762557983, accuracy 0.8100000023841858\n",
      "Train Iteration 1070: loss 1.6056900024414062, accuracy 0.8799999952316284\n",
      "Train Iteration 1080: loss 1.63197660446167, accuracy 0.8500000238418579\n",
      "Train Iteration 1090: loss 1.6645147800445557, accuracy 0.800000011920929\n",
      "Train Iteration 1100: loss 1.6651898622512817, accuracy 0.7900000214576721\n",
      "= Valid Iteration 1100: loss 1.6421338319778442, accuracy 0.8345999717712402 =\n",
      "Train Iteration 1110: loss 1.6392730474472046, accuracy 0.8600000143051147\n",
      "Train Iteration 1120: loss 1.6655279397964478, accuracy 0.8100000023841858\n",
      "Train Iteration 1130: loss 1.645323634147644, accuracy 0.8199999928474426\n",
      "Train Iteration 1140: loss 1.6893938779830933, accuracy 0.7699999809265137\n",
      "Train Iteration 1150: loss 1.6964586973190308, accuracy 0.7699999809265137\n",
      "Train Iteration 1160: loss 1.6157824993133545, accuracy 0.8500000238418579\n",
      "Train Iteration 1170: loss 1.6558520793914795, accuracy 0.8199999928474426\n",
      "Train Iteration 1180: loss 1.6756713390350342, accuracy 0.800000011920929\n",
      "Train Iteration 1190: loss 1.6687005758285522, accuracy 0.7900000214576721\n",
      "Train Iteration 1200: loss 1.6628893613815308, accuracy 0.8100000023841858\n",
      "= Valid Iteration 1200: loss 1.649977684020996, accuracy 0.8253999948501587 =\n",
      "Train Iteration 1210: loss 1.6229057312011719, accuracy 0.8600000143051147\n",
      "Train Iteration 1220: loss 1.620603322982788, accuracy 0.8700000047683716\n",
      "Train Iteration 1230: loss 1.7058899402618408, accuracy 0.7599999904632568\n",
      "Train Iteration 1240: loss 1.686158299446106, accuracy 0.800000011920929\n",
      "Train Iteration 1250: loss 1.6521815061569214, accuracy 0.8299999833106995\n",
      "Train Iteration 1260: loss 1.6289716958999634, accuracy 0.8799999952316284\n",
      "Train Iteration 1270: loss 1.6233912706375122, accuracy 0.8500000238418579\n",
      "Train Iteration 1280: loss 1.6524651050567627, accuracy 0.8100000023841858\n",
      "Train Iteration 1290: loss 1.6330630779266357, accuracy 0.8399999737739563\n",
      "Train Iteration 1300: loss 1.650296926498413, accuracy 0.8299999833106995\n",
      "= Valid Iteration 1300: loss 1.629138708114624, accuracy 0.8483999967575073 =\n",
      "Train Iteration 1310: loss 1.658962607383728, accuracy 0.8199999928474426\n",
      "Train Iteration 1320: loss 1.6919198036193848, accuracy 0.7699999809265137\n",
      "Train Iteration 1330: loss 1.6483497619628906, accuracy 0.8299999833106995\n",
      "Train Iteration 1340: loss 1.6314692497253418, accuracy 0.8500000238418579\n",
      "Train Iteration 1350: loss 1.5976226329803467, accuracy 0.8899999856948853\n",
      "Train Iteration 1360: loss 1.6892094612121582, accuracy 0.7799999713897705\n",
      "Train Iteration 1370: loss 1.6274582147598267, accuracy 0.8600000143051147\n",
      "Train Iteration 1380: loss 1.6562005281448364, accuracy 0.7900000214576721\n",
      "Train Iteration 1390: loss 1.663015604019165, accuracy 0.8100000023841858\n",
      "Train Iteration 1400: loss 1.6025768518447876, accuracy 0.8899999856948853\n",
      "= Valid Iteration 1400: loss 1.6311372518539429, accuracy 0.8464000225067139 =\n",
      "Train Iteration 1410: loss 1.6139813661575317, accuracy 0.8700000047683716\n",
      "Train Iteration 1420: loss 1.6113439798355103, accuracy 0.8799999952316284\n",
      "Train Iteration 1430: loss 1.6054328680038452, accuracy 0.8799999952316284\n",
      "Train Iteration 1440: loss 1.6097826957702637, accuracy 0.8700000047683716\n",
      "Train Iteration 1450: loss 1.6310806274414062, accuracy 0.8399999737739563\n",
      "Train Iteration 1460: loss 1.7005391120910645, accuracy 0.7799999713897705\n",
      "Train Iteration 1470: loss 1.6107412576675415, accuracy 0.8600000143051147\n",
      "Train Iteration 1480: loss 1.600030779838562, accuracy 0.8899999856948853\n",
      "Train Iteration 1490: loss 1.669377088546753, accuracy 0.800000011920929\n",
      "Train Iteration 1500: loss 1.6235971450805664, accuracy 0.8399999737739563\n",
      "= Valid Iteration 1500: loss 1.6232199668884277, accuracy 0.8529999852180481 =\n",
      "Train Iteration 1510: loss 1.5886081457138062, accuracy 0.8899999856948853\n",
      "Train Iteration 1520: loss 1.6311360597610474, accuracy 0.8500000238418579\n",
      "Train Iteration 1530: loss 1.6467803716659546, accuracy 0.8199999928474426\n",
      "Train Iteration 1540: loss 1.664034366607666, accuracy 0.8299999833106995\n",
      "Train Iteration 1550: loss 1.6309938430786133, accuracy 0.8500000238418579\n",
      "Train Iteration 1560: loss 1.6301156282424927, accuracy 0.8299999833106995\n",
      "Train Iteration 1570: loss 1.6579580307006836, accuracy 0.8100000023841858\n",
      "Train Iteration 1580: loss 1.5875622034072876, accuracy 0.8899999856948853\n",
      "Train Iteration 1590: loss 1.6449986696243286, accuracy 0.8199999928474426\n",
      "Train Iteration 1600: loss 1.6699405908584595, accuracy 0.800000011920929\n",
      "= Valid Iteration 1600: loss 1.6196209192276, accuracy 0.8578000068664551 =\n",
      "Train Iteration 1610: loss 1.6251236200332642, accuracy 0.8600000143051147\n",
      "Train Iteration 1620: loss 1.5861308574676514, accuracy 0.8899999856948853\n",
      "Train Iteration 1630: loss 1.572515845298767, accuracy 0.8999999761581421\n",
      "Train Iteration 1640: loss 1.5972141027450562, accuracy 0.8999999761581421\n",
      "Train Iteration 1650: loss 1.628196120262146, accuracy 0.8600000143051147\n",
      "Train Iteration 1660: loss 1.663541555404663, accuracy 0.8100000023841858\n",
      "Train Iteration 1670: loss 1.6487627029418945, accuracy 0.8299999833106995\n",
      "Train Iteration 1680: loss 1.5619964599609375, accuracy 0.9300000071525574\n",
      "Train Iteration 1690: loss 1.6390224695205688, accuracy 0.8399999737739563\n",
      "Train Iteration 1700: loss 1.6065243482589722, accuracy 0.8700000047683716\n",
      "= Valid Iteration 1700: loss 1.6299970149993896, accuracy 0.8414000272750854 =\n",
      "Train Iteration 1710: loss 1.6428152322769165, accuracy 0.8299999833106995\n",
      "Train Iteration 1720: loss 1.6691659688949585, accuracy 0.8299999833106995\n",
      "Train Iteration 1730: loss 1.668850064277649, accuracy 0.7900000214576721\n",
      "Train Iteration 1740: loss 1.6516547203063965, accuracy 0.8299999833106995\n",
      "Train Iteration 1750: loss 1.615514874458313, accuracy 0.8600000143051147\n",
      "Train Iteration 1760: loss 1.6068038940429688, accuracy 0.8799999952316284\n",
      "Train Iteration 1770: loss 1.6691884994506836, accuracy 0.8100000023841858\n",
      "Train Iteration 1780: loss 1.6817032098770142, accuracy 0.7900000214576721\n",
      "Train Iteration 1790: loss 1.6254843473434448, accuracy 0.8600000143051147\n",
      "Train Iteration 1800: loss 1.6445468664169312, accuracy 0.8199999928474426\n",
      "= Valid Iteration 1800: loss 1.6296405792236328, accuracy 0.8410000205039978 =\n",
      "Train Iteration 1810: loss 1.5750715732574463, accuracy 0.9100000262260437\n",
      "Train Iteration 1820: loss 1.6146849393844604, accuracy 0.8700000047683716\n",
      "Train Iteration 1830: loss 1.5904959440231323, accuracy 0.8799999952316284\n",
      "Train Iteration 1840: loss 1.6301974058151245, accuracy 0.8500000238418579\n",
      "Train Iteration 1850: loss 1.6298450231552124, accuracy 0.8199999928474426\n",
      "Train Iteration 1860: loss 1.6513168811798096, accuracy 0.8299999833106995\n",
      "Train Iteration 1870: loss 1.5960898399353027, accuracy 0.8799999952316284\n",
      "Train Iteration 1880: loss 1.646081805229187, accuracy 0.8199999928474426\n",
      "Train Iteration 1890: loss 1.6272512674331665, accuracy 0.8600000143051147\n",
      "Train Iteration 1900: loss 1.6550122499465942, accuracy 0.8100000023841858\n",
      "= Valid Iteration 1900: loss 1.615456461906433, accuracy 0.859000027179718 =\n",
      "Train Iteration 1910: loss 1.6313445568084717, accuracy 0.8299999833106995\n",
      "Train Iteration 1920: loss 1.6269536018371582, accuracy 0.8500000238418579\n",
      "Train Iteration 1930: loss 1.6161890029907227, accuracy 0.8600000143051147\n",
      "Train Iteration 1940: loss 1.6378488540649414, accuracy 0.8500000238418579\n",
      "Train Iteration 1950: loss 1.6529885530471802, accuracy 0.8100000023841858\n",
      "Train Iteration 1960: loss 1.6037466526031494, accuracy 0.8799999952316284\n",
      "Train Iteration 1970: loss 1.596428394317627, accuracy 0.9100000262260437\n",
      "Train Iteration 1980: loss 1.6318200826644897, accuracy 0.8500000238418579\n",
      "Train Iteration 1990: loss 1.68505859375, accuracy 0.800000011920929\n",
      "Train Iteration 2000: loss 1.6031512022018433, accuracy 0.8899999856948853\n",
      "= Valid Iteration 2000: loss 1.6256359815597534, accuracy 0.8474000096321106 =\n",
      "Train Iteration 2010: loss 1.6410375833511353, accuracy 0.8500000238418579\n",
      "Train Iteration 2020: loss 1.5773413181304932, accuracy 0.8999999761581421\n",
      "Train Iteration 2030: loss 1.6921133995056152, accuracy 0.7699999809265137\n",
      "Train Iteration 2040: loss 1.6307578086853027, accuracy 0.8299999833106995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Iteration 2050: loss 1.6668922901153564, accuracy 0.7799999713897705\n",
      "Train Iteration 2060: loss 1.6077446937561035, accuracy 0.8600000143051147\n",
      "Train Iteration 2070: loss 1.5894012451171875, accuracy 0.8799999952316284\n",
      "Train Iteration 2080: loss 1.5864545106887817, accuracy 0.8999999761581421\n",
      "Train Iteration 2090: loss 1.6169078350067139, accuracy 0.8600000143051147\n",
      "Train Iteration 2100: loss 1.6190426349639893, accuracy 0.8500000238418579\n",
      "= Valid Iteration 2100: loss 1.6202490329742432, accuracy 0.8515999913215637 =\n",
      "Train Iteration 2110: loss 1.551416039466858, accuracy 0.9399999976158142\n",
      "Train Iteration 2120: loss 1.6384567022323608, accuracy 0.8399999737739563\n",
      "Train Iteration 2130: loss 1.6799495220184326, accuracy 0.7900000214576721\n",
      "Train Iteration 2140: loss 1.5872163772583008, accuracy 0.8799999952316284\n",
      "Train Iteration 2150: loss 1.6238675117492676, accuracy 0.8399999737739563\n",
      "Train Iteration 2160: loss 1.6375668048858643, accuracy 0.8299999833106995\n",
      "Train Iteration 2170: loss 1.658241868019104, accuracy 0.8199999928474426\n",
      "Train Iteration 2180: loss 1.5908820629119873, accuracy 0.8899999856948853\n",
      "Train Iteration 2190: loss 1.6981453895568848, accuracy 0.7699999809265137\n",
      "Train Iteration 2200: loss 1.6291019916534424, accuracy 0.8500000238418579\n",
      "= Valid Iteration 2200: loss 1.619936227798462, accuracy 0.8518000245094299 =\n",
      "Train Iteration 2210: loss 1.5995895862579346, accuracy 0.8899999856948853\n",
      "Train Iteration 2220: loss 1.6334549188613892, accuracy 0.8500000238418579\n",
      "Train Iteration 2230: loss 1.6464036703109741, accuracy 0.8199999928474426\n",
      "Train Iteration 2240: loss 1.5818475484848022, accuracy 0.8999999761581421\n",
      "Train Iteration 2250: loss 1.597837209701538, accuracy 0.8899999856948853\n",
      "Train Iteration 2260: loss 1.626163125038147, accuracy 0.8500000238418579\n",
      "Train Iteration 2270: loss 1.6368517875671387, accuracy 0.8299999833106995\n",
      "Train Iteration 2280: loss 1.6192677021026611, accuracy 0.8399999737739563\n",
      "Train Iteration 2290: loss 1.5983648300170898, accuracy 0.8700000047683716\n",
      "Train Iteration 2300: loss 1.6341619491577148, accuracy 0.8399999737739563\n",
      "= Valid Iteration 2300: loss 1.6234482526779175, accuracy 0.8492000102996826 =\n",
      "Train Iteration 2310: loss 1.6091362237930298, accuracy 0.8700000047683716\n",
      "Train Iteration 2320: loss 1.6265857219696045, accuracy 0.8500000238418579\n",
      "Train Iteration 2330: loss 1.6548799276351929, accuracy 0.800000011920929\n",
      "Train Iteration 2340: loss 1.6393458843231201, accuracy 0.8199999928474426\n",
      "Train Iteration 2350: loss 1.6159495115280151, accuracy 0.8700000047683716\n",
      "Train Iteration 2360: loss 1.6290020942687988, accuracy 0.8399999737739563\n",
      "Train Iteration 2370: loss 1.6483889818191528, accuracy 0.8299999833106995\n",
      "Train Iteration 2380: loss 1.6327449083328247, accuracy 0.8299999833106995\n",
      "Train Iteration 2390: loss 1.6348023414611816, accuracy 0.8299999833106995\n",
      "Train Iteration 2400: loss 1.609093427658081, accuracy 0.8799999952316284\n",
      "= Valid Iteration 2400: loss 1.6198309659957886, accuracy 0.8492000102996826 =\n",
      "Train Iteration 2410: loss 1.6237869262695312, accuracy 0.8399999737739563\n",
      "Train Iteration 2420: loss 1.6234707832336426, accuracy 0.8500000238418579\n",
      "Train Iteration 2430: loss 1.6260894536972046, accuracy 0.8500000238418579\n",
      "Train Iteration 2440: loss 1.6327235698699951, accuracy 0.8500000238418579\n",
      "Train Iteration 2450: loss 1.6420515775680542, accuracy 0.8299999833106995\n",
      "Train Iteration 2460: loss 1.6210293769836426, accuracy 0.8399999737739563\n",
      "Train Iteration 2470: loss 1.5649256706237793, accuracy 0.9200000166893005\n",
      "Train Iteration 2480: loss 1.6864733695983887, accuracy 0.7699999809265137\n",
      "Train Iteration 2490: loss 1.7249151468276978, accuracy 0.7300000190734863\n",
      "Train Iteration 2500: loss 1.587746262550354, accuracy 0.8899999856948853\n",
      "= Valid Iteration 2500: loss 1.6166472434997559, accuracy 0.8569999933242798 =\n",
      "Train Iteration 2510: loss 1.6044026613235474, accuracy 0.8700000047683716\n",
      "Train Iteration 2520: loss 1.6330344676971436, accuracy 0.8399999737739563\n",
      "Train Iteration 2530: loss 1.575319528579712, accuracy 0.8899999856948853\n",
      "Train Iteration 2540: loss 1.6126593351364136, accuracy 0.8700000047683716\n",
      "Train Iteration 2550: loss 1.641471266746521, accuracy 0.8399999737739563\n",
      "Train Iteration 2560: loss 1.5994045734405518, accuracy 0.8799999952316284\n",
      "Train Iteration 2570: loss 1.6200652122497559, accuracy 0.8500000238418579\n",
      "Train Iteration 2580: loss 1.6208281517028809, accuracy 0.8399999737739563\n",
      "Train Iteration 2590: loss 1.613301396369934, accuracy 0.8600000143051147\n",
      "Train Iteration 2600: loss 1.6327053308486938, accuracy 0.8399999737739563\n",
      "= Valid Iteration 2600: loss 1.6081246137619019, accuracy 0.8626000285148621 =\n",
      "Train Iteration 2610: loss 1.6068273782730103, accuracy 0.8600000143051147\n",
      "Train Iteration 2620: loss 1.6328262090682983, accuracy 0.8199999928474426\n",
      "Train Iteration 2630: loss 1.6601353883743286, accuracy 0.8100000023841858\n",
      "Train Iteration 2640: loss 1.5908371210098267, accuracy 0.8899999856948853\n",
      "Train Iteration 2650: loss 1.6020081043243408, accuracy 0.8799999952316284\n",
      "Train Iteration 2660: loss 1.604506254196167, accuracy 0.8399999737739563\n",
      "Train Iteration 2670: loss 1.6099308729171753, accuracy 0.8700000047683716\n",
      "Train Iteration 2680: loss 1.6166889667510986, accuracy 0.8600000143051147\n",
      "Train Iteration 2690: loss 1.6165878772735596, accuracy 0.8500000238418579\n",
      "Train Iteration 2700: loss 1.6489019393920898, accuracy 0.800000011920929\n",
      "= Valid Iteration 2700: loss 1.6133142709732056, accuracy 0.8539999723434448 =\n",
      "Train Iteration 2710: loss 1.5612231492996216, accuracy 0.9100000262260437\n",
      "Train Iteration 2720: loss 1.6513328552246094, accuracy 0.8299999833106995\n",
      "Train Iteration 2730: loss 1.623274803161621, accuracy 0.8500000238418579\n",
      "Train Iteration 2740: loss 1.6479978561401367, accuracy 0.8199999928474426\n",
      "Train Iteration 2750: loss 1.5762877464294434, accuracy 0.8899999856948853\n",
      "Train Iteration 2760: loss 1.622944951057434, accuracy 0.8600000143051147\n",
      "Train Iteration 2770: loss 1.5897237062454224, accuracy 0.8899999856948853\n",
      "Train Iteration 2780: loss 1.6218769550323486, accuracy 0.8500000238418579\n",
      "Train Iteration 2790: loss 1.631454586982727, accuracy 0.8500000238418579\n",
      "Train Iteration 2800: loss 1.647562861442566, accuracy 0.8100000023841858\n",
      "= Valid Iteration 2800: loss 1.6131292581558228, accuracy 0.8592000007629395 =\n",
      "Train Iteration 2810: loss 1.6068321466445923, accuracy 0.8500000238418579\n",
      "Train Iteration 2820: loss 1.6000093221664429, accuracy 0.8700000047683716\n",
      "Train Iteration 2830: loss 1.626511812210083, accuracy 0.8299999833106995\n",
      "Train Iteration 2840: loss 1.624204158782959, accuracy 0.8500000238418579\n",
      "Train Iteration 2850: loss 1.6046667098999023, accuracy 0.8799999952316284\n",
      "Train Iteration 2860: loss 1.616463303565979, accuracy 0.8500000238418579\n",
      "Train Iteration 2870: loss 1.5823708772659302, accuracy 0.8899999856948853\n",
      "Train Iteration 2880: loss 1.5830025672912598, accuracy 0.8799999952316284\n",
      "Train Iteration 2890: loss 1.6387814283370972, accuracy 0.8399999737739563\n",
      "Train Iteration 2900: loss 1.6037689447402954, accuracy 0.8500000238418579\n",
      "= Valid Iteration 2900: loss 1.618817687034607, accuracy 0.8500000238418579 =\n",
      "Train Iteration 2910: loss 1.6132729053497314, accuracy 0.8500000238418579\n",
      "Train Iteration 2920: loss 1.5665005445480347, accuracy 0.9100000262260437\n",
      "Train Iteration 2930: loss 1.5860180854797363, accuracy 0.8899999856948853\n",
      "Train Iteration 2940: loss 1.5951757431030273, accuracy 0.8700000047683716\n",
      "Train Iteration 2950: loss 1.575835108757019, accuracy 0.8899999856948853\n",
      "Train Iteration 2960: loss 1.5553016662597656, accuracy 0.9200000166893005\n",
      "Train Iteration 2970: loss 1.639248013496399, accuracy 0.8100000023841858\n",
      "Train Iteration 2980: loss 1.5757783651351929, accuracy 0.8899999856948853\n",
      "Train Iteration 2990: loss 1.6511421203613281, accuracy 0.8199999928474426\n",
      "Train Iteration 3000: loss 1.571006178855896, accuracy 0.8999999761581421\n",
      "= Valid Iteration 3000: loss 1.6025972366333008, accuracy 0.8668000102043152 =\n",
      "Train Iteration 3010: loss 1.5308822393417358, accuracy 0.949999988079071\n",
      "Train Iteration 3020: loss 1.612154483795166, accuracy 0.8500000238418579\n",
      "Train Iteration 3030: loss 1.5929958820343018, accuracy 0.8899999856948853\n",
      "Train Iteration 3040: loss 1.584519386291504, accuracy 0.8999999761581421\n",
      "Train Iteration 3050: loss 1.5783671140670776, accuracy 0.8999999761581421\n",
      "Train Iteration 3060: loss 1.6117310523986816, accuracy 0.8500000238418579\n",
      "Train Iteration 3070: loss 1.6194064617156982, accuracy 0.8299999833106995\n",
      "Train Iteration 3080: loss 1.6548174619674683, accuracy 0.8100000023841858\n",
      "Train Iteration 3090: loss 1.5930240154266357, accuracy 0.8899999856948853\n",
      "Train Iteration 3100: loss 1.6253247261047363, accuracy 0.8399999737739563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Valid Iteration 3100: loss 1.607574462890625, accuracy 0.8664000034332275 =\n",
      "Train Iteration 3110: loss 1.6125413179397583, accuracy 0.8500000238418579\n",
      "Train Iteration 3120: loss 1.6512138843536377, accuracy 0.800000011920929\n",
      "Train Iteration 3130: loss 1.6150741577148438, accuracy 0.8299999833106995\n",
      "Train Iteration 3140: loss 1.6136364936828613, accuracy 0.8700000047683716\n",
      "Train Iteration 3150: loss 1.5905641317367554, accuracy 0.8899999856948853\n",
      "Train Iteration 3160: loss 1.6124299764633179, accuracy 0.8500000238418579\n",
      "Train Iteration 3170: loss 1.5980294942855835, accuracy 0.8899999856948853\n",
      "Train Iteration 3180: loss 1.5968362092971802, accuracy 0.8799999952316284\n",
      "Train Iteration 3190: loss 1.6006295680999756, accuracy 0.8799999952316284\n",
      "Train Iteration 3200: loss 1.628790020942688, accuracy 0.8500000238418579\n",
      "= Valid Iteration 3200: loss 1.6059350967407227, accuracy 0.8611999750137329 =\n",
      "Train Iteration 3210: loss 1.6302132606506348, accuracy 0.8600000143051147\n",
      "Train Iteration 3220: loss 1.6348971128463745, accuracy 0.8399999737739563\n",
      "Train Iteration 3230: loss 1.607632040977478, accuracy 0.8700000047683716\n",
      "Train Iteration 3240: loss 1.5704376697540283, accuracy 0.9100000262260437\n",
      "Train Iteration 3250: loss 1.5815765857696533, accuracy 0.8899999856948853\n",
      "Train Iteration 3260: loss 1.618177890777588, accuracy 0.8500000238418579\n",
      "Train Iteration 3270: loss 1.5590826272964478, accuracy 0.9100000262260437\n",
      "Train Iteration 3280: loss 1.6607288122177124, accuracy 0.8299999833106995\n",
      "Train Iteration 3290: loss 1.5986040830612183, accuracy 0.8799999952316284\n",
      "Train Iteration 3300: loss 1.5757502317428589, accuracy 0.8799999952316284\n",
      "= Valid Iteration 3300: loss 1.6098657846450806, accuracy 0.8592000007629395 =\n",
      "Train Iteration 3310: loss 1.6430457830429077, accuracy 0.8199999928474426\n",
      "Train Iteration 3320: loss 1.5722897052764893, accuracy 0.8899999856948853\n",
      "Train Iteration 3330: loss 1.6233731508255005, accuracy 0.8500000238418579\n",
      "Train Iteration 3340: loss 1.6109298467636108, accuracy 0.8600000143051147\n",
      "Train Iteration 3350: loss 1.633609414100647, accuracy 0.8399999737739563\n",
      "Train Iteration 3360: loss 1.6295876502990723, accuracy 0.8399999737739563\n",
      "Train Iteration 3370: loss 1.5755807161331177, accuracy 0.8999999761581421\n",
      "Train Iteration 3380: loss 1.6215541362762451, accuracy 0.8500000238418579\n",
      "Train Iteration 3390: loss 1.6522010564804077, accuracy 0.8100000023841858\n",
      "Train Iteration 3400: loss 1.5921478271484375, accuracy 0.8799999952316284\n",
      "= Valid Iteration 3400: loss 1.6028187274932861, accuracy 0.8641999959945679 =\n",
      "Train Iteration 3410: loss 1.6169284582138062, accuracy 0.8399999737739563\n",
      "Train Iteration 3420: loss 1.5680220127105713, accuracy 0.8999999761581421\n",
      "Train Iteration 3430: loss 1.5837386846542358, accuracy 0.8999999761581421\n",
      "Train Iteration 3440: loss 1.5847113132476807, accuracy 0.8899999856948853\n",
      "Train Iteration 3450: loss 1.6144431829452515, accuracy 0.8500000238418579\n",
      "Train Iteration 3460: loss 1.6505755186080933, accuracy 0.8199999928474426\n",
      "Train Iteration 3470: loss 1.598404884338379, accuracy 0.8600000143051147\n",
      "Train Iteration 3480: loss 1.5520336627960205, accuracy 0.9200000166893005\n",
      "Train Iteration 3490: loss 1.5543725490570068, accuracy 0.9200000166893005\n",
      "Train Iteration 3500: loss 1.6151074171066284, accuracy 0.8600000143051147\n",
      "= Valid Iteration 3500: loss 1.6080951690673828, accuracy 0.8622000217437744 =\n",
      "Train Iteration 3510: loss 1.6370811462402344, accuracy 0.8299999833106995\n",
      "Train Iteration 3520: loss 1.573116660118103, accuracy 0.8899999856948853\n",
      "Train Iteration 3530: loss 1.5597991943359375, accuracy 0.9300000071525574\n",
      "Train Iteration 3540: loss 1.601674199104309, accuracy 0.8999999761581421\n",
      "Train Iteration 3550: loss 1.7438230514526367, accuracy 0.7200000286102295\n",
      "Train Iteration 3560: loss 1.6068997383117676, accuracy 0.8399999737739563\n",
      "Train Iteration 3570: loss 1.5927002429962158, accuracy 0.8799999952316284\n",
      "Train Iteration 3580: loss 1.5940451622009277, accuracy 0.8799999952316284\n",
      "Train Iteration 3590: loss 1.6067886352539062, accuracy 0.8600000143051147\n",
      "Train Iteration 3600: loss 1.5467300415039062, accuracy 0.9100000262260437\n",
      "= Valid Iteration 3600: loss 1.6074416637420654, accuracy 0.8601999878883362 =\n",
      "Train Iteration 3610: loss 1.6239351034164429, accuracy 0.8600000143051147\n",
      "Train Iteration 3620: loss 1.6380319595336914, accuracy 0.8199999928474426\n",
      "Train Iteration 3630: loss 1.5929417610168457, accuracy 0.8899999856948853\n",
      "Train Iteration 3640: loss 1.6482795476913452, accuracy 0.8199999928474426\n",
      "Train Iteration 3650: loss 1.6507997512817383, accuracy 0.8100000023841858\n",
      "Train Iteration 3660: loss 1.652490496635437, accuracy 0.8199999928474426\n",
      "Train Iteration 3670: loss 1.632443904876709, accuracy 0.8600000143051147\n",
      "Train Iteration 3680: loss 1.5709974765777588, accuracy 0.8999999761581421\n",
      "Train Iteration 3690: loss 1.5683032274246216, accuracy 0.8999999761581421\n",
      "Train Iteration 3700: loss 1.5918548107147217, accuracy 0.8700000047683716\n",
      "= Valid Iteration 3700: loss 1.6121975183486938, accuracy 0.8564000129699707 =\n",
      "Train Iteration 3710: loss 1.6217451095581055, accuracy 0.8500000238418579\n",
      "Train Iteration 3720: loss 1.5502734184265137, accuracy 0.9399999976158142\n",
      "Train Iteration 3730: loss 1.6174311637878418, accuracy 0.8600000143051147\n",
      "Train Iteration 3740: loss 1.55976140499115, accuracy 0.8999999761581421\n",
      "Train Iteration 3750: loss 1.548824667930603, accuracy 0.9100000262260437\n",
      "Train Iteration 3760: loss 1.5922536849975586, accuracy 0.8799999952316284\n",
      "Train Iteration 3770: loss 1.5943951606750488, accuracy 0.8700000047683716\n",
      "Train Iteration 3780: loss 1.6311612129211426, accuracy 0.8299999833106995\n",
      "Train Iteration 3790: loss 1.590628981590271, accuracy 0.8899999856948853\n",
      "Train Iteration 3800: loss 1.6494923830032349, accuracy 0.8199999928474426\n",
      "= Valid Iteration 3800: loss 1.6184169054031372, accuracy 0.8492000102996826 =\n",
      "Train Iteration 3810: loss 1.574079990386963, accuracy 0.8899999856948853\n",
      "Train Iteration 3820: loss 1.5870181322097778, accuracy 0.8799999952316284\n",
      "Train Iteration 3830: loss 1.5984513759613037, accuracy 0.8600000143051147\n",
      "Train Iteration 3840: loss 1.6164218187332153, accuracy 0.8399999737739563\n",
      "Train Iteration 3850: loss 1.642665982246399, accuracy 0.8299999833106995\n",
      "Train Iteration 3860: loss 1.6165406703948975, accuracy 0.8399999737739563\n",
      "Train Iteration 3870: loss 1.5590524673461914, accuracy 0.9200000166893005\n",
      "Train Iteration 3880: loss 1.612614393234253, accuracy 0.8399999737739563\n",
      "Train Iteration 3890: loss 1.605684757232666, accuracy 0.8700000047683716\n",
      "Train Iteration 3900: loss 1.5754541158676147, accuracy 0.8700000047683716\n",
      "= Valid Iteration 3900: loss 1.6090179681777954, accuracy 0.8574000000953674 =\n",
      "Train Iteration 3910: loss 1.5930179357528687, accuracy 0.8700000047683716\n",
      "Train Iteration 3920: loss 1.6430237293243408, accuracy 0.800000011920929\n",
      "Train Iteration 3930: loss 1.5509743690490723, accuracy 0.9200000166893005\n",
      "Train Iteration 3940: loss 1.6006511449813843, accuracy 0.8600000143051147\n",
      "Train Iteration 3950: loss 1.6453351974487305, accuracy 0.8299999833106995\n",
      "Train Iteration 3960: loss 1.6210932731628418, accuracy 0.8399999737739563\n",
      "Train Iteration 3970: loss 1.5789850950241089, accuracy 0.8899999856948853\n",
      "Train Iteration 3980: loss 1.6063531637191772, accuracy 0.8600000143051147\n",
      "Train Iteration 3990: loss 1.6152762174606323, accuracy 0.8600000143051147\n",
      "Train Iteration 4000: loss 1.631239414215088, accuracy 0.8500000238418579\n",
      "= Valid Iteration 4000: loss 1.6025054454803467, accuracy 0.8650000095367432 =\n",
      "Train Iteration 4010: loss 1.5736796855926514, accuracy 0.8999999761581421\n",
      "Train Iteration 4020: loss 1.5827569961547852, accuracy 0.8799999952316284\n",
      "Train Iteration 4030: loss 1.6235650777816772, accuracy 0.8600000143051147\n",
      "Train Iteration 4040: loss 1.595994234085083, accuracy 0.8799999952316284\n",
      "Train Iteration 4050: loss 1.5890785455703735, accuracy 0.8899999856948853\n",
      "Train Iteration 4060: loss 1.5831278562545776, accuracy 0.8899999856948853\n",
      "Train Iteration 4070: loss 1.6037455797195435, accuracy 0.8500000238418579\n",
      "Train Iteration 4080: loss 1.593983769416809, accuracy 0.8799999952316284\n",
      "Train Iteration 4090: loss 1.6107735633850098, accuracy 0.8700000047683716\n",
      "Train Iteration 4100: loss 1.5951874256134033, accuracy 0.8899999856948853\n",
      "= Valid Iteration 4100: loss 1.6194336414337158, accuracy 0.847000002861023 =\n",
      "Train Iteration 4110: loss 1.6086238622665405, accuracy 0.8500000238418579\n",
      "Train Iteration 4120: loss 1.6420634984970093, accuracy 0.8199999928474426\n",
      "Train Iteration 4130: loss 1.5872176885604858, accuracy 0.8700000047683716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Iteration 4140: loss 1.623616337776184, accuracy 0.8500000238418579\n",
      "Train Iteration 4150: loss 1.6162246465682983, accuracy 0.8700000047683716\n",
      "Train Iteration 4160: loss 1.6064748764038086, accuracy 0.8500000238418579\n",
      "Train Iteration 4170: loss 1.6207950115203857, accuracy 0.8399999737739563\n",
      "Train Iteration 4180: loss 1.619407057762146, accuracy 0.8600000143051147\n",
      "Train Iteration 4190: loss 1.6020264625549316, accuracy 0.8600000143051147\n",
      "Train Iteration 4200: loss 1.5719330310821533, accuracy 0.8999999761581421\n",
      "= Valid Iteration 4200: loss 1.6000298261642456, accuracy 0.8646000027656555 =\n",
      "Train Iteration 4210: loss 1.6273232698440552, accuracy 0.8500000238418579\n",
      "Train Iteration 4220: loss 1.57769775390625, accuracy 0.8899999856948853\n",
      "Train Iteration 4230: loss 1.6209845542907715, accuracy 0.8399999737739563\n",
      "Train Iteration 4240: loss 1.608399510383606, accuracy 0.8500000238418579\n",
      "Train Iteration 4250: loss 1.6461328268051147, accuracy 0.8299999833106995\n",
      "Train Iteration 4260: loss 1.5804632902145386, accuracy 0.8899999856948853\n",
      "Train Iteration 4270: loss 1.5705381631851196, accuracy 0.8999999761581421\n",
      "Train Iteration 4280: loss 1.6029486656188965, accuracy 0.8600000143051147\n",
      "Train Iteration 4290: loss 1.5978378057479858, accuracy 0.8700000047683716\n",
      "Train Iteration 4300: loss 1.670801043510437, accuracy 0.7900000214576721\n",
      "= Valid Iteration 4300: loss 1.607910394668579, accuracy 0.8604000210762024 =\n",
      "Train Iteration 4310: loss 1.6108291149139404, accuracy 0.8299999833106995\n",
      "Train Iteration 4320: loss 1.6727294921875, accuracy 0.800000011920929\n",
      "Train Iteration 4330: loss 1.6326414346694946, accuracy 0.8399999737739563\n",
      "Train Iteration 4340: loss 1.605690360069275, accuracy 0.8600000143051147\n",
      "Train Iteration 4350: loss 1.6098158359527588, accuracy 0.8700000047683716\n",
      "Train Iteration 4360: loss 1.5615997314453125, accuracy 0.9100000262260437\n",
      "Train Iteration 4370: loss 1.5825011730194092, accuracy 0.8799999952316284\n",
      "Train Iteration 4380: loss 1.5854154825210571, accuracy 0.8799999952316284\n",
      "Train Iteration 4390: loss 1.6384131908416748, accuracy 0.8500000238418579\n",
      "Train Iteration 4400: loss 1.572464108467102, accuracy 0.9100000262260437\n",
      "= Valid Iteration 4400: loss 1.6075531244277954, accuracy 0.8582000136375427 =\n",
      "Train Iteration 4410: loss 1.6122658252716064, accuracy 0.8600000143051147\n",
      "Train Iteration 4420: loss 1.6082968711853027, accuracy 0.8500000238418579\n",
      "Train Iteration 4430: loss 1.6249545812606812, accuracy 0.8299999833106995\n",
      "Train Iteration 4440: loss 1.6245064735412598, accuracy 0.8399999737739563\n",
      "Train Iteration 4450: loss 1.5627914667129517, accuracy 0.9100000262260437\n",
      "Train Iteration 4460: loss 1.5675638914108276, accuracy 0.8899999856948853\n",
      "Train Iteration 4470: loss 1.5301541090011597, accuracy 0.9399999976158142\n",
      "Train Iteration 4480: loss 1.6450506448745728, accuracy 0.8199999928474426\n",
      "Train Iteration 4490: loss 1.556909203529358, accuracy 0.9200000166893005\n",
      "Train Iteration 4500: loss 1.605139970779419, accuracy 0.8600000143051147\n",
      "= Valid Iteration 4500: loss 1.598772406578064, accuracy 0.8697999715805054 =\n",
      "Train Iteration 4510: loss 1.626237392425537, accuracy 0.8299999833106995\n",
      "Train Iteration 4520: loss 1.587085247039795, accuracy 0.8600000143051147\n",
      "Train Iteration 4530: loss 1.616711139678955, accuracy 0.8399999737739563\n",
      "Train Iteration 4540: loss 1.6372113227844238, accuracy 0.8199999928474426\n",
      "Train Iteration 4550: loss 1.637181043624878, accuracy 0.8299999833106995\n",
      "Train Iteration 4560: loss 1.6138339042663574, accuracy 0.8500000238418579\n",
      "Train Iteration 4570: loss 1.5981194972991943, accuracy 0.8600000143051147\n",
      "Train Iteration 4580: loss 1.600669503211975, accuracy 0.8700000047683716\n",
      "Train Iteration 4590: loss 1.5746368169784546, accuracy 0.8899999856948853\n",
      "Train Iteration 4600: loss 1.5681707859039307, accuracy 0.9200000166893005\n",
      "= Valid Iteration 4600: loss 1.5992302894592285, accuracy 0.8673999905586243 =\n",
      "Train Iteration 4610: loss 1.6527584791183472, accuracy 0.8100000023841858\n",
      "Train Iteration 4620: loss 1.608249545097351, accuracy 0.8500000238418579\n",
      "Train Iteration 4630: loss 1.666987657546997, accuracy 0.8100000023841858\n",
      "Train Iteration 4640: loss 1.6081370115280151, accuracy 0.8600000143051147\n",
      "Train Iteration 4650: loss 1.5811669826507568, accuracy 0.8799999952316284\n",
      "Train Iteration 4660: loss 1.6432058811187744, accuracy 0.8199999928474426\n",
      "Train Iteration 4670: loss 1.6225472688674927, accuracy 0.8600000143051147\n",
      "Train Iteration 4680: loss 1.5630009174346924, accuracy 0.8999999761581421\n",
      "Train Iteration 4690: loss 1.568356990814209, accuracy 0.8999999761581421\n",
      "Train Iteration 4700: loss 1.648112177848816, accuracy 0.8199999928474426\n",
      "= Valid Iteration 4700: loss 1.5995967388153076, accuracy 0.8668000102043152 =\n",
      "Train Iteration 4710: loss 1.6225121021270752, accuracy 0.8500000238418579\n",
      "Train Iteration 4720: loss 1.5715712308883667, accuracy 0.9100000262260437\n",
      "Train Iteration 4730: loss 1.5804297924041748, accuracy 0.8999999761581421\n",
      "Train Iteration 4740: loss 1.5862749814987183, accuracy 0.8899999856948853\n",
      "Train Iteration 4750: loss 1.6285996437072754, accuracy 0.8500000238418579\n",
      "Train Iteration 4760: loss 1.5897188186645508, accuracy 0.8700000047683716\n",
      "Train Iteration 4770: loss 1.5633597373962402, accuracy 0.9200000166893005\n",
      "Train Iteration 4780: loss 1.576115369796753, accuracy 0.8899999856948853\n",
      "Train Iteration 4790: loss 1.5663936138153076, accuracy 0.8999999761581421\n",
      "Train Iteration 4800: loss 1.6367790699005127, accuracy 0.8399999737739563\n",
      "= Valid Iteration 4800: loss 1.601506233215332, accuracy 0.8640000224113464 =\n",
      "Train Iteration 4810: loss 1.6391098499298096, accuracy 0.8299999833106995\n",
      "Train Iteration 4820: loss 1.552750587463379, accuracy 0.9399999976158142\n",
      "Train Iteration 4830: loss 1.692897915840149, accuracy 0.7599999904632568\n",
      "Train Iteration 4840: loss 1.6197346448898315, accuracy 0.8500000238418579\n",
      "Train Iteration 4850: loss 1.5580161809921265, accuracy 0.9100000262260437\n",
      "Train Iteration 4860: loss 1.6341586112976074, accuracy 0.8299999833106995\n",
      "Train Iteration 4870: loss 1.596834659576416, accuracy 0.8799999952316284\n",
      "Train Iteration 4880: loss 1.626692771911621, accuracy 0.8399999737739563\n",
      "Train Iteration 4890: loss 1.5651108026504517, accuracy 0.9200000166893005\n",
      "Train Iteration 4900: loss 1.5941029787063599, accuracy 0.8600000143051147\n",
      "= Valid Iteration 4900: loss 1.6077810525894165, accuracy 0.8564000129699707 =\n",
      "Train Iteration 4910: loss 1.5493457317352295, accuracy 0.9200000166893005\n",
      "Train Iteration 4920: loss 1.5567153692245483, accuracy 0.9200000166893005\n",
      "Train Iteration 4930: loss 1.5289437770843506, accuracy 0.949999988079071\n",
      "Train Iteration 4940: loss 1.5796904563903809, accuracy 0.8899999856948853\n",
      "Train Iteration 4950: loss 1.6107693910598755, accuracy 0.8399999737739563\n",
      "Train Iteration 4960: loss 1.5982376337051392, accuracy 0.8600000143051147\n",
      "Train Iteration 4970: loss 1.6036640405654907, accuracy 0.8600000143051147\n",
      "Train Iteration 4980: loss 1.6370447874069214, accuracy 0.8299999833106995\n",
      "Train Iteration 4990: loss 1.5981934070587158, accuracy 0.8700000047683716\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "model_path = logging_meta['model_path']\n",
    "        \n",
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    session.run(initialize_vars)\n",
    "    for iteration in range(5000):\n",
    "        ##################\n",
    "        # Training phase #\n",
    "        ##################\n",
    "        _images, _labels = data.train.next_batch(100)\n",
    "        _ = session.run([train_step], feed_dict={images: _images, labels: _labels, keep_dropout_prob: 0.5})\n",
    "        if iteration % 10 == 0:\n",
    "            _summary, _accuracy, _loss = session.run([merge_summaries, accuracy, loss],\n",
    "                                                     feed_dict={images: _images, \n",
    "                                                                labels: _labels, \n",
    "                                                                keep_dropout_prob: 1.0})\n",
    "            logging_meta['train_writer'].add_summary(_summary, iteration)\n",
    "            print(\"Train Iteration {}: loss {}, accuracy {}\".format(iteration, _loss, _accuracy))\n",
    "      \n",
    "        ####################\n",
    "        # Validation phase #\n",
    "        ####################\n",
    "        if iteration % 100 == 0:\n",
    "            _summary, _accuracy, _loss = session.run([merge_summaries, accuracy, loss], \n",
    "                                          feed_dict={images: data.validation.images, \n",
    "                                                     labels: data.validation.labels,\n",
    "                                                     keep_dropout_prob: 1.0})\n",
    "            logging_meta['valid_writer'].add_summary(_summary, iteration)\n",
    "            logging_meta['saver'].save(session, model_path, iteration)\n",
    "            print(\"= Valid Iteration {}: loss {}, accuracy {} =\".format(iteration, _loss, _accuracy))\n",
    "            \n",
    "    _prediction, = session.run([prediction], feed_dict={images: data.validation.images, keep_dropout_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.07458769e-16,   2.02757429e-12,   1.86062967e-14, ...,\n",
       "          1.20290244e-09,   6.35634545e-10,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   1.08944589e-10,   4.81477025e-10, ...,\n",
       "          3.60207895e-19,   1.18872046e-09,   1.29780964e-10],\n",
       "       [  4.83380526e-01,   6.40578568e-02,   2.49041594e-03, ...,\n",
       "          1.40850883e-04,   2.82091321e-04,   3.37777566e-03],\n",
       "       ..., \n",
       "       [  4.12653719e-07,   1.89303489e-06,   5.06804872e-06, ...,\n",
       "          3.06115195e-04,   1.09589295e-04,   8.92834098e-04],\n",
       "       [  1.57973474e-08,   4.50984352e-08,   1.33971754e-03, ...,\n",
       "          5.15389363e-11,   9.98659015e-01,   3.85884574e-10],\n",
       "       [  1.13414526e-05,   7.33688765e-04,   1.22960819e-05, ...,\n",
       "          5.74003971e-05,   4.08170272e-05,   2.81546563e-05]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
