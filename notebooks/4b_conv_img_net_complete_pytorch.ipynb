{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Image Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.nn_visualization import variable_summaries\n",
    "from utils.data import init_model_logging\n",
    "from utils.nn_graph import simple_layer\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-26d964d64c62>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /data/fashion/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /data/fashion/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting /data/fashion/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('/data/fashion/', one_hot=True)\n",
    "img_shape = (28, 28)\n",
    "class_id2class_name_mapping = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(name, input_data, \n",
    "               conv_filter_shape, pooling_filter_shape, \n",
    "               conv_filter_stride=[1, 1, 1, 1], \n",
    "               pooling_filter_stride=[1, 1, 1, 1],\n",
    "               padding='SAME',\n",
    "               is_training=True):\n",
    "    w_name = 'w_' + name\n",
    "    b_name = 'b_' + name\n",
    "    \n",
    "    # Variables initialization\n",
    "    w = tf.get_variable(w_name, conv_filter_shape, initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "    bias = tf.get_variable(b_name, initializer=tf.constant_initializer(0), shape=conv_filter_shape[-1])\n",
    "\n",
    "    # Convolution part\n",
    "    conv_layer = tf.nn.conv2d(input_data, w, strides=conv_filter_stride, padding=padding)\n",
    "    # conv_layer = tf.contrib.layers.batch_norm(conv_layer, is_training=is_training)\n",
    "\n",
    "    conv_layer = conv_layer + bias\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "\n",
    "    # Pooling part\n",
    "    conv_layer = tf.nn.max_pool(conv_layer, \n",
    "                                ksize=pooling_filter_shape, \n",
    "                                strides=pooling_filter_stride, \n",
    "                                padding=padding)\n",
    "    \n",
    "    return conv_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Conv Net Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('conv_image_net_inputs'):\n",
    "        images = tf.placeholder(tf.float32, shape=[None, 784], name='images')\n",
    "        labels = tf.placeholder(tf.float32, shape=[None, 10], name='labels')\n",
    "        keep_dropout_prob = tf.placeholder(tf.float32, name='keep_dropout_prob')\n",
    "        is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "            \n",
    "    with tf.name_scope('image_reshape'):        \n",
    "        images_reshaped = tf.reshape(images, [-1, 28, 28, 1])\n",
    "\n",
    "    with tf.variable_scope('conv_layer_1'):\n",
    "        conv_layer_1 = conv_layer('cl_1', images_reshaped, \n",
    "               conv_filter_shape=[3, 3, 1, 32], pooling_filter_shape=[1, 2, 2, 1], \n",
    "               conv_filter_stride=[1, 1, 1, 1], pooling_filter_stride=[1, 2, 2, 1],\n",
    "               padding='SAME')  \n",
    "\n",
    "    with tf.variable_scope('conv_layer_2'):\n",
    "        conv_layer_2 = conv_layer('cl_2', conv_layer_1, \n",
    "               conv_filter_shape=[3, 3, 32, 64], pooling_filter_shape=[1, 2, 2, 1], \n",
    "               conv_filter_stride=[1, 1, 1, 1], pooling_filter_stride=[1, 2, 2, 1],\n",
    "               padding='SAME') \n",
    "    \n",
    "    with tf.variable_scope('feed_forward_layer_1'):\n",
    "        ff_layer_1 = tf.reshape(conv_layer_2, [-1, 7*7*64])\n",
    "        ff_layer_1 = simple_layer('ff_1', ff_layer_1, shape=[7*7*64, 10], activation='linear')\n",
    "        raw_prediction = tf.nn.dropout(ff_layer_1, keep_dropout_prob)\n",
    "    \n",
    "    with tf.name_scope('prediction'):\n",
    "        prediction = tf.nn.softmax(raw_prediction)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy_vector = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=raw_prediction)\n",
    "        loss = tf.reduce_mean(cross_entropy_vector)\n",
    "        variable_summaries('loss_summary', cross_entropy_vector)\n",
    "        \n",
    "    with tf.name_scope('training'):\n",
    "        # This dependency is here because of potential batch normalization and need of floating averages update\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_step  = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction)\n",
    "        variable_summaries('accuracy_summary', correct_prediction)\n",
    "    \n",
    "    initialize_vars = tf.global_variables_initializer()\n",
    "    merge_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Model Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/tensorboard_summaries/conv_image_net/'\n",
    "logging_meta = init_model_logging(base_dir, 'experiment_final', graph=graph, remove_existing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Conv Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "model_path = logging_meta['model_path']\n",
    "\n",
    "validation_feed_dict = {\n",
    "    images: data.validation.images, \n",
    "    labels: data.validation.labels,\n",
    "    keep_dropout_prob: 1., \n",
    "    is_training: False}\n",
    "\n",
    "session = tf.Session(graph=graph, config=config)\n",
    "session.run(initialize_vars)\n",
    "\n",
    "for iteration in range(101):\n",
    "    ##################\n",
    "    # Training Phase #\n",
    "    ##################\n",
    "    \n",
    "    _images, _labels = data.train.next_batch(100)\n",
    "    feed_dict = {images: _images, labels: _labels, keep_dropout_prob: 0.5, is_training: True}\n",
    "    _ = session.run([train_step], feed_dict=feed_dict)\n",
    " \n",
    "\n",
    "    #################\n",
    "    # Logging Phase #\n",
    "    #################\n",
    "\n",
    "    # Train log\n",
    "    feed_dict={images: _images, labels: _labels, keep_dropout_prob: 1., is_training: False}\n",
    "    _summary, _accuracy, _loss = session.run([merge_summaries, accuracy, loss],feed_dict=feed_dict)\n",
    "    logging_meta['train_writer'].add_summary(_summary, iteration)\n",
    "\n",
    "    # Valid Log\n",
    "    if iteration % 100 == 0:\n",
    "        _summary, _accuracy, _loss = session.run([merge_summaries, accuracy, loss], validation_feed_dict)\n",
    "        \n",
    "        logging_meta['valid_writer'].add_summary(_summary, iteration)\n",
    "        logging_meta['saver'].save(session, model_path, iteration)\n",
    "        print(\"= Valid Iteration {}: loss {}, accuracy {} =\".format(iteration, _loss, _accuracy))\n",
    "\n",
    "_prediction, = session.run([prediction], feed_dict=validation_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as k\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Flatten, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Input(shape=(28, 28, 1))\n",
    "layer = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(images)\n",
    "layer = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(layer)\n",
    "\n",
    "layer = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(images)\n",
    "layer = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(layer)\n",
    "\n",
    "layer = Flatten()(layer)\n",
    "prediction = Dense(10, activation='softmax')(layer)\n",
    "\n",
    "model = Model(inputs=images, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = data.train.images.reshape((-1, 28, 28, 1))\n",
    "labels = data.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_images = data.validation.images.reshape((-1, 28, 28, 1))\n",
    "valid_labels = data.validation.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=images, y=labels, batch_size=32, epochs=5, \n",
    "          validation_data=(valid_images, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_prediction = model.predict(valid_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.Adam([w1, w2], lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 33174540.0\n",
      "1000 32282524.0\n",
      "2000 31407946.0\n",
      "3000 30551264.0\n",
      "4000 29709850.0\n",
      "5000 28885426.0\n",
      "6000 28075776.0\n",
      "7000 27281814.0\n",
      "8000 26502998.0\n",
      "9000 25738418.0\n",
      "10000 24988076.0\n",
      "11000 24251710.0\n",
      "12000 23529110.0\n",
      "13000 22820762.0\n",
      "14000 22126830.0\n",
      "15000 21446944.0\n",
      "16000 20781058.0\n",
      "17000 20128876.0\n",
      "18000 19490962.0\n",
      "19000 18866906.0\n",
      "20000 18256076.0\n",
      "21000 17658252.0\n",
      "22000 17073316.0\n",
      "23000 16501061.0\n",
      "24000 15941383.0\n",
      "25000 15394809.0\n",
      "26000 14861603.0\n",
      "27000 14340860.0\n",
      "28000 13832507.0\n",
      "29000 13336252.0\n",
      "30000 12852342.0\n",
      "31000 12380270.0\n",
      "32000 11919481.0\n",
      "33000 11469913.0\n",
      "34000 11031235.0\n",
      "35000 10603697.0\n",
      "36000 10187285.0\n",
      "37000 9781710.0\n",
      "38000 9386925.0\n",
      "39000 9002984.0\n",
      "40000 8630072.0\n",
      "41000 8268239.5\n",
      "42000 7916777.5\n",
      "43000 7575345.0\n",
      "44000 7244323.5\n",
      "45000 6923452.5\n",
      "46000 6612356.5\n",
      "47000 6310855.0\n",
      "48000 6019002.0\n",
      "49000 5736856.5\n",
      "50000 5463679.0\n",
      "51000 5200102.5\n",
      "52000 4945442.0\n",
      "53000 4699418.5\n",
      "54000 4461374.5\n",
      "55000 4231956.0\n",
      "56000 4010873.5\n",
      "57000 3797960.25\n",
      "58000 3592799.25\n",
      "59000 3395201.0\n",
      "60000 3205204.0\n",
      "61000 3022600.25\n",
      "62000 2847157.75\n",
      "63000 2678887.0\n",
      "64000 2517751.75\n",
      "65000 2363909.5\n",
      "66000 2216771.0\n",
      "67000 2076100.875\n",
      "68000 1941527.25\n",
      "69000 1812959.125\n",
      "70000 1690391.875\n",
      "71000 1573537.125\n",
      "72000 1462142.75\n",
      "73000 1356195.625\n",
      "74000 1255370.875\n",
      "75000 1159483.625\n",
      "76000 1068336.0\n",
      "77000 982009.625\n",
      "78000 900412.875\n",
      "79000 823004.3125\n",
      "80000 749714.5625\n",
      "81000 680933.6875\n",
      "82000 616427.1875\n",
      "83000 556123.3125\n",
      "84000 499668.625\n",
      "85000 446799.5\n",
      "86000 397444.5625\n",
      "87000 351744.5625\n",
      "88000 309460.78125\n",
      "89000 270448.3125\n",
      "90000 234632.265625\n",
      "91000 201959.875\n",
      "92000 172259.203125\n",
      "93000 145400.328125\n",
      "94000 121259.359375\n",
      "95000 99766.2109375\n",
      "96000 80822.3828125\n",
      "97000 64276.48828125\n",
      "98000 50001.26171875\n",
      "99000 37890.01953125\n"
     ]
    }
   ],
   "source": [
    "for t in range(100000):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t%1000 == 0:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.results_evaluation import get_info_df\n",
    "from utils.results_evaluation import get_accuracy\n",
    "from utils.results_evaluation import get_false_positives\n",
    "from utils.results_evaluation import get_info_df\n",
    "from utils.results_evaluation import get_rec_prec\n",
    "from utils.results_evaluation import plot_coocurance_matrix\n",
    "from utils.results_evaluation import plot_examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_info_df(data.validation.labels, _prediction, class_id2class_name_mapping, data.validation.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_prec(df, class_id2class_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = get_false_positives(df, 'Shirt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurance_matrix(df, use_top3=False, use_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
