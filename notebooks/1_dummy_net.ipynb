{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interesting tasks**\n",
    " - inspect tensorboard\n",
    " - change learning rates\n",
    " - change initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import init_dir\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Net Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug [prediction]: (?, 1)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('dummy_net_inputs'):\n",
    "        data = tf.placeholder(tf.float32, shape=[None, 3], name='data')\n",
    "        labels = tf.placeholder(tf.float32, shape=[None, 1], name='labels')\n",
    "    \n",
    "    with tf.variable_scope('layer_1'):\n",
    "        w1 = tf.get_variable('w1', initializer=tf.constant_initializer(0), shape=[3,2])\n",
    "        prediction = tf.matmul(data, w1)\n",
    "        tf.summary.histogram('w1_histogram', w1)\n",
    "    \n",
    "    with tf.variable_scope('layer_2'):\n",
    "        w2 = tf.get_variable('w2', initializer=tf.truncated_normal(shape=[2,1], stddev=0.1))\n",
    "        prediction = tf.matmul(prediction, w2)\n",
    "        print('Debug [prediction]:', prediction.get_shape())\n",
    "        tf.summary.histogram('w2_histogram', w2)\n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.losses.mean_squared_error(labels, prediction)\n",
    "        tf.summary.scalar('loss_summary', loss)\n",
    "\n",
    "    with tf.name_scope('training'):\n",
    "        train_step = tf.train.GradientDescentOptimizer(learning_rate=0.005).minimize(loss)\n",
    "\n",
    "    initialize_vars = tf.global_variables_initializer()\n",
    "    merge_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trainable_variables', 'train_op', 'losses', 'summaries', 'variables']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_all_collection_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Model Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import init_model_logging\n",
    "base_dir = '/tensorboard_summaries/dummy_net/'\n",
    "\n",
    "logging_meta = init_model_logging(base_dir, 'experiment1', graph=graph, remove_existing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_path': '/tensorboard_summaries/dummy_net/experiment1/valid/model.ckpt',\n",
       " 'saver': <tensorflow.python.training.saver.Saver at 0x7f0200e064a8>,\n",
       " 'train_writer': <tensorflow.python.summary.writer.writer.FileWriter at 0x7f0200e06588>,\n",
       " 'train_writer_dir': '/tensorboard_summaries/dummy_net/experiment1/train',\n",
       " 'valid_writer': <tensorflow.python.summary.writer.writer.FileWriter at 0x7f0200e06828>,\n",
       " 'valid_writer_dir': '/tensorboard_summaries/dummy_net/experiment1/valid'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: loss 25.0, pred 0.0\n",
      "Iteration 1: loss 24.779279708862305, pred 0.022121001034975052\n",
      "Iteration 2: loss 24.545263290405273, pred 0.04568234458565712\n",
      "Iteration 3: loss 24.267642974853516, pred 0.07378026843070984\n",
      "Iteration 4: loss 23.91391372680664, pred 0.1098146140575409\n",
      "Iteration 5: loss 23.44634437561035, pred 0.15785764157772064\n",
      "Iteration 6: loss 22.819705963134766, pred 0.2230023741722107\n",
      "Iteration 7: loss 21.98041343688965, pred 0.3116726875305176\n",
      "Iteration 8: loss 20.868255615234375, pred 0.431821346282959\n",
      "Iteration 9: loss 19.42290687561035, pred 0.592857301235199\n",
      "Iteration 10: loss 17.59773826599121, pred 0.805034339427948\n",
      "Iteration 11: loss 15.382562637329102, pred 1.0779390335083008\n",
      "Iteration 12: loss 12.832423210144043, pred 1.4177627563476562\n",
      "Iteration 13: loss 10.090475082397461, pred 1.8234491348266602\n",
      "Iteration 14: loss 7.383357524871826, pred 2.282766580581665\n",
      "Iteration 15: loss 4.97019100189209, pred 2.7706074714660645\n",
      "Iteration 16: loss 3.0549468994140625, pred 3.252159357070923\n",
      "Iteration 17: loss 1.7122541666030884, pred 3.6914687156677246\n",
      "Iteration 18: loss 0.8801968693733215, pred 4.061811923980713\n",
      "Iteration 19: loss 0.4199036955833435, pred 4.3520002365112305\n",
      "Iteration 20: loss 0.18870094418525696, pred 4.565602779388428\n",
      "Iteration 21: loss 0.08109422773122787, pred 4.715229511260986\n",
      "Iteration 22: loss 0.033763591200113297, pred 4.816251277923584\n",
      "Iteration 23: loss 0.013757620006799698, pred 4.882707118988037\n",
      "Iteration 24: loss 0.005526416003704071, pred 4.925660133361816\n",
      "Iteration 25: loss 0.0021995462011545897, pred 4.953100681304932\n",
      "Iteration 26: loss 0.0008702504565007985, pred 4.9704999923706055\n",
      "Iteration 27: loss 0.0003430212091188878, pred 4.981479167938232\n",
      "Iteration 28: loss 0.00013488141121342778, pred 4.988386154174805\n",
      "Iteration 29: loss 5.296184099279344e-05, pred 4.992722511291504\n",
      "Iteration 30: loss 2.07761513593141e-05, pred 4.995441913604736\n",
      "Iteration 31: loss 8.147298103722278e-06, pred 4.997145652770996\n",
      "Iteration 32: loss 3.192328449586057e-06, pred 4.998213291168213\n",
      "Iteration 33: loss 1.2503335256042192e-06, pred 4.998881816864014\n",
      "Iteration 34: loss 4.893283858109498e-07, pred 4.999300479888916\n",
      "Iteration 35: loss 1.916132532642223e-07, pred 4.9995622634887695\n",
      "Iteration 36: loss 7.491416909033433e-08, pred 4.999726295471191\n",
      "Iteration 37: loss 2.9467628337442875e-08, pred 4.999828338623047\n",
      "Iteration 38: loss 1.161333784693852e-08, pred 4.999892234802246\n",
      "Iteration 39: loss 4.5204160414868966e-09, pred 4.999932765960693\n",
      "Iteration 40: loss 1.8010268831858411e-09, pred 4.99995756149292\n",
      "Iteration 41: loss 7.130438461899757e-10, pred 4.999973297119141\n",
      "Iteration 42: loss 2.7853275241795927e-10, pred 4.999983310699463\n",
      "Iteration 43: loss 1.0027179087046534e-10, pred 4.999989986419678\n",
      "Iteration 44: loss 4.4565240386873484e-11, pred 4.999993324279785\n",
      "Iteration 45: loss 1.8417267710901797e-11, pred 4.999995708465576\n",
      "Iteration 46: loss 8.185452315956354e-12, pred 4.999997138977051\n",
      "Iteration 47: loss 2.0463630789890885e-12, pred 4.999998569488525\n",
      "Iteration 48: loss 2.0463630789890885e-12, pred 4.999998569488525\n",
      "Iteration 49: loss 9.094947017729282e-13, pred 4.999999046325684\n",
      "Iteration 50: loss 0.0, pred 5.0\n",
      "Iteration 51: loss 0.0, pred 5.0\n",
      "Iteration 52: loss 0.0, pred 5.0\n",
      "Iteration 53: loss 0.0, pred 5.0\n",
      "Iteration 54: loss 0.0, pred 5.0\n",
      "Iteration 55: loss 0.0, pred 5.0\n",
      "Iteration 56: loss 0.0, pred 5.0\n",
      "Iteration 57: loss 0.0, pred 5.0\n",
      "Iteration 58: loss 0.0, pred 5.0\n",
      "Iteration 59: loss 0.0, pred 5.0\n",
      "Iteration 60: loss 0.0, pred 5.0\n",
      "Iteration 61: loss 0.0, pred 5.0\n",
      "Iteration 62: loss 0.0, pred 5.0\n",
      "Iteration 63: loss 0.0, pred 5.0\n",
      "Iteration 64: loss 0.0, pred 5.0\n",
      "Iteration 65: loss 0.0, pred 5.0\n",
      "Iteration 66: loss 0.0, pred 5.0\n",
      "Iteration 67: loss 0.0, pred 5.0\n",
      "Iteration 68: loss 0.0, pred 5.0\n",
      "Iteration 69: loss 0.0, pred 5.0\n",
      "Iteration 70: loss 0.0, pred 5.0\n",
      "Iteration 71: loss 0.0, pred 5.0\n",
      "Iteration 72: loss 0.0, pred 5.0\n",
      "Iteration 73: loss 0.0, pred 5.0\n",
      "Iteration 74: loss 0.0, pred 5.0\n",
      "Iteration 75: loss 0.0, pred 5.0\n",
      "Iteration 76: loss 0.0, pred 5.0\n",
      "Iteration 77: loss 0.0, pred 5.0\n",
      "Iteration 78: loss 0.0, pred 5.0\n",
      "Iteration 79: loss 0.0, pred 5.0\n",
      "Iteration 80: loss 0.0, pred 5.0\n",
      "Iteration 81: loss 0.0, pred 5.0\n",
      "Iteration 82: loss 0.0, pred 5.0\n",
      "Iteration 83: loss 0.0, pred 5.0\n",
      "Iteration 84: loss 0.0, pred 5.0\n",
      "Iteration 85: loss 0.0, pred 5.0\n",
      "Iteration 86: loss 0.0, pred 5.0\n",
      "Iteration 87: loss 0.0, pred 5.0\n",
      "Iteration 88: loss 0.0, pred 5.0\n",
      "Iteration 89: loss 0.0, pred 5.0\n",
      "Iteration 90: loss 0.0, pred 5.0\n",
      "Iteration 91: loss 0.0, pred 5.0\n",
      "Iteration 92: loss 0.0, pred 5.0\n",
      "Iteration 93: loss 0.0, pred 5.0\n",
      "Iteration 94: loss 0.0, pred 5.0\n",
      "Iteration 95: loss 0.0, pred 5.0\n",
      "Iteration 96: loss 0.0, pred 5.0\n",
      "Iteration 97: loss 0.0, pred 5.0\n",
      "Iteration 98: loss 0.0, pred 5.0\n",
      "Iteration 99: loss 0.0, pred 5.0\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "_data = np.array([[1,2,3]])\n",
    "_labels = np.array([[5]])\n",
    "\n",
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    session.run(initialize_vars)\n",
    "    \n",
    "    for iteration in range(100):\n",
    "        # Prepare data\n",
    "        feed_dict = {data: _data, labels: _labels}\n",
    "        fetches = [train_step, prediction, loss, merge_summaries]\n",
    "\n",
    "        # Train\n",
    "        _, _prediction, _loss, _summary = session.run(fetches, feed_dict)\n",
    "        \n",
    "        # Log\n",
    "        logging_meta['train_writer'].add_summary(_summary, iteration)\n",
    "        print(\"Iteration {}: loss {}, pred {}\".format(iteration, _loss, _prediction[0][0]))\n",
    "\n",
    "    logging_meta['saver'].save(session, logging_meta['model_path'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
