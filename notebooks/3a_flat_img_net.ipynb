{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flat Image Net - Basic Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from utils.data import init_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting /data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting /data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting /data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('/data/fashion/', one_hot=True)\n",
    "class_id2class_name_mapping = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic summary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summaries(name, var):\n",
    "    with tf.name_scope(name):        \n",
    "        tf.summary.histogram('histogram', var)\n",
    "        ###########################################################\n",
    "        # Complete scalar summaries for min, max, stddev and mean #\n",
    "        ###########################################################\n",
    "        \n",
    "def img_summaries(name, var):\n",
    "    with tf.name_scope(name):\n",
    "        tf.summary.image(name, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_layer(name, input_data, shape, activation='linear'):\n",
    "    w_name = 'w_' + name\n",
    "    b_name = 'b_' + name\n",
    "    \n",
    "    w = tf.get_variable('w', initializer=tf.truncated_normal(shape, stddev=0.1))\n",
    "    bias = tf.get_variable(b_name, initializer=tf.constant_initializer(0.1), shape=shape[1])\n",
    "    \n",
    "    #####################################################\n",
    "    # Complete xavier and variance_scaling initializers #\n",
    "    #####################################################\n",
    "    \n",
    "    output_data = tf.matmul(input_data, w) + bias\n",
    "    \n",
    "    #################################################\n",
    "    # Complete sigmoid, linear and relu activations #\n",
    "    #################################################\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Net Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('flat_image_net_inputs'):\n",
    "        images = tf.placeholder(tf.float32, shape=[None, 784], name='images')\n",
    "        labels = tf.placeholder(tf.float32, shape=[None, 10], name='labels')\n",
    "    \n",
    "    with tf.variable_scope('simple_layer_1'):\n",
    "        raw_prediction = simple_layer(name='layer1', input_data=images, shape=[784, 10])\n",
    "            \n",
    "    with tf.name_scope('prediction'):\n",
    "        prediction = raw_prediction\n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        #####################\n",
    "        # Fix loss function #\n",
    "        #####################\n",
    "        loss_vector = raw_prediction - labels\n",
    "        loss = tf.reduce_mean(loss_vector)\n",
    "        variable_summaries('loss_summary', loss_vector)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction)\n",
    "        variable_summaries('accuracy_summary', correct_prediction)       \n",
    "        \n",
    "    with tf.name_scope('training'):\n",
    "        ####################\n",
    "        # Change optimizer #\n",
    "        ####################\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "            \n",
    "    initialize_vars = tf.global_variables_initializer()\n",
    "    merge_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Model Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import init_model_logging\n",
    "base_dir = '/tensorboard_summaries/flat_image_net/'\n",
    "\n",
    "logging_meta = init_model_logging(base_dir, 'experiment1', graph=graph, remove_existing=True)\n",
    "######################################\n",
    "# Inspect code of init_model_logging #\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: loss -4.3117265701293945, accuracy 0.03999999910593033\n",
      "Iteration 10: loss -54.31332778930664, accuracy 0.05999999865889549\n",
      "Iteration 20: loss -99.51949310302734, accuracy 0.14000000059604645\n",
      "Iteration 30: loss -139.197265625, accuracy 0.11999999731779099\n",
      "Iteration 40: loss -200.31491088867188, accuracy 0.05000000074505806\n",
      "Iteration 50: loss -229.6427764892578, accuracy 0.12999999523162842\n",
      "Iteration 60: loss -300.5534973144531, accuracy 0.14000000059604645\n",
      "Iteration 70: loss -341.6572570800781, accuracy 0.10999999940395355\n",
      "Iteration 80: loss -374.0713806152344, accuracy 0.10999999940395355\n",
      "Iteration 90: loss -383.85693359375, accuracy 0.10000000149011612\n",
      "Iteration 100: loss -488.0667419433594, accuracy 0.10000000149011612\n",
      "Iteration 110: loss -539.5288696289062, accuracy 0.07999999821186066\n",
      "Iteration 120: loss -575.18408203125, accuracy 0.009999999776482582\n",
      "Iteration 130: loss -626.6466064453125, accuracy 0.12999999523162842\n",
      "Iteration 140: loss -662.1748046875, accuracy 0.15000000596046448\n",
      "Iteration 150: loss -682.8535766601562, accuracy 0.09000000357627869\n",
      "Iteration 160: loss -769.91748046875, accuracy 0.10000000149011612\n",
      "Iteration 170: loss -793.0518188476562, accuracy 0.10000000149011612\n",
      "Iteration 180: loss -815.1686401367188, accuracy 0.10999999940395355\n",
      "Iteration 190: loss -876.420166015625, accuracy 0.10999999940395355\n",
      "Iteration 200: loss -958.4026489257812, accuracy 0.11999999731779099\n",
      "Iteration 210: loss -976.8433837890625, accuracy 0.07999999821186066\n",
      "Iteration 220: loss -1036.95166015625, accuracy 0.07999999821186066\n",
      "Iteration 230: loss -1054.5701904296875, accuracy 0.05999999865889549\n",
      "Iteration 240: loss -1206.27783203125, accuracy 0.07999999821186066\n",
      "Iteration 250: loss -1215.4283447265625, accuracy 0.1599999964237213\n",
      "Iteration 260: loss -1227.1470947265625, accuracy 0.10999999940395355\n",
      "Iteration 270: loss -1269.7261962890625, accuracy 0.15000000596046448\n",
      "Iteration 280: loss -1237.2103271484375, accuracy 0.15000000596046448\n",
      "Iteration 290: loss -1347.6553955078125, accuracy 0.07999999821186066\n",
      "Iteration 300: loss -1411.322509765625, accuracy 0.05000000074505806\n",
      "Iteration 310: loss -1463.3466796875, accuracy 0.09000000357627869\n",
      "Iteration 320: loss -1561.9482421875, accuracy 0.10999999940395355\n",
      "Iteration 330: loss -1577.93212890625, accuracy 0.07999999821186066\n",
      "Iteration 340: loss -1596.5032958984375, accuracy 0.10000000149011612\n",
      "Iteration 350: loss -1583.1021728515625, accuracy 0.11999999731779099\n",
      "Iteration 360: loss -1707.0450439453125, accuracy 0.07999999821186066\n",
      "Iteration 370: loss -1738.033203125, accuracy 0.07000000029802322\n",
      "Iteration 380: loss -1824.2332763671875, accuracy 0.07999999821186066\n",
      "Iteration 390: loss -1813.80859375, accuracy 0.10000000149011612\n",
      "Iteration 400: loss -2015.694091796875, accuracy 0.05000000074505806\n",
      "Iteration 410: loss -1917.106201171875, accuracy 0.10999999940395355\n",
      "Iteration 420: loss -1810.583984375, accuracy 0.14000000059604645\n",
      "Iteration 430: loss -1995.9788818359375, accuracy 0.09000000357627869\n",
      "Iteration 440: loss -2068.99462890625, accuracy 0.15000000596046448\n",
      "Iteration 450: loss -2093.60693359375, accuracy 0.09000000357627869\n",
      "Iteration 460: loss -2135.4716796875, accuracy 0.10000000149011612\n",
      "Iteration 470: loss -2318.368896484375, accuracy 0.07999999821186066\n",
      "Iteration 480: loss -2227.598388671875, accuracy 0.07999999821186066\n",
      "Iteration 490: loss -2323.958984375, accuracy 0.05999999865889549\n",
      "Iteration 500: loss -2430.930419921875, accuracy 0.10999999940395355\n",
      "Iteration 510: loss -2407.932861328125, accuracy 0.10999999940395355\n",
      "Iteration 520: loss -2373.549072265625, accuracy 0.10999999940395355\n",
      "Iteration 530: loss -2408.148193359375, accuracy 0.10999999940395355\n",
      "Iteration 540: loss -2523.87451171875, accuracy 0.07000000029802322\n",
      "Iteration 550: loss -2609.644287109375, accuracy 0.10999999940395355\n",
      "Iteration 560: loss -2562.718505859375, accuracy 0.10999999940395355\n",
      "Iteration 570: loss -2805.484619140625, accuracy 0.1599999964237213\n",
      "Iteration 580: loss -2756.72314453125, accuracy 0.07999999821186066\n",
      "Iteration 590: loss -3103.100830078125, accuracy 0.07999999821186066\n",
      "Iteration 600: loss -2955.2470703125, accuracy 0.10000000149011612\n",
      "Iteration 610: loss -2920.965576171875, accuracy 0.07999999821186066\n",
      "Iteration 620: loss -2827.78759765625, accuracy 0.09000000357627869\n",
      "Iteration 630: loss -2897.3076171875, accuracy 0.05999999865889549\n",
      "Iteration 640: loss -2802.938232421875, accuracy 0.10999999940395355\n",
      "Iteration 650: loss -3017.996337890625, accuracy 0.07999999821186066\n",
      "Iteration 660: loss -3183.607421875, accuracy 0.09000000357627869\n",
      "Iteration 670: loss -3233.32080078125, accuracy 0.11999999731779099\n",
      "Iteration 680: loss -3140.5576171875, accuracy 0.10000000149011612\n",
      "Iteration 690: loss -3231.917236328125, accuracy 0.12999999523162842\n",
      "Iteration 700: loss -3017.7490234375, accuracy 0.12999999523162842\n",
      "Iteration 710: loss -3400.29052734375, accuracy 0.07999999821186066\n",
      "Iteration 720: loss -3314.3056640625, accuracy 0.07000000029802322\n",
      "Iteration 730: loss -3306.618896484375, accuracy 0.14000000059604645\n",
      "Iteration 740: loss -3613.7734375, accuracy 0.07000000029802322\n",
      "Iteration 750: loss -3564.98974609375, accuracy 0.10999999940395355\n",
      "Iteration 760: loss -3619.37548828125, accuracy 0.11999999731779099\n",
      "Iteration 770: loss -3727.63720703125, accuracy 0.10000000149011612\n",
      "Iteration 780: loss -3861.89306640625, accuracy 0.019999999552965164\n",
      "Iteration 790: loss -3539.319580078125, accuracy 0.05999999865889549\n",
      "Iteration 800: loss -3703.135986328125, accuracy 0.03999999910593033\n",
      "Iteration 810: loss -3817.321044921875, accuracy 0.07999999821186066\n",
      "Iteration 820: loss -3889.322509765625, accuracy 0.07999999821186066\n",
      "Iteration 830: loss -3884.615234375, accuracy 0.05999999865889549\n",
      "Iteration 840: loss -3972.268310546875, accuracy 0.15000000596046448\n",
      "Iteration 850: loss -3830.1806640625, accuracy 0.09000000357627869\n",
      "Iteration 860: loss -4115.73876953125, accuracy 0.10000000149011612\n",
      "Iteration 870: loss -4118.44921875, accuracy 0.10999999940395355\n",
      "Iteration 880: loss -4057.530029296875, accuracy 0.10999999940395355\n",
      "Iteration 890: loss -4130.59326171875, accuracy 0.09000000357627869\n",
      "Iteration 900: loss -4270.31787109375, accuracy 0.10000000149011612\n",
      "Iteration 910: loss -4143.228515625, accuracy 0.10999999940395355\n",
      "Iteration 920: loss -4366.369140625, accuracy 0.10000000149011612\n",
      "Iteration 930: loss -4342.037109375, accuracy 0.10999999940395355\n",
      "Iteration 940: loss -4530.38818359375, accuracy 0.07999999821186066\n",
      "Iteration 950: loss -4563.16015625, accuracy 0.07999999821186066\n",
      "Iteration 960: loss -4463.17822265625, accuracy 0.12999999523162842\n",
      "Iteration 970: loss -4690.17529296875, accuracy 0.07999999821186066\n",
      "Iteration 980: loss -5003.52734375, accuracy 0.09000000357627869\n",
      "Iteration 990: loss -4679.10986328125, accuracy 0.10999999940395355\n",
      "Iteration 1000: loss -4542.32763671875, accuracy 0.11999999731779099\n",
      "Iteration 1010: loss -4601.52880859375, accuracy 0.07999999821186066\n",
      "Iteration 1020: loss -4689.6220703125, accuracy 0.10000000149011612\n",
      "Iteration 1030: loss -4886.01220703125, accuracy 0.05999999865889549\n",
      "Iteration 1040: loss -5268.50537109375, accuracy 0.14000000059604645\n",
      "Iteration 1050: loss -4917.91357421875, accuracy 0.09000000357627869\n",
      "Iteration 1060: loss -4898.7958984375, accuracy 0.12999999523162842\n",
      "Iteration 1070: loss -5320.4111328125, accuracy 0.10000000149011612\n",
      "Iteration 1080: loss -5413.94482421875, accuracy 0.05999999865889549\n",
      "Iteration 1090: loss -5331.37255859375, accuracy 0.07000000029802322\n",
      "Iteration 1100: loss -5034.62548828125, accuracy 0.12999999523162842\n",
      "Iteration 1110: loss -5474.45654296875, accuracy 0.10999999940395355\n",
      "Iteration 1120: loss -5216.498046875, accuracy 0.07999999821186066\n",
      "Iteration 1130: loss -5490.5537109375, accuracy 0.07999999821186066\n",
      "Iteration 1140: loss -5231.56201171875, accuracy 0.15000000596046448\n",
      "Iteration 1150: loss -5238.56982421875, accuracy 0.09000000357627869\n",
      "Iteration 1160: loss -5697.4716796875, accuracy 0.11999999731779099\n",
      "Iteration 1170: loss -4941.9990234375, accuracy 0.05000000074505806\n",
      "Iteration 1180: loss -5274.85498046875, accuracy 0.12999999523162842\n",
      "Iteration 1190: loss -5678.1767578125, accuracy 0.10999999940395355\n",
      "Iteration 1200: loss -5775.9130859375, accuracy 0.09000000357627869\n",
      "Iteration 1210: loss -5942.587890625, accuracy 0.10999999940395355\n",
      "Iteration 1220: loss -5755.6201171875, accuracy 0.07999999821186066\n",
      "Iteration 1230: loss -5567.26123046875, accuracy 0.10000000149011612\n",
      "Iteration 1240: loss -5634.80859375, accuracy 0.10999999940395355\n",
      "Iteration 1250: loss -5437.2646484375, accuracy 0.09000000357627869\n",
      "Iteration 1260: loss -6504.29150390625, accuracy 0.07999999821186066\n",
      "Iteration 1270: loss -6068.44482421875, accuracy 0.10000000149011612\n",
      "Iteration 1280: loss -5901.1552734375, accuracy 0.029999999329447746\n",
      "Iteration 1290: loss -5897.35107421875, accuracy 0.05999999865889549\n",
      "Iteration 1300: loss -6082.27783203125, accuracy 0.10000000149011612\n",
      "Iteration 1310: loss -6059.65087890625, accuracy 0.14000000059604645\n",
      "Iteration 1320: loss -6170.11376953125, accuracy 0.11999999731779099\n",
      "Iteration 1330: loss -6190.34619140625, accuracy 0.09000000357627869\n",
      "Iteration 1340: loss -6423.85498046875, accuracy 0.10000000149011612\n",
      "Iteration 1350: loss -6763.80078125, accuracy 0.05999999865889549\n",
      "Iteration 1360: loss -6747.05615234375, accuracy 0.07999999821186066\n",
      "Iteration 1370: loss -6072.81494140625, accuracy 0.10999999940395355\n",
      "Iteration 1380: loss -7343.01953125, accuracy 0.12999999523162842\n",
      "Iteration 1390: loss -6090.056640625, accuracy 0.12999999523162842\n",
      "Iteration 1400: loss -6930.833984375, accuracy 0.09000000357627869\n",
      "Iteration 1410: loss -6351.8056640625, accuracy 0.05000000074505806\n",
      "Iteration 1420: loss -5937.46728515625, accuracy 0.14000000059604645\n",
      "Iteration 1430: loss -6888.0087890625, accuracy 0.07000000029802322\n",
      "Iteration 1440: loss -6614.3701171875, accuracy 0.15000000596046448\n",
      "Iteration 1450: loss -6820.72802734375, accuracy 0.07000000029802322\n",
      "Iteration 1460: loss -7249.5029296875, accuracy 0.07000000029802322\n",
      "Iteration 1470: loss -6977.5859375, accuracy 0.11999999731779099\n",
      "Iteration 1480: loss -6951.48681640625, accuracy 0.15000000596046448\n",
      "Iteration 1490: loss -7241.06982421875, accuracy 0.09000000357627869\n",
      "Iteration 1500: loss -7150.5908203125, accuracy 0.09000000357627869\n",
      "Iteration 1510: loss -6991.0595703125, accuracy 0.09000000357627869\n",
      "Iteration 1520: loss -7489.0791015625, accuracy 0.05000000074505806\n",
      "Iteration 1530: loss -7642.619140625, accuracy 0.09000000357627869\n",
      "Iteration 1540: loss -7447.05126953125, accuracy 0.10999999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1550: loss -7382.7177734375, accuracy 0.12999999523162842\n",
      "Iteration 1560: loss -7717.5087890625, accuracy 0.11999999731779099\n",
      "Iteration 1570: loss -7635.95263671875, accuracy 0.05000000074505806\n",
      "Iteration 1580: loss -7152.02685546875, accuracy 0.03999999910593033\n",
      "Iteration 1590: loss -7490.79248046875, accuracy 0.10999999940395355\n",
      "Iteration 1600: loss -7730.37890625, accuracy 0.14000000059604645\n",
      "Iteration 1610: loss -7850.544921875, accuracy 0.12999999523162842\n",
      "Iteration 1620: loss -7620.0400390625, accuracy 0.09000000357627869\n",
      "Iteration 1630: loss -7875.8310546875, accuracy 0.11999999731779099\n",
      "Iteration 1640: loss -7611.96044921875, accuracy 0.12999999523162842\n",
      "Iteration 1650: loss -7661.23681640625, accuracy 0.07999999821186066\n",
      "Iteration 1660: loss -8337.4306640625, accuracy 0.12999999523162842\n",
      "Iteration 1670: loss -8174.4013671875, accuracy 0.12999999523162842\n",
      "Iteration 1680: loss -8300.212890625, accuracy 0.14000000059604645\n",
      "Iteration 1690: loss -8387.02734375, accuracy 0.10000000149011612\n",
      "Iteration 1700: loss -8128.68994140625, accuracy 0.12999999523162842\n",
      "Iteration 1710: loss -7816.59716796875, accuracy 0.10000000149011612\n",
      "Iteration 1720: loss -8093.18994140625, accuracy 0.10999999940395355\n",
      "Iteration 1730: loss -8264.46875, accuracy 0.12999999523162842\n",
      "Iteration 1740: loss -8398.2470703125, accuracy 0.05999999865889549\n",
      "Iteration 1750: loss -8425.9619140625, accuracy 0.07999999821186066\n",
      "Iteration 1760: loss -8237.2578125, accuracy 0.09000000357627869\n",
      "Iteration 1770: loss -8105.4111328125, accuracy 0.07000000029802322\n",
      "Iteration 1780: loss -8368.2001953125, accuracy 0.1599999964237213\n",
      "Iteration 1790: loss -8711.095703125, accuracy 0.07999999821186066\n",
      "Iteration 1800: loss -8063.20556640625, accuracy 0.09000000357627869\n",
      "Iteration 1810: loss -8487.4248046875, accuracy 0.10999999940395355\n",
      "Iteration 1820: loss -9161.861328125, accuracy 0.12999999523162842\n",
      "Iteration 1830: loss -8169.15234375, accuracy 0.07999999821186066\n",
      "Iteration 1840: loss -8260.212890625, accuracy 0.09000000357627869\n",
      "Iteration 1850: loss -8987.1181640625, accuracy 0.09000000357627869\n",
      "Iteration 1860: loss -8659.3818359375, accuracy 0.11999999731779099\n",
      "Iteration 1870: loss -9122.1669921875, accuracy 0.17000000178813934\n",
      "Iteration 1880: loss -8864.4501953125, accuracy 0.15000000596046448\n",
      "Iteration 1890: loss -9170.4287109375, accuracy 0.12999999523162842\n",
      "Iteration 1900: loss -9196.1357421875, accuracy 0.07000000029802322\n",
      "Iteration 1910: loss -8672.3798828125, accuracy 0.07999999821186066\n",
      "Iteration 1920: loss -9141.7666015625, accuracy 0.07000000029802322\n",
      "Iteration 1930: loss -8681.2861328125, accuracy 0.07000000029802322\n",
      "Iteration 1940: loss -8511.6083984375, accuracy 0.10000000149011612\n",
      "Iteration 1950: loss -9251.7900390625, accuracy 0.14000000059604645\n",
      "Iteration 1960: loss -8952.734375, accuracy 0.10999999940395355\n",
      "Iteration 1970: loss -9734.6396484375, accuracy 0.09000000357627869\n",
      "Iteration 1980: loss -9417.49609375, accuracy 0.10000000149011612\n",
      "Iteration 1990: loss -10242.76171875, accuracy 0.07999999821186066\n",
      "Iteration 2000: loss -9520.41015625, accuracy 0.14000000059604645\n",
      "Iteration 2010: loss -9347.3740234375, accuracy 0.07000000029802322\n",
      "Iteration 2020: loss -9784.595703125, accuracy 0.17000000178813934\n",
      "Iteration 2030: loss -9516.0986328125, accuracy 0.10000000149011612\n",
      "Iteration 2040: loss -9678.1533203125, accuracy 0.09000000357627869\n",
      "Iteration 2050: loss -9812.9482421875, accuracy 0.05999999865889549\n",
      "Iteration 2060: loss -9771.638671875, accuracy 0.09000000357627869\n",
      "Iteration 2070: loss -9274.6025390625, accuracy 0.09000000357627869\n",
      "Iteration 2080: loss -9320.9072265625, accuracy 0.07999999821186066\n",
      "Iteration 2090: loss -9123.3857421875, accuracy 0.12999999523162842\n",
      "Iteration 2100: loss -10392.3662109375, accuracy 0.14000000059604645\n",
      "Iteration 2110: loss -9855.244140625, accuracy 0.10999999940395355\n",
      "Iteration 2120: loss -10376.087890625, accuracy 0.09000000357627869\n",
      "Iteration 2130: loss -9945.58203125, accuracy 0.11999999731779099\n",
      "Iteration 2140: loss -9855.1328125, accuracy 0.07999999821186066\n",
      "Iteration 2150: loss -9601.515625, accuracy 0.10000000149011612\n",
      "Iteration 2160: loss -10361.265625, accuracy 0.05999999865889549\n",
      "Iteration 2170: loss -9896.3388671875, accuracy 0.07000000029802322\n",
      "Iteration 2180: loss -10143.4267578125, accuracy 0.07999999821186066\n",
      "Iteration 2190: loss -11290.017578125, accuracy 0.07000000029802322\n",
      "Iteration 2200: loss -10636.349609375, accuracy 0.10000000149011612\n",
      "Iteration 2210: loss -11277.0185546875, accuracy 0.05999999865889549\n",
      "Iteration 2220: loss -10517.8369140625, accuracy 0.07000000029802322\n",
      "Iteration 2230: loss -11082.9384765625, accuracy 0.10999999940395355\n",
      "Iteration 2240: loss -10142.408203125, accuracy 0.10000000149011612\n",
      "Iteration 2250: loss -10382.3984375, accuracy 0.05999999865889549\n",
      "Iteration 2260: loss -10360.630859375, accuracy 0.11999999731779099\n",
      "Iteration 2270: loss -10983.603515625, accuracy 0.11999999731779099\n",
      "Iteration 2280: loss -10354.0048828125, accuracy 0.05000000074505806\n",
      "Iteration 2290: loss -11272.51171875, accuracy 0.10999999940395355\n",
      "Iteration 2300: loss -11084.904296875, accuracy 0.11999999731779099\n",
      "Iteration 2310: loss -11092.2490234375, accuracy 0.10000000149011612\n",
      "Iteration 2320: loss -11400.8095703125, accuracy 0.07999999821186066\n",
      "Iteration 2330: loss -11199.5908203125, accuracy 0.10999999940395355\n",
      "Iteration 2340: loss -11003.7548828125, accuracy 0.10999999940395355\n",
      "Iteration 2350: loss -10946.748046875, accuracy 0.05000000074505806\n",
      "Iteration 2360: loss -10615.9462890625, accuracy 0.10000000149011612\n",
      "Iteration 2370: loss -11326.6494140625, accuracy 0.1899999976158142\n",
      "Iteration 2380: loss -10684.8115234375, accuracy 0.10000000149011612\n",
      "Iteration 2390: loss -11712.4130859375, accuracy 0.10000000149011612\n",
      "Iteration 2400: loss -12068.0439453125, accuracy 0.10999999940395355\n",
      "Iteration 2410: loss -10838.7919921875, accuracy 0.05999999865889549\n",
      "Iteration 2420: loss -12467.7822265625, accuracy 0.05000000074505806\n",
      "Iteration 2430: loss -11470.0693359375, accuracy 0.15000000596046448\n",
      "Iteration 2440: loss -11415.4384765625, accuracy 0.10000000149011612\n",
      "Iteration 2450: loss -11787.1630859375, accuracy 0.05999999865889549\n",
      "Iteration 2460: loss -10835.732421875, accuracy 0.11999999731779099\n",
      "Iteration 2470: loss -11431.091796875, accuracy 0.07999999821186066\n",
      "Iteration 2480: loss -11335.6416015625, accuracy 0.10999999940395355\n",
      "Iteration 2490: loss -11704.2060546875, accuracy 0.12999999523162842\n",
      "Iteration 2500: loss -12516.640625, accuracy 0.10000000149011612\n",
      "Iteration 2510: loss -11254.7158203125, accuracy 0.12999999523162842\n",
      "Iteration 2520: loss -12379.83203125, accuracy 0.11999999731779099\n",
      "Iteration 2530: loss -12239.3046875, accuracy 0.17000000178813934\n",
      "Iteration 2540: loss -11868.423828125, accuracy 0.12999999523162842\n",
      "Iteration 2550: loss -12309.41015625, accuracy 0.10999999940395355\n",
      "Iteration 2560: loss -12573.123046875, accuracy 0.14000000059604645\n",
      "Iteration 2570: loss -12174.7099609375, accuracy 0.15000000596046448\n",
      "Iteration 2580: loss -12399.572265625, accuracy 0.20000000298023224\n",
      "Iteration 2590: loss -11449.064453125, accuracy 0.05999999865889549\n",
      "Iteration 2600: loss -12270.9755859375, accuracy 0.10999999940395355\n",
      "Iteration 2610: loss -13199.06640625, accuracy 0.10000000149011612\n",
      "Iteration 2620: loss -11996.541015625, accuracy 0.07999999821186066\n",
      "Iteration 2630: loss -11869.4384765625, accuracy 0.07999999821186066\n",
      "Iteration 2640: loss -12971.8447265625, accuracy 0.14000000059604645\n",
      "Iteration 2650: loss -13059.703125, accuracy 0.07999999821186066\n",
      "Iteration 2660: loss -12301.7470703125, accuracy 0.05000000074505806\n",
      "Iteration 2670: loss -12403.33984375, accuracy 0.12999999523162842\n",
      "Iteration 2680: loss -13386.9658203125, accuracy 0.07000000029802322\n",
      "Iteration 2690: loss -11885.3837890625, accuracy 0.11999999731779099\n",
      "Iteration 2700: loss -11507.7763671875, accuracy 0.10000000149011612\n",
      "Iteration 2710: loss -13034.5478515625, accuracy 0.03999999910593033\n",
      "Iteration 2720: loss -13763.3251953125, accuracy 0.10000000149011612\n",
      "Iteration 2730: loss -11947.59375, accuracy 0.09000000357627869\n",
      "Iteration 2740: loss -13267.8583984375, accuracy 0.07999999821186066\n",
      "Iteration 2750: loss -13456.623046875, accuracy 0.07000000029802322\n",
      "Iteration 2760: loss -12690.4716796875, accuracy 0.11999999731779099\n",
      "Iteration 2770: loss -11731.6357421875, accuracy 0.11999999731779099\n",
      "Iteration 2780: loss -12520.8251953125, accuracy 0.09000000357627869\n",
      "Iteration 2790: loss -12793.927734375, accuracy 0.05000000074505806\n",
      "Iteration 2800: loss -14159.09765625, accuracy 0.10000000149011612\n",
      "Iteration 2810: loss -13306.8369140625, accuracy 0.10000000149011612\n",
      "Iteration 2820: loss -12944.3916015625, accuracy 0.029999999329447746\n",
      "Iteration 2830: loss -13263.4736328125, accuracy 0.11999999731779099\n",
      "Iteration 2840: loss -13406.41796875, accuracy 0.10999999940395355\n",
      "Iteration 2850: loss -13331.8642578125, accuracy 0.11999999731779099\n",
      "Iteration 2860: loss -13048.3330078125, accuracy 0.05999999865889549\n",
      "Iteration 2870: loss -14133.8935546875, accuracy 0.14000000059604645\n",
      "Iteration 2880: loss -14314.20703125, accuracy 0.10999999940395355\n",
      "Iteration 2890: loss -13567.5810546875, accuracy 0.07000000029802322\n",
      "Iteration 2900: loss -13433.9228515625, accuracy 0.07999999821186066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2910: loss -14267.1220703125, accuracy 0.10000000149011612\n",
      "Iteration 2920: loss -13860.505859375, accuracy 0.07999999821186066\n",
      "Iteration 2930: loss -13109.4296875, accuracy 0.12999999523162842\n",
      "Iteration 2940: loss -13716.53125, accuracy 0.05999999865889549\n",
      "Iteration 2950: loss -13432.6064453125, accuracy 0.15000000596046448\n",
      "Iteration 2960: loss -14799.5654296875, accuracy 0.05000000074505806\n",
      "Iteration 2970: loss -13761.197265625, accuracy 0.07999999821186066\n",
      "Iteration 2980: loss -14863.63671875, accuracy 0.14000000059604645\n",
      "Iteration 2990: loss -14983.73828125, accuracy 0.05000000074505806\n",
      "Iteration 3000: loss -13887.353515625, accuracy 0.1599999964237213\n",
      "Iteration 3010: loss -13979.0439453125, accuracy 0.14000000059604645\n",
      "Iteration 3020: loss -15206.4736328125, accuracy 0.12999999523162842\n",
      "Iteration 3030: loss -14173.0830078125, accuracy 0.09000000357627869\n",
      "Iteration 3040: loss -14546.89453125, accuracy 0.10000000149011612\n",
      "Iteration 3050: loss -13793.9697265625, accuracy 0.10999999940395355\n",
      "Iteration 3060: loss -14251.982421875, accuracy 0.09000000357627869\n",
      "Iteration 3070: loss -13709.7509765625, accuracy 0.05000000074505806\n",
      "Iteration 3080: loss -14831.3720703125, accuracy 0.12999999523162842\n",
      "Iteration 3090: loss -14301.6943359375, accuracy 0.12999999523162842\n",
      "Iteration 3100: loss -14432.041015625, accuracy 0.17000000178813934\n",
      "Iteration 3110: loss -15256.4423828125, accuracy 0.05999999865889549\n",
      "Iteration 3120: loss -14429.126953125, accuracy 0.10000000149011612\n",
      "Iteration 3130: loss -14666.2216796875, accuracy 0.10000000149011612\n",
      "Iteration 3140: loss -14941.3876953125, accuracy 0.10000000149011612\n",
      "Iteration 3150: loss -16117.7890625, accuracy 0.07000000029802322\n",
      "Iteration 3160: loss -15720.3662109375, accuracy 0.09000000357627869\n",
      "Iteration 3170: loss -14353.73828125, accuracy 0.07999999821186066\n",
      "Iteration 3180: loss -15117.537109375, accuracy 0.07999999821186066\n",
      "Iteration 3190: loss -14731.4775390625, accuracy 0.07999999821186066\n",
      "Iteration 3200: loss -15348.9501953125, accuracy 0.10999999940395355\n",
      "Iteration 3210: loss -14978.3154296875, accuracy 0.05000000074505806\n",
      "Iteration 3220: loss -14262.0673828125, accuracy 0.05999999865889549\n",
      "Iteration 3230: loss -15359.0009765625, accuracy 0.1599999964237213\n",
      "Iteration 3240: loss -14801.521484375, accuracy 0.09000000357627869\n",
      "Iteration 3250: loss -14201.6416015625, accuracy 0.10999999940395355\n",
      "Iteration 3260: loss -15299.4404296875, accuracy 0.15000000596046448\n",
      "Iteration 3270: loss -15951.4404296875, accuracy 0.09000000357627869\n",
      "Iteration 3280: loss -15769.8056640625, accuracy 0.10000000149011612\n",
      "Iteration 3290: loss -16336.0224609375, accuracy 0.07999999821186066\n",
      "Iteration 3300: loss -15650.009765625, accuracy 0.07000000029802322\n",
      "Iteration 3310: loss -14029.443359375, accuracy 0.07999999821186066\n",
      "Iteration 3320: loss -14952.4736328125, accuracy 0.03999999910593033\n",
      "Iteration 3330: loss -14731.8359375, accuracy 0.09000000357627869\n",
      "Iteration 3340: loss -16585.55078125, accuracy 0.09000000357627869\n",
      "Iteration 3350: loss -16228.4130859375, accuracy 0.10999999940395355\n",
      "Iteration 3360: loss -16774.03515625, accuracy 0.11999999731779099\n",
      "Iteration 3370: loss -15613.455078125, accuracy 0.05000000074505806\n",
      "Iteration 3380: loss -16576.99609375, accuracy 0.11999999731779099\n",
      "Iteration 3390: loss -15902.9697265625, accuracy 0.07000000029802322\n",
      "Iteration 3400: loss -15511.9638671875, accuracy 0.10999999940395355\n",
      "Iteration 3410: loss -15792.3642578125, accuracy 0.07999999821186066\n",
      "Iteration 3420: loss -16216.43359375, accuracy 0.09000000357627869\n",
      "Iteration 3430: loss -15997.3623046875, accuracy 0.12999999523162842\n",
      "Iteration 3440: loss -16612.8515625, accuracy 0.10000000149011612\n",
      "Iteration 3450: loss -16351.3759765625, accuracy 0.10999999940395355\n",
      "Iteration 3460: loss -15821.431640625, accuracy 0.10999999940395355\n",
      "Iteration 3470: loss -16918.607421875, accuracy 0.05999999865889549\n",
      "Iteration 3480: loss -15843.890625, accuracy 0.1599999964237213\n",
      "Iteration 3490: loss -16095.6474609375, accuracy 0.07999999821186066\n",
      "Iteration 3500: loss -15300.982421875, accuracy 0.07000000029802322\n",
      "Iteration 3510: loss -16514.90234375, accuracy 0.09000000357627869\n",
      "Iteration 3520: loss -16347.1943359375, accuracy 0.07999999821186066\n",
      "Iteration 3530: loss -17851.81640625, accuracy 0.17000000178813934\n",
      "Iteration 3540: loss -16132.27734375, accuracy 0.09000000357627869\n",
      "Iteration 3550: loss -17726.46875, accuracy 0.10000000149011612\n",
      "Iteration 3560: loss -17258.20703125, accuracy 0.07000000029802322\n",
      "Iteration 3570: loss -15783.595703125, accuracy 0.10000000149011612\n",
      "Iteration 3580: loss -17121.3359375, accuracy 0.12999999523162842\n",
      "Iteration 3590: loss -15769.2958984375, accuracy 0.07999999821186066\n",
      "Iteration 3600: loss -18383.70703125, accuracy 0.07000000029802322\n",
      "Iteration 3610: loss -16233.623046875, accuracy 0.019999999552965164\n",
      "Iteration 3620: loss -17568.69140625, accuracy 0.07000000029802322\n",
      "Iteration 3630: loss -17147.9765625, accuracy 0.11999999731779099\n",
      "Iteration 3640: loss -17810.01953125, accuracy 0.10000000149011612\n",
      "Iteration 3650: loss -17489.388671875, accuracy 0.12999999523162842\n",
      "Iteration 3660: loss -16850.666015625, accuracy 0.03999999910593033\n",
      "Iteration 3670: loss -17901.18359375, accuracy 0.15000000596046448\n",
      "Iteration 3680: loss -16894.990234375, accuracy 0.11999999731779099\n",
      "Iteration 3690: loss -18095.34765625, accuracy 0.07000000029802322\n",
      "Iteration 3700: loss -18058.1796875, accuracy 0.05999999865889549\n",
      "Iteration 3710: loss -18170.48828125, accuracy 0.10000000149011612\n",
      "Iteration 3720: loss -17096.80859375, accuracy 0.07999999821186066\n",
      "Iteration 3730: loss -18193.1171875, accuracy 0.05999999865889549\n",
      "Iteration 3740: loss -17259.8984375, accuracy 0.05999999865889549\n",
      "Iteration 3750: loss -17860.64453125, accuracy 0.07999999821186066\n",
      "Iteration 3760: loss -17262.189453125, accuracy 0.11999999731779099\n",
      "Iteration 3770: loss -16554.58203125, accuracy 0.10999999940395355\n",
      "Iteration 3780: loss -17708.92578125, accuracy 0.10999999940395355\n",
      "Iteration 3790: loss -18812.3359375, accuracy 0.14000000059604645\n",
      "Iteration 3800: loss -18352.232421875, accuracy 0.10000000149011612\n",
      "Iteration 3810: loss -17840.724609375, accuracy 0.14000000059604645\n",
      "Iteration 3820: loss -17780.333984375, accuracy 0.11999999731779099\n",
      "Iteration 3830: loss -17993.513671875, accuracy 0.07999999821186066\n",
      "Iteration 3840: loss -18437.88671875, accuracy 0.12999999523162842\n",
      "Iteration 3850: loss -17989.8828125, accuracy 0.05999999865889549\n",
      "Iteration 3860: loss -19205.48046875, accuracy 0.09000000357627869\n",
      "Iteration 3870: loss -19339.900390625, accuracy 0.15000000596046448\n",
      "Iteration 3880: loss -17335.0859375, accuracy 0.10000000149011612\n",
      "Iteration 3890: loss -18346.267578125, accuracy 0.07999999821186066\n",
      "Iteration 3900: loss -17527.94921875, accuracy 0.10000000149011612\n",
      "Iteration 3910: loss -17812.69140625, accuracy 0.11999999731779099\n",
      "Iteration 3920: loss -18990.005859375, accuracy 0.07000000029802322\n",
      "Iteration 3930: loss -18868.330078125, accuracy 0.09000000357627869\n",
      "Iteration 3940: loss -19969.279296875, accuracy 0.11999999731779099\n",
      "Iteration 3950: loss -19355.087890625, accuracy 0.05999999865889549\n",
      "Iteration 3960: loss -18241.232421875, accuracy 0.10000000149011612\n",
      "Iteration 3970: loss -19799.15625, accuracy 0.10000000149011612\n",
      "Iteration 3980: loss -18019.97265625, accuracy 0.09000000357627869\n",
      "Iteration 3990: loss -17844.154296875, accuracy 0.14000000059604645\n",
      "Iteration 4000: loss -18056.642578125, accuracy 0.10000000149011612\n",
      "Iteration 4010: loss -18502.09765625, accuracy 0.07999999821186066\n",
      "Iteration 4020: loss -19107.681640625, accuracy 0.07999999821186066\n",
      "Iteration 4030: loss -20176.86328125, accuracy 0.05999999865889549\n",
      "Iteration 4040: loss -19636.048828125, accuracy 0.07999999821186066\n",
      "Iteration 4050: loss -18596.03125, accuracy 0.14000000059604645\n",
      "Iteration 4060: loss -19213.5, accuracy 0.09000000357627869\n",
      "Iteration 4070: loss -17774.271484375, accuracy 0.12999999523162842\n",
      "Iteration 4080: loss -21018.712890625, accuracy 0.10999999940395355\n",
      "Iteration 4090: loss -19259.240234375, accuracy 0.14000000059604645\n",
      "Iteration 4100: loss -20389.81640625, accuracy 0.10000000149011612\n",
      "Iteration 4110: loss -19028.912109375, accuracy 0.05999999865889549\n",
      "Iteration 4120: loss -19467.453125, accuracy 0.05999999865889549\n",
      "Iteration 4130: loss -19014.0390625, accuracy 0.10000000149011612\n",
      "Iteration 4140: loss -18267.6875, accuracy 0.14000000059604645\n",
      "Iteration 4150: loss -19541.87109375, accuracy 0.09000000357627869\n",
      "Iteration 4160: loss -20035.955078125, accuracy 0.10999999940395355\n",
      "Iteration 4170: loss -17879.455078125, accuracy 0.09000000357627869\n",
      "Iteration 4180: loss -20308.23046875, accuracy 0.07999999821186066\n",
      "Iteration 4190: loss -20787.564453125, accuracy 0.07999999821186066\n",
      "Iteration 4200: loss -19299.517578125, accuracy 0.05000000074505806\n",
      "Iteration 4210: loss -20395.587890625, accuracy 0.14000000059604645\n",
      "Iteration 4220: loss -19708.494140625, accuracy 0.10999999940395355\n",
      "Iteration 4230: loss -18991.11328125, accuracy 0.10999999940395355\n",
      "Iteration 4240: loss -20073.51171875, accuracy 0.10000000149011612\n",
      "Iteration 4250: loss -19812.822265625, accuracy 0.09000000357627869\n",
      "Iteration 4260: loss -20718.345703125, accuracy 0.1599999964237213\n",
      "Iteration 4270: loss -20173.244140625, accuracy 0.09000000357627869\n",
      "Iteration 4280: loss -21477.18359375, accuracy 0.10000000149011612\n",
      "Iteration 4290: loss -20767.61328125, accuracy 0.07999999821186066\n",
      "Iteration 4300: loss -20000.55859375, accuracy 0.11999999731779099\n",
      "Iteration 4310: loss -20863.423828125, accuracy 0.07999999821186066\n",
      "Iteration 4320: loss -20358.8203125, accuracy 0.07000000029802322\n",
      "Iteration 4330: loss -19545.275390625, accuracy 0.07000000029802322\n",
      "Iteration 4340: loss -20253.986328125, accuracy 0.10999999940395355\n",
      "Iteration 4350: loss -20226.45703125, accuracy 0.07999999821186066\n",
      "Iteration 4360: loss -20835.904296875, accuracy 0.09000000357627869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4370: loss -21156.87890625, accuracy 0.10999999940395355\n",
      "Iteration 4380: loss -20921.1953125, accuracy 0.10000000149011612\n",
      "Iteration 4390: loss -20621.802734375, accuracy 0.07999999821186066\n",
      "Iteration 4400: loss -21739.935546875, accuracy 0.10000000149011612\n",
      "Iteration 4410: loss -22307.060546875, accuracy 0.10999999940395355\n",
      "Iteration 4420: loss -22732.927734375, accuracy 0.15000000596046448\n",
      "Iteration 4430: loss -20397.900390625, accuracy 0.07999999821186066\n",
      "Iteration 4440: loss -21387.796875, accuracy 0.10000000149011612\n",
      "Iteration 4450: loss -19922.064453125, accuracy 0.09000000357627869\n",
      "Iteration 4460: loss -21500.736328125, accuracy 0.12999999523162842\n",
      "Iteration 4470: loss -20916.337890625, accuracy 0.05999999865889549\n",
      "Iteration 4480: loss -22431.0625, accuracy 0.09000000357627869\n",
      "Iteration 4490: loss -21270.818359375, accuracy 0.019999999552965164\n",
      "Iteration 4500: loss -20820.46484375, accuracy 0.10000000149011612\n",
      "Iteration 4510: loss -21350.46484375, accuracy 0.07999999821186066\n",
      "Iteration 4520: loss -20774.484375, accuracy 0.09000000357627869\n",
      "Iteration 4530: loss -22257.7734375, accuracy 0.03999999910593033\n",
      "Iteration 4540: loss -21975.576171875, accuracy 0.10999999940395355\n",
      "Iteration 4550: loss -22061.03515625, accuracy 0.05000000074505806\n",
      "Iteration 4560: loss -22932.966796875, accuracy 0.18000000715255737\n",
      "Iteration 4570: loss -20484.234375, accuracy 0.10000000149011612\n",
      "Iteration 4580: loss -21604.49609375, accuracy 0.14000000059604645\n",
      "Iteration 4590: loss -22205.884765625, accuracy 0.07999999821186066\n",
      "Iteration 4600: loss -21782.6953125, accuracy 0.07999999821186066\n",
      "Iteration 4610: loss -22535.642578125, accuracy 0.09000000357627869\n",
      "Iteration 4620: loss -20827.46484375, accuracy 0.11999999731779099\n",
      "Iteration 4630: loss -23633.97265625, accuracy 0.11999999731779099\n",
      "Iteration 4640: loss -21956.12890625, accuracy 0.11999999731779099\n",
      "Iteration 4650: loss -22160.734375, accuracy 0.07999999821186066\n",
      "Iteration 4660: loss -21839.392578125, accuracy 0.07999999821186066\n",
      "Iteration 4670: loss -21872.4765625, accuracy 0.10000000149011612\n",
      "Iteration 4680: loss -21869.5234375, accuracy 0.11999999731779099\n",
      "Iteration 4690: loss -22877.95703125, accuracy 0.07999999821186066\n",
      "Iteration 4700: loss -22115.783203125, accuracy 0.11999999731779099\n",
      "Iteration 4710: loss -22476.35546875, accuracy 0.10000000149011612\n",
      "Iteration 4720: loss -24381.912109375, accuracy 0.07000000029802322\n",
      "Iteration 4730: loss -22717.75, accuracy 0.14000000059604645\n",
      "Iteration 4740: loss -21491.828125, accuracy 0.07999999821186066\n",
      "Iteration 4750: loss -21888.134765625, accuracy 0.07999999821186066\n",
      "Iteration 4760: loss -23572.0078125, accuracy 0.09000000357627869\n",
      "Iteration 4770: loss -22800.30859375, accuracy 0.07999999821186066\n",
      "Iteration 4780: loss -23951.095703125, accuracy 0.07000000029802322\n",
      "Iteration 4790: loss -22548.1640625, accuracy 0.10999999940395355\n",
      "Iteration 4800: loss -24285.052734375, accuracy 0.11999999731779099\n",
      "Iteration 4810: loss -23049.982421875, accuracy 0.18000000715255737\n",
      "Iteration 4820: loss -22183.921875, accuracy 0.07999999821186066\n",
      "Iteration 4830: loss -23979.779296875, accuracy 0.10999999940395355\n",
      "Iteration 4840: loss -22754.5078125, accuracy 0.09000000357627869\n",
      "Iteration 4850: loss -24072.13671875, accuracy 0.09000000357627869\n",
      "Iteration 4860: loss -21824.603515625, accuracy 0.1599999964237213\n",
      "Iteration 4870: loss -23107.19140625, accuracy 0.10999999940395355\n",
      "Iteration 4880: loss -23045.111328125, accuracy 0.10999999940395355\n",
      "Iteration 4890: loss -23242.44140625, accuracy 0.14000000059604645\n",
      "Iteration 4900: loss -23365.716796875, accuracy 0.12999999523162842\n",
      "Iteration 4910: loss -23143.11328125, accuracy 0.10000000149011612\n",
      "Iteration 4920: loss -23088.10546875, accuracy 0.09000000357627869\n",
      "Iteration 4930: loss -23899.119140625, accuracy 0.09000000357627869\n",
      "Iteration 4940: loss -22338.931640625, accuracy 0.029999999329447746\n",
      "Iteration 4950: loss -23864.373046875, accuracy 0.09000000357627869\n",
      "Iteration 4960: loss -23382.236328125, accuracy 0.07000000029802322\n",
      "Iteration 4970: loss -21606.54296875, accuracy 0.07999999821186066\n",
      "Iteration 4980: loss -23761.640625, accuracy 0.07999999821186066\n",
      "Iteration 4990: loss -22319.92578125, accuracy 0.10999999940395355\n",
      "Iteration 5000: loss -24529.888671875, accuracy 0.12999999523162842\n",
      "Iteration 5010: loss -24429.79296875, accuracy 0.07000000029802322\n",
      "Iteration 5020: loss -23383.626953125, accuracy 0.05999999865889549\n",
      "Iteration 5030: loss -24867.2421875, accuracy 0.10000000149011612\n",
      "Iteration 5040: loss -23605.3828125, accuracy 0.05999999865889549\n",
      "Iteration 5050: loss -21935.232421875, accuracy 0.09000000357627869\n",
      "Iteration 5060: loss -23623.064453125, accuracy 0.07999999821186066\n",
      "Iteration 5070: loss -23897.14453125, accuracy 0.10000000149011612\n",
      "Iteration 5080: loss -23590.99609375, accuracy 0.15000000596046448\n",
      "Iteration 5090: loss -24063.611328125, accuracy 0.11999999731779099\n",
      "Iteration 5100: loss -24196.080078125, accuracy 0.10999999940395355\n",
      "Iteration 5110: loss -24244.9140625, accuracy 0.07000000029802322\n",
      "Iteration 5120: loss -25458.830078125, accuracy 0.1599999964237213\n",
      "Iteration 5130: loss -22281.9609375, accuracy 0.10999999940395355\n",
      "Iteration 5140: loss -23772.6484375, accuracy 0.10999999940395355\n",
      "Iteration 5150: loss -26362.6015625, accuracy 0.11999999731779099\n",
      "Iteration 5160: loss -23860.40625, accuracy 0.10999999940395355\n",
      "Iteration 5170: loss -23620.05078125, accuracy 0.11999999731779099\n",
      "Iteration 5180: loss -23820.951171875, accuracy 0.07999999821186066\n",
      "Iteration 5190: loss -25286.197265625, accuracy 0.07999999821186066\n",
      "Iteration 5200: loss -25206.990234375, accuracy 0.07000000029802322\n",
      "Iteration 5210: loss -24319.556640625, accuracy 0.14000000059604645\n",
      "Iteration 5220: loss -25178.69921875, accuracy 0.05999999865889549\n",
      "Iteration 5230: loss -24989.630859375, accuracy 0.10999999940395355\n",
      "Iteration 5240: loss -25095.818359375, accuracy 0.07999999821186066\n",
      "Iteration 5250: loss -25441.072265625, accuracy 0.05999999865889549\n",
      "Iteration 5260: loss -25352.7109375, accuracy 0.07999999821186066\n",
      "Iteration 5270: loss -25061.078125, accuracy 0.07999999821186066\n",
      "Iteration 5280: loss -25814.388671875, accuracy 0.07000000029802322\n",
      "Iteration 5290: loss -25561.423828125, accuracy 0.10999999940395355\n",
      "Iteration 5300: loss -24890.47265625, accuracy 0.10000000149011612\n",
      "Iteration 5310: loss -26325.15625, accuracy 0.12999999523162842\n",
      "Iteration 5320: loss -25656.59375, accuracy 0.07000000029802322\n",
      "Iteration 5330: loss -25478.615234375, accuracy 0.09000000357627869\n",
      "Iteration 5340: loss -25602.783203125, accuracy 0.07000000029802322\n",
      "Iteration 5350: loss -25723.451171875, accuracy 0.07000000029802322\n",
      "Iteration 5360: loss -22550.33984375, accuracy 0.07000000029802322\n",
      "Iteration 5370: loss -26350.45703125, accuracy 0.07999999821186066\n",
      "Iteration 5380: loss -26763.02734375, accuracy 0.10999999940395355\n",
      "Iteration 5390: loss -25057.630859375, accuracy 0.10999999940395355\n",
      "Iteration 5400: loss -25253.056640625, accuracy 0.07999999821186066\n",
      "Iteration 5410: loss -24630.359375, accuracy 0.11999999731779099\n",
      "Iteration 5420: loss -24296.923828125, accuracy 0.09000000357627869\n",
      "Iteration 5430: loss -25640.390625, accuracy 0.14000000059604645\n",
      "Iteration 5440: loss -24569.462890625, accuracy 0.11999999731779099\n",
      "Iteration 5450: loss -25351.359375, accuracy 0.07999999821186066\n",
      "Iteration 5460: loss -27591.03515625, accuracy 0.10999999940395355\n",
      "Iteration 5470: loss -25781.51171875, accuracy 0.14000000059604645\n",
      "Iteration 5480: loss -25159.63671875, accuracy 0.10000000149011612\n",
      "Iteration 5490: loss -25598.8828125, accuracy 0.12999999523162842\n",
      "Iteration 5500: loss -25449.79296875, accuracy 0.11999999731779099\n",
      "Iteration 5510: loss -23950.78515625, accuracy 0.14000000059604645\n",
      "Iteration 5520: loss -26357.66796875, accuracy 0.1599999964237213\n",
      "Iteration 5530: loss -27175.96875, accuracy 0.09000000357627869\n",
      "Iteration 5540: loss -26239.083984375, accuracy 0.07000000029802322\n",
      "Iteration 5550: loss -28122.9765625, accuracy 0.14000000059604645\n",
      "Iteration 5560: loss -26683.70703125, accuracy 0.11999999731779099\n",
      "Iteration 5570: loss -27730.1015625, accuracy 0.05999999865889549\n",
      "Iteration 5580: loss -26072.748046875, accuracy 0.10000000149011612\n",
      "Iteration 5590: loss -26307.412109375, accuracy 0.07000000029802322\n",
      "Iteration 5600: loss -26667.8203125, accuracy 0.14000000059604645\n",
      "Iteration 5610: loss -26273.140625, accuracy 0.10000000149011612\n",
      "Iteration 5620: loss -27659.62890625, accuracy 0.11999999731779099\n",
      "Iteration 5630: loss -26605.98046875, accuracy 0.09000000357627869\n",
      "Iteration 5640: loss -26903.548828125, accuracy 0.10999999940395355\n",
      "Iteration 5650: loss -28259.365234375, accuracy 0.09000000357627869\n",
      "Iteration 5660: loss -26326.619140625, accuracy 0.15000000596046448\n",
      "Iteration 5670: loss -26851.767578125, accuracy 0.09000000357627869\n",
      "Iteration 5680: loss -28859.36328125, accuracy 0.12999999523162842\n",
      "Iteration 5690: loss -27268.728515625, accuracy 0.10999999940395355\n",
      "Iteration 5700: loss -29046.427734375, accuracy 0.10999999940395355\n",
      "Iteration 5710: loss -26198.615234375, accuracy 0.14000000059604645\n",
      "Iteration 5720: loss -26980.5234375, accuracy 0.10000000149011612\n",
      "Iteration 5730: loss -27097.796875, accuracy 0.12999999523162842\n",
      "Iteration 5740: loss -26185.294921875, accuracy 0.11999999731779099\n",
      "Iteration 5750: loss -26043.337890625, accuracy 0.05999999865889549\n",
      "Iteration 5760: loss -28254.82421875, accuracy 0.07999999821186066\n",
      "Iteration 5770: loss -26523.7890625, accuracy 0.10999999940395355\n",
      "Iteration 5780: loss -27836.154296875, accuracy 0.12999999523162842\n",
      "Iteration 5790: loss -28666.3046875, accuracy 0.07999999821186066\n",
      "Iteration 5800: loss -27784.935546875, accuracy 0.05000000074505806\n",
      "Iteration 5810: loss -28294.205078125, accuracy 0.10999999940395355\n",
      "Iteration 5820: loss -28663.021484375, accuracy 0.10000000149011612\n",
      "Iteration 5830: loss -27329.140625, accuracy 0.10000000149011612\n",
      "Iteration 5840: loss -27506.54296875, accuracy 0.11999999731779099\n",
      "Iteration 5850: loss -27554.265625, accuracy 0.10000000149011612\n",
      "Iteration 5860: loss -27698.85546875, accuracy 0.12999999523162842\n",
      "Iteration 5870: loss -26221.771484375, accuracy 0.07000000029802322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5880: loss -26180.26171875, accuracy 0.11999999731779099\n",
      "Iteration 5890: loss -27344.16796875, accuracy 0.07999999821186066\n",
      "Iteration 5900: loss -26452.677734375, accuracy 0.11999999731779099\n",
      "Iteration 5910: loss -26210.5859375, accuracy 0.15000000596046448\n",
      "Iteration 5920: loss -27270.73046875, accuracy 0.10999999940395355\n",
      "Iteration 5930: loss -27018.25390625, accuracy 0.12999999523162842\n",
      "Iteration 5940: loss -26414.16015625, accuracy 0.11999999731779099\n",
      "Iteration 5950: loss -29689.66796875, accuracy 0.14000000059604645\n",
      "Iteration 5960: loss -28485.63671875, accuracy 0.12999999523162842\n",
      "Iteration 5970: loss -29803.451171875, accuracy 0.05999999865889549\n",
      "Iteration 5980: loss -26419.8046875, accuracy 0.10000000149011612\n",
      "Iteration 5990: loss -28067.474609375, accuracy 0.09000000357627869\n",
      "Iteration 6000: loss -28026.435546875, accuracy 0.09000000357627869\n",
      "Iteration 6010: loss -27660.783203125, accuracy 0.15000000596046448\n",
      "Iteration 6020: loss -25932.427734375, accuracy 0.09000000357627869\n",
      "Iteration 6030: loss -26888.095703125, accuracy 0.05999999865889549\n",
      "Iteration 6040: loss -31136.0390625, accuracy 0.07999999821186066\n",
      "Iteration 6050: loss -29583.123046875, accuracy 0.10000000149011612\n",
      "Iteration 6060: loss -29762.1875, accuracy 0.10999999940395355\n",
      "Iteration 6070: loss -27188.712890625, accuracy 0.11999999731779099\n",
      "Iteration 6080: loss -28676.8671875, accuracy 0.09000000357627869\n",
      "Iteration 6090: loss -28050.876953125, accuracy 0.12999999523162842\n",
      "Iteration 6100: loss -29142.41015625, accuracy 0.07999999821186066\n",
      "Iteration 6110: loss -29891.59765625, accuracy 0.14000000059604645\n",
      "Iteration 6120: loss -29049.548828125, accuracy 0.07999999821186066\n",
      "Iteration 6130: loss -29335.1171875, accuracy 0.05999999865889549\n",
      "Iteration 6140: loss -29537.072265625, accuracy 0.07999999821186066\n",
      "Iteration 6150: loss -29242.603515625, accuracy 0.09000000357627869\n",
      "Iteration 6160: loss -28994.09765625, accuracy 0.07999999821186066\n",
      "Iteration 6170: loss -32021.1484375, accuracy 0.11999999731779099\n",
      "Iteration 6180: loss -28279.484375, accuracy 0.07999999821186066\n",
      "Iteration 6190: loss -29189.966796875, accuracy 0.07000000029802322\n",
      "Iteration 6200: loss -26866.064453125, accuracy 0.07999999821186066\n",
      "Iteration 6210: loss -30571.376953125, accuracy 0.12999999523162842\n",
      "Iteration 6220: loss -27746.474609375, accuracy 0.12999999523162842\n",
      "Iteration 6230: loss -29098.298828125, accuracy 0.09000000357627869\n",
      "Iteration 6240: loss -29692.8125, accuracy 0.10000000149011612\n",
      "Iteration 6250: loss -29263.044921875, accuracy 0.11999999731779099\n",
      "Iteration 6260: loss -30260.724609375, accuracy 0.07999999821186066\n",
      "Iteration 6270: loss -29159.232421875, accuracy 0.07999999821186066\n",
      "Iteration 6280: loss -32054.66796875, accuracy 0.07999999821186066\n",
      "Iteration 6290: loss -31773.859375, accuracy 0.09000000357627869\n",
      "Iteration 6300: loss -27927.8046875, accuracy 0.07000000029802322\n",
      "Iteration 6310: loss -28162.048828125, accuracy 0.05999999865889549\n",
      "Iteration 6320: loss -29611.908203125, accuracy 0.11999999731779099\n",
      "Iteration 6330: loss -30262.0234375, accuracy 0.10000000149011612\n",
      "Iteration 6340: loss -31775.1875, accuracy 0.14000000059604645\n",
      "Iteration 6350: loss -28495.0078125, accuracy 0.07999999821186066\n",
      "Iteration 6360: loss -30645.79296875, accuracy 0.12999999523162842\n",
      "Iteration 6370: loss -29144.486328125, accuracy 0.07000000029802322\n",
      "Iteration 6380: loss -29156.767578125, accuracy 0.10999999940395355\n",
      "Iteration 6390: loss -30905.2890625, accuracy 0.11999999731779099\n",
      "Iteration 6400: loss -31559.0234375, accuracy 0.09000000357627869\n",
      "Iteration 6410: loss -30556.29296875, accuracy 0.14000000059604645\n",
      "Iteration 6420: loss -30990.328125, accuracy 0.09000000357627869\n",
      "Iteration 6430: loss -27586.455078125, accuracy 0.14000000059604645\n",
      "Iteration 6440: loss -29683.296875, accuracy 0.12999999523162842\n",
      "Iteration 6450: loss -30457.576171875, accuracy 0.10000000149011612\n",
      "Iteration 6460: loss -33778.69140625, accuracy 0.09000000357627869\n",
      "Iteration 6470: loss -29121.845703125, accuracy 0.14000000059604645\n",
      "Iteration 6480: loss -31376.1015625, accuracy 0.07999999821186066\n",
      "Iteration 6490: loss -33557.55859375, accuracy 0.14000000059604645\n",
      "Iteration 6500: loss -30847.283203125, accuracy 0.11999999731779099\n",
      "Iteration 6510: loss -31911.10546875, accuracy 0.05000000074505806\n",
      "Iteration 6520: loss -30676.26953125, accuracy 0.09000000357627869\n",
      "Iteration 6530: loss -29565.115234375, accuracy 0.09000000357627869\n",
      "Iteration 6540: loss -30850.896484375, accuracy 0.10999999940395355\n",
      "Iteration 6550: loss -31063.48046875, accuracy 0.09000000357627869\n",
      "Iteration 6560: loss -32311.912109375, accuracy 0.07000000029802322\n",
      "Iteration 6570: loss -30173.78125, accuracy 0.10999999940395355\n",
      "Iteration 6580: loss -30518.818359375, accuracy 0.05000000074505806\n",
      "Iteration 6590: loss -32695.69140625, accuracy 0.07000000029802322\n",
      "Iteration 6600: loss -30849.47265625, accuracy 0.07000000029802322\n",
      "Iteration 6610: loss -32346.31640625, accuracy 0.12999999523162842\n",
      "Iteration 6620: loss -31251.451171875, accuracy 0.10999999940395355\n",
      "Iteration 6630: loss -33149.328125, accuracy 0.12999999523162842\n",
      "Iteration 6640: loss -30342.767578125, accuracy 0.14000000059604645\n",
      "Iteration 6650: loss -31055.599609375, accuracy 0.10999999940395355\n",
      "Iteration 6660: loss -30913.328125, accuracy 0.07000000029802322\n",
      "Iteration 6670: loss -29513.6953125, accuracy 0.07000000029802322\n",
      "Iteration 6680: loss -30249.3203125, accuracy 0.14000000059604645\n",
      "Iteration 6690: loss -32927.55078125, accuracy 0.09000000357627869\n",
      "Iteration 6700: loss -35595.9453125, accuracy 0.07000000029802322\n",
      "Iteration 6710: loss -32269.267578125, accuracy 0.10999999940395355\n",
      "Iteration 6720: loss -33328.6875, accuracy 0.07000000029802322\n",
      "Iteration 6730: loss -32847.34375, accuracy 0.15000000596046448\n",
      "Iteration 6740: loss -34036.875, accuracy 0.10999999940395355\n",
      "Iteration 6750: loss -31585.8828125, accuracy 0.09000000357627869\n",
      "Iteration 6760: loss -32553.755859375, accuracy 0.09000000357627869\n",
      "Iteration 6770: loss -33282.80859375, accuracy 0.07999999821186066\n",
      "Iteration 6780: loss -33586.78515625, accuracy 0.12999999523162842\n",
      "Iteration 6790: loss -30569.8203125, accuracy 0.10000000149011612\n",
      "Iteration 6800: loss -33203.6484375, accuracy 0.07999999821186066\n",
      "Iteration 6810: loss -31588.515625, accuracy 0.09000000357627869\n",
      "Iteration 6820: loss -31510.41015625, accuracy 0.05000000074505806\n",
      "Iteration 6830: loss -31155.1953125, accuracy 0.09000000357627869\n",
      "Iteration 6840: loss -32785.90625, accuracy 0.11999999731779099\n",
      "Iteration 6850: loss -29874.58984375, accuracy 0.03999999910593033\n",
      "Iteration 6860: loss -32855.8203125, accuracy 0.07999999821186066\n",
      "Iteration 6870: loss -32943.46875, accuracy 0.09000000357627869\n",
      "Iteration 6880: loss -34636.9453125, accuracy 0.07999999821186066\n",
      "Iteration 6890: loss -33923.26953125, accuracy 0.11999999731779099\n",
      "Iteration 6900: loss -31071.328125, accuracy 0.10000000149011612\n",
      "Iteration 6910: loss -33790.77734375, accuracy 0.14000000059604645\n",
      "Iteration 6920: loss -34288.16015625, accuracy 0.14000000059604645\n",
      "Iteration 6930: loss -30339.814453125, accuracy 0.03999999910593033\n",
      "Iteration 6940: loss -30287.919921875, accuracy 0.10000000149011612\n",
      "Iteration 6950: loss -33079.14453125, accuracy 0.09000000357627869\n",
      "Iteration 6960: loss -31336.576171875, accuracy 0.11999999731779099\n",
      "Iteration 6970: loss -32853.15625, accuracy 0.17000000178813934\n",
      "Iteration 6980: loss -35314.125, accuracy 0.029999999329447746\n",
      "Iteration 6990: loss -32687.15234375, accuracy 0.10999999940395355\n",
      "Iteration 7000: loss -32378.685546875, accuracy 0.05000000074505806\n",
      "Iteration 7010: loss -34440.84765625, accuracy 0.11999999731779099\n",
      "Iteration 7020: loss -33954.23828125, accuracy 0.11999999731779099\n",
      "Iteration 7030: loss -35172.3515625, accuracy 0.10999999940395355\n",
      "Iteration 7040: loss -34298.21484375, accuracy 0.03999999910593033\n",
      "Iteration 7050: loss -34838.89453125, accuracy 0.12999999523162842\n",
      "Iteration 7060: loss -33771.9609375, accuracy 0.15000000596046448\n",
      "Iteration 7070: loss -35180.703125, accuracy 0.10000000149011612\n",
      "Iteration 7080: loss -35439.10546875, accuracy 0.10000000149011612\n",
      "Iteration 7090: loss -32245.755859375, accuracy 0.09000000357627869\n",
      "Iteration 7100: loss -32084.60546875, accuracy 0.09000000357627869\n",
      "Iteration 7110: loss -33837.78515625, accuracy 0.10999999940395355\n",
      "Iteration 7120: loss -34729.5859375, accuracy 0.07999999821186066\n",
      "Iteration 7130: loss -34278.48828125, accuracy 0.07000000029802322\n",
      "Iteration 7140: loss -32180.076171875, accuracy 0.12999999523162842\n",
      "Iteration 7150: loss -34419.43359375, accuracy 0.10000000149011612\n",
      "Iteration 7160: loss -36775.4375, accuracy 0.07999999821186066\n",
      "Iteration 7170: loss -32953.09375, accuracy 0.17000000178813934\n",
      "Iteration 7180: loss -31732.837890625, accuracy 0.11999999731779099\n",
      "Iteration 7190: loss -32209.544921875, accuracy 0.14000000059604645\n",
      "Iteration 7200: loss -34044.15625, accuracy 0.07999999821186066\n",
      "Iteration 7210: loss -35277.5546875, accuracy 0.17000000178813934\n",
      "Iteration 7220: loss -33256.6953125, accuracy 0.10000000149011612\n",
      "Iteration 7230: loss -32639.724609375, accuracy 0.11999999731779099\n",
      "Iteration 7240: loss -39724.52734375, accuracy 0.10999999940395355\n",
      "Iteration 7250: loss -34263.19140625, accuracy 0.14000000059604645\n",
      "Iteration 7260: loss -32275.98828125, accuracy 0.10000000149011612\n",
      "Iteration 7270: loss -34635.48046875, accuracy 0.07999999821186066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7280: loss -34766.15234375, accuracy 0.07999999821186066\n",
      "Iteration 7290: loss -36341.2578125, accuracy 0.12999999523162842\n",
      "Iteration 7300: loss -35569.0703125, accuracy 0.15000000596046448\n",
      "Iteration 7310: loss -36628.9453125, accuracy 0.14000000059604645\n",
      "Iteration 7320: loss -32526.02734375, accuracy 0.09000000357627869\n",
      "Iteration 7330: loss -35911.30078125, accuracy 0.09000000357627869\n",
      "Iteration 7340: loss -34462.359375, accuracy 0.05999999865889549\n",
      "Iteration 7350: loss -31122.390625, accuracy 0.09000000357627869\n",
      "Iteration 7360: loss -35086.18359375, accuracy 0.10999999940395355\n",
      "Iteration 7370: loss -35226.66796875, accuracy 0.03999999910593033\n",
      "Iteration 7380: loss -36285.3046875, accuracy 0.09000000357627869\n",
      "Iteration 7390: loss -33594.5, accuracy 0.10000000149011612\n",
      "Iteration 7400: loss -36830.625, accuracy 0.10000000149011612\n",
      "Iteration 7410: loss -35313.12890625, accuracy 0.10999999940395355\n",
      "Iteration 7420: loss -35641.44140625, accuracy 0.05999999865889549\n",
      "Iteration 7430: loss -33235.4921875, accuracy 0.11999999731779099\n",
      "Iteration 7440: loss -34820.65625, accuracy 0.11999999731779099\n",
      "Iteration 7450: loss -36702.515625, accuracy 0.10000000149011612\n",
      "Iteration 7460: loss -34804.34375, accuracy 0.09000000357627869\n",
      "Iteration 7470: loss -34981.6484375, accuracy 0.05999999865889549\n",
      "Iteration 7480: loss -36801.453125, accuracy 0.03999999910593033\n",
      "Iteration 7490: loss -35095.17578125, accuracy 0.07999999821186066\n",
      "Iteration 7500: loss -36914.67578125, accuracy 0.09000000357627869\n",
      "Iteration 7510: loss -35567.47265625, accuracy 0.10999999940395355\n",
      "Iteration 7520: loss -36083.671875, accuracy 0.10999999940395355\n",
      "Iteration 7530: loss -35135.86328125, accuracy 0.10000000149011612\n",
      "Iteration 7540: loss -34875.85546875, accuracy 0.11999999731779099\n",
      "Iteration 7550: loss -37756.375, accuracy 0.11999999731779099\n",
      "Iteration 7560: loss -39264.3671875, accuracy 0.07999999821186066\n",
      "Iteration 7570: loss -35438.88671875, accuracy 0.14000000059604645\n",
      "Iteration 7580: loss -37529.17578125, accuracy 0.17000000178813934\n",
      "Iteration 7590: loss -34911.78515625, accuracy 0.12999999523162842\n",
      "Iteration 7600: loss -36325.90234375, accuracy 0.07000000029802322\n",
      "Iteration 7610: loss -35309.73828125, accuracy 0.09000000357627869\n",
      "Iteration 7620: loss -34630.23828125, accuracy 0.07000000029802322\n",
      "Iteration 7630: loss -36241.11328125, accuracy 0.10999999940395355\n",
      "Iteration 7640: loss -34613.46875, accuracy 0.09000000357627869\n",
      "Iteration 7650: loss -34414.6484375, accuracy 0.14000000059604645\n",
      "Iteration 7660: loss -35623.6640625, accuracy 0.11999999731779099\n",
      "Iteration 7670: loss -35764.83984375, accuracy 0.07000000029802322\n",
      "Iteration 7680: loss -36118.640625, accuracy 0.07000000029802322\n",
      "Iteration 7690: loss -38799.26953125, accuracy 0.15000000596046448\n",
      "Iteration 7700: loss -37422.88671875, accuracy 0.10999999940395355\n",
      "Iteration 7710: loss -36673.3984375, accuracy 0.029999999329447746\n",
      "Iteration 7720: loss -38049.328125, accuracy 0.09000000357627869\n",
      "Iteration 7730: loss -33868.80078125, accuracy 0.12999999523162842\n",
      "Iteration 7740: loss -37818.1171875, accuracy 0.07999999821186066\n",
      "Iteration 7750: loss -35904.51953125, accuracy 0.07999999821186066\n",
      "Iteration 7760: loss -38321.73828125, accuracy 0.12999999523162842\n",
      "Iteration 7770: loss -37276.82421875, accuracy 0.03999999910593033\n",
      "Iteration 7780: loss -38162.83203125, accuracy 0.10000000149011612\n",
      "Iteration 7790: loss -35344.98046875, accuracy 0.10000000149011612\n",
      "Iteration 7800: loss -38636.54296875, accuracy 0.10000000149011612\n",
      "Iteration 7810: loss -37336.421875, accuracy 0.07000000029802322\n",
      "Iteration 7820: loss -36800.52734375, accuracy 0.07000000029802322\n",
      "Iteration 7830: loss -37375.2578125, accuracy 0.14000000059604645\n",
      "Iteration 7840: loss -37669.63671875, accuracy 0.10000000149011612\n",
      "Iteration 7850: loss -37737.76953125, accuracy 0.09000000357627869\n",
      "Iteration 7860: loss -39155.2578125, accuracy 0.15000000596046448\n",
      "Iteration 7870: loss -37007.46484375, accuracy 0.07999999821186066\n",
      "Iteration 7880: loss -38361.15625, accuracy 0.07999999821186066\n",
      "Iteration 7890: loss -37525.65234375, accuracy 0.09000000357627869\n",
      "Iteration 7900: loss -38388.09765625, accuracy 0.10000000149011612\n",
      "Iteration 7910: loss -39684.90234375, accuracy 0.1899999976158142\n",
      "Iteration 7920: loss -36820.8203125, accuracy 0.07000000029802322\n",
      "Iteration 7930: loss -37972.92578125, accuracy 0.09000000357627869\n",
      "Iteration 7940: loss -38599.94140625, accuracy 0.05999999865889549\n",
      "Iteration 7950: loss -37686.9375, accuracy 0.11999999731779099\n",
      "Iteration 7960: loss -37586.88671875, accuracy 0.07000000029802322\n",
      "Iteration 7970: loss -37080.25390625, accuracy 0.07999999821186066\n",
      "Iteration 7980: loss -34742.3359375, accuracy 0.09000000357627869\n",
      "Iteration 7990: loss -34934.54296875, accuracy 0.10000000149011612\n",
      "Iteration 8000: loss -38209.6484375, accuracy 0.14000000059604645\n",
      "Iteration 8010: loss -36824.0703125, accuracy 0.12999999523162842\n",
      "Iteration 8020: loss -36396.66796875, accuracy 0.05000000074505806\n",
      "Iteration 8030: loss -36637.53515625, accuracy 0.15000000596046448\n",
      "Iteration 8040: loss -37258.46484375, accuracy 0.10999999940395355\n",
      "Iteration 8050: loss -36533.98046875, accuracy 0.09000000357627869\n",
      "Iteration 8060: loss -38264.80859375, accuracy 0.10999999940395355\n",
      "Iteration 8070: loss -39808.046875, accuracy 0.10000000149011612\n",
      "Iteration 8080: loss -35415.51171875, accuracy 0.10000000149011612\n",
      "Iteration 8090: loss -40205.234375, accuracy 0.05999999865889549\n",
      "Iteration 8100: loss -38371.1796875, accuracy 0.10000000149011612\n",
      "Iteration 8110: loss -39851.875, accuracy 0.14000000059604645\n",
      "Iteration 8120: loss -38829.2109375, accuracy 0.10000000149011612\n",
      "Iteration 8130: loss -36618.80859375, accuracy 0.11999999731779099\n",
      "Iteration 8140: loss -41383.02734375, accuracy 0.10999999940395355\n",
      "Iteration 8150: loss -39841.87890625, accuracy 0.09000000357627869\n",
      "Iteration 8160: loss -39961.54296875, accuracy 0.10999999940395355\n",
      "Iteration 8170: loss -39153.28515625, accuracy 0.10000000149011612\n",
      "Iteration 8180: loss -40218.96875, accuracy 0.11999999731779099\n",
      "Iteration 8190: loss -37331.41015625, accuracy 0.05999999865889549\n",
      "Iteration 8200: loss -38201.8984375, accuracy 0.07999999821186066\n",
      "Iteration 8210: loss -40346.28515625, accuracy 0.05000000074505806\n",
      "Iteration 8220: loss -39545.75390625, accuracy 0.15000000596046448\n",
      "Iteration 8230: loss -39404.29296875, accuracy 0.05999999865889549\n",
      "Iteration 8240: loss -37191.20703125, accuracy 0.15000000596046448\n",
      "Iteration 8250: loss -40021.640625, accuracy 0.03999999910593033\n",
      "Iteration 8260: loss -41409.40625, accuracy 0.09000000357627869\n",
      "Iteration 8270: loss -39578.66015625, accuracy 0.10999999940395355\n",
      "Iteration 8280: loss -40477.0703125, accuracy 0.10000000149011612\n",
      "Iteration 8290: loss -38491.55078125, accuracy 0.10999999940395355\n",
      "Iteration 8300: loss -41306.2109375, accuracy 0.10999999940395355\n",
      "Iteration 8310: loss -39056.2890625, accuracy 0.10000000149011612\n",
      "Iteration 8320: loss -38286.01171875, accuracy 0.09000000357627869\n",
      "Iteration 8330: loss -41021.3671875, accuracy 0.07999999821186066\n",
      "Iteration 8340: loss -39655.82421875, accuracy 0.07999999821186066\n",
      "Iteration 8350: loss -38554.0859375, accuracy 0.11999999731779099\n",
      "Iteration 8360: loss -39302.5390625, accuracy 0.07000000029802322\n",
      "Iteration 8370: loss -38753.81640625, accuracy 0.03999999910593033\n",
      "Iteration 8380: loss -40221.046875, accuracy 0.07999999821186066\n",
      "Iteration 8390: loss -40107.76171875, accuracy 0.07000000029802322\n",
      "Iteration 8400: loss -41200.08984375, accuracy 0.14000000059604645\n",
      "Iteration 8410: loss -40041.0390625, accuracy 0.09000000357627869\n",
      "Iteration 8420: loss -32741.73828125, accuracy 0.11999999731779099\n",
      "Iteration 8430: loss -41733.11328125, accuracy 0.12999999523162842\n",
      "Iteration 8440: loss -38875.45703125, accuracy 0.12999999523162842\n",
      "Iteration 8450: loss -41039.50390625, accuracy 0.11999999731779099\n",
      "Iteration 8460: loss -40728.3828125, accuracy 0.10000000149011612\n",
      "Iteration 8470: loss -37954.16796875, accuracy 0.10000000149011612\n",
      "Iteration 8480: loss -41023.0625, accuracy 0.07999999821186066\n",
      "Iteration 8490: loss -41543.55078125, accuracy 0.10000000149011612\n",
      "Iteration 8500: loss -41608.77734375, accuracy 0.11999999731779099\n",
      "Iteration 8510: loss -38940.68359375, accuracy 0.09000000357627869\n",
      "Iteration 8520: loss -40326.65234375, accuracy 0.11999999731779099\n",
      "Iteration 8530: loss -40630.875, accuracy 0.07999999821186066\n",
      "Iteration 8540: loss -43185.8828125, accuracy 0.09000000357627869\n",
      "Iteration 8550: loss -39690.40625, accuracy 0.11999999731779099\n",
      "Iteration 8560: loss -41057.11328125, accuracy 0.05999999865889549\n",
      "Iteration 8570: loss -36775.52734375, accuracy 0.11999999731779099\n",
      "Iteration 8580: loss -40644.09375, accuracy 0.09000000357627869\n",
      "Iteration 8590: loss -39720.28125, accuracy 0.07000000029802322\n",
      "Iteration 8600: loss -39891.14453125, accuracy 0.10999999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8610: loss -37884.5, accuracy 0.07999999821186066\n",
      "Iteration 8620: loss -42918.6015625, accuracy 0.05000000074505806\n",
      "Iteration 8630: loss -44098.76953125, accuracy 0.11999999731779099\n",
      "Iteration 8640: loss -40813.0703125, accuracy 0.07999999821186066\n",
      "Iteration 8650: loss -43719.83984375, accuracy 0.03999999910593033\n",
      "Iteration 8660: loss -41191.5859375, accuracy 0.14000000059604645\n",
      "Iteration 8670: loss -39461.46484375, accuracy 0.12999999523162842\n",
      "Iteration 8680: loss -40633.11328125, accuracy 0.12999999523162842\n",
      "Iteration 8690: loss -40395.54296875, accuracy 0.05999999865889549\n",
      "Iteration 8700: loss -40058.0703125, accuracy 0.07999999821186066\n",
      "Iteration 8710: loss -41010.59375, accuracy 0.12999999523162842\n",
      "Iteration 8720: loss -38569.546875, accuracy 0.11999999731779099\n",
      "Iteration 8730: loss -41718.34375, accuracy 0.12999999523162842\n",
      "Iteration 8740: loss -42471.484375, accuracy 0.05999999865889549\n",
      "Iteration 8750: loss -43475.796875, accuracy 0.07000000029802322\n",
      "Iteration 8760: loss -41032.76171875, accuracy 0.05999999865889549\n",
      "Iteration 8770: loss -43722.7109375, accuracy 0.12999999523162842\n",
      "Iteration 8780: loss -42384.83203125, accuracy 0.05999999865889549\n",
      "Iteration 8790: loss -43921.93359375, accuracy 0.11999999731779099\n",
      "Iteration 8800: loss -39982.79296875, accuracy 0.10999999940395355\n",
      "Iteration 8810: loss -43499.9296875, accuracy 0.10999999940395355\n",
      "Iteration 8820: loss -38113.17578125, accuracy 0.12999999523162842\n",
      "Iteration 8830: loss -41517.6484375, accuracy 0.07000000029802322\n",
      "Iteration 8840: loss -41926.04296875, accuracy 0.14000000059604645\n",
      "Iteration 8850: loss -42815.48828125, accuracy 0.05999999865889549\n",
      "Iteration 8860: loss -43139.3046875, accuracy 0.05999999865889549\n",
      "Iteration 8870: loss -43022.92578125, accuracy 0.09000000357627869\n",
      "Iteration 8880: loss -46317.7265625, accuracy 0.07999999821186066\n",
      "Iteration 8890: loss -43879.67578125, accuracy 0.15000000596046448\n",
      "Iteration 8900: loss -42686.50390625, accuracy 0.11999999731779099\n",
      "Iteration 8910: loss -39521.11328125, accuracy 0.07999999821186066\n",
      "Iteration 8920: loss -40129.734375, accuracy 0.07000000029802322\n",
      "Iteration 8930: loss -42961.76171875, accuracy 0.05999999865889549\n",
      "Iteration 8940: loss -43853.8984375, accuracy 0.10999999940395355\n",
      "Iteration 8950: loss -42298.83203125, accuracy 0.07000000029802322\n",
      "Iteration 8960: loss -42812.6953125, accuracy 0.10999999940395355\n",
      "Iteration 8970: loss -45203.81640625, accuracy 0.14000000059604645\n",
      "Iteration 8980: loss -43426.34765625, accuracy 0.05999999865889549\n",
      "Iteration 8990: loss -41932.3203125, accuracy 0.11999999731779099\n",
      "Iteration 9000: loss -43221.046875, accuracy 0.10000000149011612\n",
      "Iteration 9010: loss -38611.72265625, accuracy 0.05000000074505806\n",
      "Iteration 9020: loss -42524.953125, accuracy 0.05999999865889549\n",
      "Iteration 9030: loss -45784.9453125, accuracy 0.11999999731779099\n",
      "Iteration 9040: loss -42701.18359375, accuracy 0.07000000029802322\n",
      "Iteration 9050: loss -42026.9609375, accuracy 0.09000000357627869\n",
      "Iteration 9060: loss -44194.14453125, accuracy 0.09000000357627869\n",
      "Iteration 9070: loss -41671.7109375, accuracy 0.05000000074505806\n",
      "Iteration 9080: loss -45402.11328125, accuracy 0.10999999940395355\n",
      "Iteration 9090: loss -42181.81640625, accuracy 0.07999999821186066\n",
      "Iteration 9100: loss -42084.921875, accuracy 0.12999999523162842\n",
      "Iteration 9110: loss -40646.828125, accuracy 0.10999999940395355\n",
      "Iteration 9120: loss -43506.5390625, accuracy 0.1899999976158142\n",
      "Iteration 9130: loss -44481.44921875, accuracy 0.12999999523162842\n",
      "Iteration 9140: loss -47087.6484375, accuracy 0.07999999821186066\n",
      "Iteration 9150: loss -44044.55078125, accuracy 0.09000000357627869\n",
      "Iteration 9160: loss -44751.9765625, accuracy 0.05999999865889549\n",
      "Iteration 9170: loss -43841.3203125, accuracy 0.10000000149011612\n",
      "Iteration 9180: loss -42711.125, accuracy 0.10999999940395355\n",
      "Iteration 9190: loss -42206.21484375, accuracy 0.09000000357627869\n",
      "Iteration 9200: loss -42269.34375, accuracy 0.07999999821186066\n",
      "Iteration 9210: loss -40648.7421875, accuracy 0.05000000074505806\n",
      "Iteration 9220: loss -42724.42578125, accuracy 0.15000000596046448\n",
      "Iteration 9230: loss -47791.19140625, accuracy 0.09000000357627869\n",
      "Iteration 9240: loss -43622.96484375, accuracy 0.10000000149011612\n",
      "Iteration 9250: loss -42842.234375, accuracy 0.10999999940395355\n",
      "Iteration 9260: loss -41754.8203125, accuracy 0.10999999940395355\n",
      "Iteration 9270: loss -43000.80859375, accuracy 0.09000000357627869\n",
      "Iteration 9280: loss -47725.98046875, accuracy 0.10999999940395355\n",
      "Iteration 9290: loss -45690.9609375, accuracy 0.11999999731779099\n",
      "Iteration 9300: loss -43450.87890625, accuracy 0.14000000059604645\n",
      "Iteration 9310: loss -40257.86328125, accuracy 0.09000000357627869\n",
      "Iteration 9320: loss -41145.875, accuracy 0.05999999865889549\n",
      "Iteration 9330: loss -44198.57421875, accuracy 0.17000000178813934\n",
      "Iteration 9340: loss -45992.203125, accuracy 0.10999999940395355\n",
      "Iteration 9350: loss -44525.90625, accuracy 0.09000000357627869\n",
      "Iteration 9360: loss -45303.51171875, accuracy 0.14000000059604645\n",
      "Iteration 9370: loss -42458.14453125, accuracy 0.17000000178813934\n",
      "Iteration 9380: loss -46072.21484375, accuracy 0.11999999731779099\n",
      "Iteration 9390: loss -44372.296875, accuracy 0.07999999821186066\n",
      "Iteration 9400: loss -42452.22265625, accuracy 0.12999999523162842\n",
      "Iteration 9410: loss -43547.09765625, accuracy 0.09000000357627869\n",
      "Iteration 9420: loss -43142.3671875, accuracy 0.05000000074505806\n",
      "Iteration 9430: loss -46701.0703125, accuracy 0.15000000596046448\n",
      "Iteration 9440: loss -44140.12109375, accuracy 0.12999999523162842\n",
      "Iteration 9450: loss -48055.03125, accuracy 0.10000000149011612\n",
      "Iteration 9460: loss -40192.9453125, accuracy 0.07999999821186066\n",
      "Iteration 9470: loss -45273.765625, accuracy 0.11999999731779099\n",
      "Iteration 9480: loss -44785.21484375, accuracy 0.09000000357627869\n",
      "Iteration 9490: loss -46994.50390625, accuracy 0.17000000178813934\n",
      "Iteration 9500: loss -42128.0234375, accuracy 0.11999999731779099\n",
      "Iteration 9510: loss -45504.6796875, accuracy 0.09000000357627869\n",
      "Iteration 9520: loss -45599.8125, accuracy 0.09000000357627869\n",
      "Iteration 9530: loss -45377.7734375, accuracy 0.20000000298023224\n",
      "Iteration 9540: loss -46623.6875, accuracy 0.11999999731779099\n",
      "Iteration 9550: loss -46461.55859375, accuracy 0.10999999940395355\n",
      "Iteration 9560: loss -48963.328125, accuracy 0.07000000029802322\n",
      "Iteration 9570: loss -43984.81640625, accuracy 0.14000000059604645\n",
      "Iteration 9580: loss -42681.55078125, accuracy 0.07000000029802322\n",
      "Iteration 9590: loss -46118.55859375, accuracy 0.10000000149011612\n",
      "Iteration 9600: loss -47546.5859375, accuracy 0.09000000357627869\n",
      "Iteration 9610: loss -44709.47265625, accuracy 0.14000000059604645\n",
      "Iteration 9620: loss -46352.16015625, accuracy 0.07999999821186066\n",
      "Iteration 9630: loss -44722.7421875, accuracy 0.14000000059604645\n",
      "Iteration 9640: loss -44601.96875, accuracy 0.11999999731779099\n",
      "Iteration 9650: loss -48215.77734375, accuracy 0.05999999865889549\n",
      "Iteration 9660: loss -47068.9765625, accuracy 0.10000000149011612\n",
      "Iteration 9670: loss -43978.7109375, accuracy 0.029999999329447746\n",
      "Iteration 9680: loss -48320.52734375, accuracy 0.10999999940395355\n",
      "Iteration 9690: loss -44619.87890625, accuracy 0.07999999821186066\n",
      "Iteration 9700: loss -41905.21484375, accuracy 0.11999999731779099\n",
      "Iteration 9710: loss -43209.65234375, accuracy 0.12999999523162842\n",
      "Iteration 9720: loss -47800.89453125, accuracy 0.09000000357627869\n",
      "Iteration 9730: loss -46106.14453125, accuracy 0.07000000029802322\n",
      "Iteration 9740: loss -44339.86328125, accuracy 0.1599999964237213\n",
      "Iteration 9750: loss -45821.24609375, accuracy 0.12999999523162842\n",
      "Iteration 9760: loss -45548.3203125, accuracy 0.11999999731779099\n",
      "Iteration 9770: loss -47701.734375, accuracy 0.10999999940395355\n",
      "Iteration 9780: loss -48244.3671875, accuracy 0.05999999865889549\n",
      "Iteration 9790: loss -47989.7109375, accuracy 0.05999999865889549\n",
      "Iteration 9800: loss -44632.5078125, accuracy 0.07000000029802322\n",
      "Iteration 9810: loss -45432.3671875, accuracy 0.11999999731779099\n",
      "Iteration 9820: loss -43308.05078125, accuracy 0.10999999940395355\n",
      "Iteration 9830: loss -44221.4375, accuracy 0.09000000357627869\n",
      "Iteration 9840: loss -47228.6328125, accuracy 0.10999999940395355\n",
      "Iteration 9850: loss -48009.19140625, accuracy 0.10999999940395355\n",
      "Iteration 9860: loss -46379.84765625, accuracy 0.09000000357627869\n",
      "Iteration 9870: loss -47080.86328125, accuracy 0.12999999523162842\n",
      "Iteration 9880: loss -48573.7265625, accuracy 0.11999999731779099\n",
      "Iteration 9890: loss -50624.95703125, accuracy 0.07999999821186066\n",
      "Iteration 9900: loss -45794.46875, accuracy 0.07999999821186066\n",
      "Iteration 9910: loss -49003.68359375, accuracy 0.09000000357627869\n",
      "Iteration 9920: loss -47806.53125, accuracy 0.12999999523162842\n",
      "Iteration 9930: loss -47994.94140625, accuracy 0.05999999865889549\n",
      "Iteration 9940: loss -47796.42578125, accuracy 0.07000000029802322\n",
      "Iteration 9950: loss -47729.63671875, accuracy 0.03999999910593033\n",
      "Iteration 9960: loss -44368.6796875, accuracy 0.12999999523162842\n",
      "Iteration 9970: loss -48363.49609375, accuracy 0.029999999329447746\n",
      "Iteration 9980: loss -43656.71875, accuracy 0.09000000357627869\n",
      "Iteration 9990: loss -44574.81640625, accuracy 0.07000000029802322\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "model_path = logging_meta['model_path']\n",
    "\n",
    "        \n",
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    session.run(initialize_vars)\n",
    "    for iteration in range(10000):\n",
    "        _images, _labels = data.train.next_batch(100)\n",
    "        \n",
    "        _ = session.run([train_step], feed_dict={images: _images, labels: _labels})\n",
    "        if iteration % 10 == 0:\n",
    "            _summary, _accuracy, _loss = session.run([merge_summaries, accuracy, loss],\n",
    "                                                     feed_dict={images: _images, labels: _labels})\n",
    "            logging_meta['train_writer'].add_summary(_summary, iteration)\n",
    "            print(\"Iteration {}: loss {}, accuracy {}\".format(iteration, _loss, _accuracy))\n",
    "        \n",
    "        #####################################\n",
    "        # Add validation section with saver #\n",
    "        #####################################\n",
    "            \n",
    "    _prediction, = session.run([prediction], feed_dict={images: data.validation.images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-60869.6484375 , -60867.18359375, -60867.23828125, ...,\n",
       "        -60870.0625    , -60866.8046875 , -60867.671875  ],\n",
       "       [-67426.75      , -67423.7109375 , -67425.5859375 , ...,\n",
       "        -67427.921875  , -67424.65625   , -67426.2890625 ],\n",
       "       [-26674.76367188, -26673.16015625, -26673.80664062, ...,\n",
       "        -26675.41015625, -26673.44335938, -26673.84179688],\n",
       "       ..., \n",
       "       [-16572.75390625, -16571.66992188, -16571.40234375, ...,\n",
       "        -16571.68554688, -16571.8046875 , -16572.54101562],\n",
       "       [-63961.3125    , -63958.421875  , -63958.625     , ...,\n",
       "        -63962.51953125, -63958.21484375, -63960.3203125 ],\n",
       "       [-28546.58984375, -28545.76757812, -28545.37109375, ...,\n",
       "        -28547.55078125, -28545.515625  , -28546.046875  ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
