{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Image Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from utils.nn_graph import simple_layer\n",
    "from utils.data import init_dir\n",
    "from utils.nn_visualization import init_embedding_projector, init_embedding_data\n",
    "from utils.nn_visualization import get_sprite_img, get_label_class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting /data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting /data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting /data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('/data/fashion/', one_hot=True)\n",
    "img_shape = (28, 28)\n",
    "class_id2class_name_mapping = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Conv Net Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.nn_visualization import conv33132_summaries, conv55124_summary, variable_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug [cross_etropy_vector]: (?,)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('conv_image_net_inputs'):\n",
    "        images = tf.placeholder(tf.float32, shape=[None, 784], name='images')\n",
    "        labels = tf.placeholder(tf.float32, shape=[None, 10], name='labels')\n",
    "        keep_dropout_prob = tf.placeholder(tf.float32, name='keep_dropout_prob')\n",
    "        is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "            \n",
    "    with tf.name_scope('image_reshape'):        \n",
    "        images_reshaped = tf.reshape(images, [-1, 28, 28, 1])\n",
    "\n",
    "    with tf.variable_scope('conv_layer_1'):\n",
    "        w_conv_1 = tf.get_variable('w_conv_1', [3, 3, 1, 32], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "        b_conv_1 = tf.get_variable('b_conv_1', initializer=tf.constant_initializer(0), shape=[32])\n",
    "        conv33132_summaries('w_conv_1_summary', w_conv_1)\n",
    "\n",
    "        conv_layer_1 = tf.nn.conv2d(images_reshaped, w_conv_1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        # conv_layer_1 = tf.contrib.layers.batch_norm(conv_layer_1, is_training=is_training)\n",
    "        conv_layer_1 = conv_layer_1 + b_conv_1\n",
    "        conv_layer_1 = tf.nn.relu(conv_layer_1)\n",
    "        conv_layer_1 = tf.nn.max_pool(conv_layer_1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')   \n",
    "\n",
    "    with tf.variable_scope('conv_layer_2'):\n",
    "        w_conv_2 = tf.get_variable('w_conv_2', [3, 3, 32, 64], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "        b_conv_2 = tf.get_variable('b_conv_2', initializer=tf.constant_initializer(0), shape=[64])\n",
    "        \n",
    "        conv_layer_2 = tf.nn.conv2d(conv_layer_1, w_conv_2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        # conv_layer_2 = tf.contrib.layers.batch_norm(conv_layer_2, is_training=is_training)\n",
    "        conv_layer_2 = conv_layer_2 + b_conv_2\n",
    "        conv_layer_2 = tf.nn.relu(conv_layer_2)\n",
    "        conv_layer_2 = tf.nn.max_pool(conv_layer_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    with tf.variable_scope('feed_forward_layer_1'):\n",
    "        ff_layer_1 = tf.reshape(conv_layer_2, [-1, 7*7*64])\n",
    "        ff_layer_1 = simple_layer('ff_1', ff_layer_1, shape=[7*7*64, 10], activation='linear')\n",
    "        raw_prediction = tf.nn.dropout(ff_layer_1, keep_dropout_prob)\n",
    "    \n",
    "    with tf.name_scope('prediction'):\n",
    "        prediction = tf.nn.softmax(raw_prediction)\n",
    "    \n",
    "    with tf.variable_scope(\"embedding_visualization\"):\n",
    "        embedding = tf.Variable(tf.zeros([5000, 10]), name='valid_embedding')\n",
    "        embedding_assignment = embedding.assign(raw_prediction)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy_vector = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=raw_prediction)\n",
    "        print('Debug [cross_etropy_vector]:', cross_entropy_vector.get_shape())\n",
    "        loss = tf.reduce_mean(cross_entropy_vector)\n",
    "        variable_summaries('loss_summary', cross_entropy_vector)\n",
    "        \n",
    "    with tf.name_scope('training'):\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_step  = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction)\n",
    "        variable_summaries('accuracy_summary', correct_prediction)\n",
    "    \n",
    "    initialize_vars = tf.global_variables_initializer()\n",
    "    merge_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Model Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import init_model_logging\n",
    "base_dir = '/tensorboard_summaries/conv_image_net/'\n",
    "exp_name = 'experiment_final'\n",
    "\n",
    "logging_meta = init_model_logging(base_dir, exp_name, graph=graph, remove_existing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Embedding Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprite_img = get_sprite_img(data.validation.images, img_shape)\n",
    "label_names = get_label_class_names(data.validation.labels, class_id2class_name_mapping)\n",
    "\n",
    "init_embedding_data(logging_meta['valid_writer_dir'], sprite_img, label_names)\n",
    "init_embedding_projector(logging_meta['valid_writer'], embedding, img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Conv Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Iteration 0: loss 2.182243585586548, accuracy 0.30000001192092896\n",
      "= Valid Iteration 0: loss 2.289867639541626, accuracy 0.20280000567436218 =\n",
      "Train Iteration 10: loss 1.0675846338272095, accuracy 0.7200000286102295\n",
      "Train Iteration 20: loss 1.0855540037155151, accuracy 0.5799999833106995\n",
      "Train Iteration 30: loss 0.9468861222267151, accuracy 0.7599999904632568\n",
      "Train Iteration 40: loss 0.8134348392486572, accuracy 0.7599999904632568\n",
      "Train Iteration 50: loss 0.7536531686782837, accuracy 0.7699999809265137\n",
      "Train Iteration 60: loss 0.7573251128196716, accuracy 0.7099999785423279\n",
      "Train Iteration 70: loss 0.7410078644752502, accuracy 0.800000011920929\n",
      "Train Iteration 80: loss 0.704986572265625, accuracy 0.7599999904632568\n",
      "Train Iteration 90: loss 0.7159327864646912, accuracy 0.75\n",
      "Train Iteration 100: loss 0.5893170833587646, accuracy 0.8299999833106995\n",
      "= Valid Iteration 100: loss 0.5888126492500305, accuracy 0.8342000246047974 =\n",
      "Train Iteration 110: loss 0.6716362237930298, accuracy 0.7599999904632568\n",
      "Train Iteration 120: loss 0.636761486530304, accuracy 0.8199999928474426\n",
      "Train Iteration 130: loss 0.5261700749397278, accuracy 0.8600000143051147\n",
      "Train Iteration 140: loss 0.7530144453048706, accuracy 0.7200000286102295\n",
      "Train Iteration 150: loss 0.5763589143753052, accuracy 0.8500000238418579\n",
      "Train Iteration 160: loss 0.529712975025177, accuracy 0.8700000047683716\n",
      "Train Iteration 170: loss 0.6225908994674683, accuracy 0.8199999928474426\n",
      "Train Iteration 180: loss 0.4787890911102295, accuracy 0.8799999952316284\n",
      "Train Iteration 190: loss 0.6308497786521912, accuracy 0.8100000023841858\n",
      "Train Iteration 200: loss 0.5074678063392639, accuracy 0.8899999856948853\n",
      "= Valid Iteration 200: loss 0.5054962635040283, accuracy 0.8593999743461609 =\n",
      "Train Iteration 210: loss 0.4792228043079376, accuracy 0.8500000238418579\n",
      "Train Iteration 220: loss 0.4793296158313751, accuracy 0.8999999761581421\n",
      "Train Iteration 230: loss 0.5466326475143433, accuracy 0.8199999928474426\n",
      "Train Iteration 240: loss 0.4609552323818207, accuracy 0.8899999856948853\n",
      "Train Iteration 250: loss 0.414468377828598, accuracy 0.9100000262260437\n",
      "Train Iteration 260: loss 0.47806715965270996, accuracy 0.8899999856948853\n",
      "Train Iteration 270: loss 0.3852461278438568, accuracy 0.8999999761581421\n",
      "Train Iteration 280: loss 0.41955992579460144, accuracy 0.9200000166893005\n",
      "Train Iteration 290: loss 0.3747991621494293, accuracy 0.8999999761581421\n",
      "Train Iteration 300: loss 0.40288078784942627, accuracy 0.8799999952316284\n",
      "= Valid Iteration 300: loss 0.4405592679977417, accuracy 0.8661999702453613 =\n",
      "Train Iteration 310: loss 0.4555386006832123, accuracy 0.8700000047683716\n",
      "Train Iteration 320: loss 0.3261852264404297, accuracy 0.9300000071525574\n",
      "Train Iteration 330: loss 0.433044970035553, accuracy 0.8500000238418579\n",
      "Train Iteration 340: loss 0.3994065821170807, accuracy 0.8500000238418579\n",
      "Train Iteration 350: loss 0.3776927590370178, accuracy 0.8999999761581421\n",
      "Train Iteration 360: loss 0.4274233281612396, accuracy 0.8899999856948853\n",
      "Train Iteration 370: loss 0.49920639395713806, accuracy 0.8700000047683716\n",
      "Train Iteration 380: loss 0.486085444688797, accuracy 0.8199999928474426\n",
      "Train Iteration 390: loss 0.46374794840812683, accuracy 0.8600000143051147\n",
      "Train Iteration 400: loss 0.2969456911087036, accuracy 0.949999988079071\n",
      "= Valid Iteration 400: loss 0.4094761610031128, accuracy 0.878000020980835 =\n",
      "Train Iteration 410: loss 0.379395067691803, accuracy 0.8899999856948853\n",
      "Train Iteration 420: loss 0.4434443414211273, accuracy 0.8500000238418579\n",
      "Train Iteration 430: loss 0.43853190541267395, accuracy 0.8299999833106995\n",
      "Train Iteration 440: loss 0.5385065674781799, accuracy 0.800000011920929\n",
      "Train Iteration 450: loss 0.46981316804885864, accuracy 0.8500000238418579\n",
      "Train Iteration 460: loss 0.49066802859306335, accuracy 0.8799999952316284\n",
      "Train Iteration 470: loss 0.40624022483825684, accuracy 0.9200000166893005\n",
      "Train Iteration 480: loss 0.49472731351852417, accuracy 0.8600000143051147\n",
      "Train Iteration 490: loss 0.48115241527557373, accuracy 0.8899999856948853\n",
      "Train Iteration 500: loss 0.40165847539901733, accuracy 0.8700000047683716\n",
      "= Valid Iteration 500: loss 0.3993558883666992, accuracy 0.8813999891281128 =\n",
      "Train Iteration 510: loss 0.412354439496994, accuracy 0.8700000047683716\n",
      "Train Iteration 520: loss 0.4386965036392212, accuracy 0.8899999856948853\n",
      "Train Iteration 530: loss 0.4027325510978699, accuracy 0.8799999952316284\n",
      "Train Iteration 540: loss 0.31016144156455994, accuracy 0.949999988079071\n",
      "Train Iteration 550: loss 0.40936079621315, accuracy 0.8799999952316284\n",
      "Train Iteration 560: loss 0.37858933210372925, accuracy 0.8999999761581421\n",
      "Train Iteration 570: loss 0.2971743643283844, accuracy 0.9100000262260437\n",
      "Train Iteration 580: loss 0.40510842204093933, accuracy 0.8799999952316284\n",
      "Train Iteration 590: loss 0.4100770652294159, accuracy 0.8799999952316284\n",
      "Train Iteration 600: loss 0.38433533906936646, accuracy 0.8999999761581421\n",
      "= Valid Iteration 600: loss 0.39007246494293213, accuracy 0.8844000101089478 =\n",
      "Train Iteration 610: loss 0.34566786885261536, accuracy 0.8999999761581421\n",
      "Train Iteration 620: loss 0.3609939515590668, accuracy 0.8799999952316284\n",
      "Train Iteration 630: loss 0.3331359028816223, accuracy 0.9100000262260437\n",
      "Train Iteration 640: loss 0.3020149767398834, accuracy 0.9300000071525574\n",
      "Train Iteration 650: loss 0.4116799831390381, accuracy 0.8600000143051147\n",
      "Train Iteration 660: loss 0.3540860116481781, accuracy 0.9100000262260437\n",
      "Train Iteration 670: loss 0.3645061254501343, accuracy 0.9100000262260437\n",
      "Train Iteration 680: loss 0.4116791784763336, accuracy 0.8299999833106995\n",
      "Train Iteration 690: loss 0.33017486333847046, accuracy 0.9100000262260437\n",
      "Train Iteration 700: loss 0.3098829686641693, accuracy 0.9200000166893005\n",
      "= Valid Iteration 700: loss 0.36749017238616943, accuracy 0.881600022315979 =\n",
      "Train Iteration 710: loss 0.327312707901001, accuracy 0.8899999856948853\n",
      "Train Iteration 720: loss 0.41319945454597473, accuracy 0.8299999833106995\n",
      "Train Iteration 730: loss 0.36878979206085205, accuracy 0.8600000143051147\n",
      "Train Iteration 740: loss 0.4000035226345062, accuracy 0.8500000238418579\n",
      "Train Iteration 750: loss 0.3147665858268738, accuracy 0.9300000071525574\n",
      "Train Iteration 760: loss 0.37601909041404724, accuracy 0.8999999761581421\n",
      "Train Iteration 770: loss 0.2813529074192047, accuracy 0.8600000143051147\n",
      "Train Iteration 780: loss 0.3661308288574219, accuracy 0.8799999952316284\n",
      "Train Iteration 790: loss 0.39574503898620605, accuracy 0.8500000238418579\n",
      "Train Iteration 800: loss 0.3249437212944031, accuracy 0.8899999856948853\n",
      "= Valid Iteration 800: loss 0.3517841100692749, accuracy 0.8948000073432922 =\n",
      "Train Iteration 810: loss 0.3785736858844757, accuracy 0.9100000262260437\n",
      "Train Iteration 820: loss 0.3391244411468506, accuracy 0.8999999761581421\n",
      "Train Iteration 830: loss 0.2701958417892456, accuracy 0.9399999976158142\n",
      "Train Iteration 840: loss 0.36230915784835815, accuracy 0.8999999761581421\n",
      "Train Iteration 850: loss 0.3761950731277466, accuracy 0.9100000262260437\n",
      "Train Iteration 860: loss 0.33012303709983826, accuracy 0.8999999761581421\n",
      "Train Iteration 870: loss 0.29027634859085083, accuracy 0.9200000166893005\n",
      "Train Iteration 880: loss 0.3519498109817505, accuracy 0.8799999952316284\n",
      "Train Iteration 890: loss 0.30715665221214294, accuracy 0.9300000071525574\n",
      "Train Iteration 900: loss 0.3615247309207916, accuracy 0.8999999761581421\n",
      "= Valid Iteration 900: loss 0.36690783500671387, accuracy 0.8880000114440918 =\n",
      "Train Iteration 910: loss 0.4208034574985504, accuracy 0.8899999856948853\n",
      "Train Iteration 920: loss 0.3132772147655487, accuracy 0.9200000166893005\n",
      "Train Iteration 930: loss 0.40134942531585693, accuracy 0.9100000262260437\n",
      "Train Iteration 940: loss 0.29974308609962463, accuracy 0.9200000166893005\n",
      "Train Iteration 950: loss 0.3414042592048645, accuracy 0.9300000071525574\n",
      "Train Iteration 960: loss 0.44430282711982727, accuracy 0.8700000047683716\n",
      "Train Iteration 970: loss 0.3829124867916107, accuracy 0.8700000047683716\n",
      "Train Iteration 980: loss 0.3610740602016449, accuracy 0.9100000262260437\n",
      "Train Iteration 990: loss 0.38188162446022034, accuracy 0.8399999737739563\n",
      "Train Iteration 1000: loss 0.3660944998264313, accuracy 0.8799999952316284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Valid Iteration 1000: loss 0.34487393498420715, accuracy 0.899399995803833 =\n",
      "Train Iteration 1010: loss 0.30527955293655396, accuracy 0.9300000071525574\n",
      "Train Iteration 1020: loss 0.3203602135181427, accuracy 0.9300000071525574\n",
      "Train Iteration 1030: loss 0.40870895981788635, accuracy 0.8500000238418579\n",
      "Train Iteration 1040: loss 0.37987425923347473, accuracy 0.8799999952316284\n",
      "Train Iteration 1050: loss 0.31302210688591003, accuracy 0.9200000166893005\n",
      "Train Iteration 1060: loss 0.3226400315761566, accuracy 0.9100000262260437\n",
      "Train Iteration 1070: loss 0.3709760308265686, accuracy 0.8700000047683716\n",
      "Train Iteration 1080: loss 0.2897009551525116, accuracy 0.9100000262260437\n",
      "Train Iteration 1090: loss 0.4554344117641449, accuracy 0.8500000238418579\n",
      "Train Iteration 1100: loss 0.2514658272266388, accuracy 0.9599999785423279\n",
      "= Valid Iteration 1100: loss 0.3374021649360657, accuracy 0.9031999707221985 =\n",
      "Train Iteration 1110: loss 0.3289186954498291, accuracy 0.9100000262260437\n",
      "Train Iteration 1120: loss 0.364566832780838, accuracy 0.8600000143051147\n",
      "Train Iteration 1130: loss 0.46811607480049133, accuracy 0.8700000047683716\n",
      "Train Iteration 1140: loss 0.3354291617870331, accuracy 0.8799999952316284\n",
      "Train Iteration 1150: loss 0.23107977211475372, accuracy 0.949999988079071\n",
      "Train Iteration 1160: loss 0.31853240728378296, accuracy 0.8999999761581421\n",
      "Train Iteration 1170: loss 0.3502267599105835, accuracy 0.8700000047683716\n",
      "Train Iteration 1180: loss 0.26423537731170654, accuracy 0.9399999976158142\n",
      "Train Iteration 1190: loss 0.29547804594039917, accuracy 0.9100000262260437\n",
      "Train Iteration 1200: loss 0.3225651979446411, accuracy 0.9200000166893005\n",
      "= Valid Iteration 1200: loss 0.34185999631881714, accuracy 0.892799973487854 =\n",
      "Train Iteration 1210: loss 0.35158324241638184, accuracy 0.8700000047683716\n",
      "Train Iteration 1220: loss 0.3133814334869385, accuracy 0.9100000262260437\n",
      "Train Iteration 1230: loss 0.19502177834510803, accuracy 0.949999988079071\n",
      "Train Iteration 1240: loss 0.24872051179409027, accuracy 0.9300000071525574\n",
      "Train Iteration 1250: loss 0.3178417980670929, accuracy 0.8999999761581421\n",
      "Train Iteration 1260: loss 0.25543898344039917, accuracy 0.9300000071525574\n",
      "Train Iteration 1270: loss 0.3672420382499695, accuracy 0.8899999856948853\n",
      "Train Iteration 1280: loss 0.2800176739692688, accuracy 0.8899999856948853\n",
      "Train Iteration 1290: loss 0.25880974531173706, accuracy 0.8999999761581421\n",
      "Train Iteration 1300: loss 0.3682253658771515, accuracy 0.8500000238418579\n",
      "= Valid Iteration 1300: loss 0.3255999982357025, accuracy 0.8939999938011169 =\n",
      "Train Iteration 1310: loss 0.3418962061405182, accuracy 0.9100000262260437\n",
      "Train Iteration 1320: loss 0.29754942655563354, accuracy 0.9300000071525574\n",
      "Train Iteration 1330: loss 0.29364651441574097, accuracy 0.9200000166893005\n",
      "Train Iteration 1340: loss 0.3918340802192688, accuracy 0.8600000143051147\n",
      "Train Iteration 1350: loss 0.33209624886512756, accuracy 0.8799999952316284\n",
      "Train Iteration 1360: loss 0.30267202854156494, accuracy 0.949999988079071\n",
      "Train Iteration 1370: loss 0.404330849647522, accuracy 0.8899999856948853\n",
      "Train Iteration 1380: loss 0.4036341905593872, accuracy 0.8700000047683716\n",
      "Train Iteration 1390: loss 0.3837626576423645, accuracy 0.8600000143051147\n",
      "Train Iteration 1400: loss 0.46101751923561096, accuracy 0.8600000143051147\n",
      "= Valid Iteration 1400: loss 0.33608701825141907, accuracy 0.8949999809265137 =\n",
      "Train Iteration 1410: loss 0.37627890706062317, accuracy 0.8799999952316284\n",
      "Train Iteration 1420: loss 0.26648637652397156, accuracy 0.9399999976158142\n",
      "Train Iteration 1430: loss 0.23957942426204681, accuracy 0.9399999976158142\n",
      "Train Iteration 1440: loss 0.2942366600036621, accuracy 0.9100000262260437\n",
      "Train Iteration 1450: loss 0.3696833848953247, accuracy 0.8999999761581421\n",
      "Train Iteration 1460: loss 0.3521817922592163, accuracy 0.8899999856948853\n",
      "Train Iteration 1470: loss 0.2973520755767822, accuracy 0.8899999856948853\n",
      "Train Iteration 1480: loss 0.1619081050157547, accuracy 0.9800000190734863\n",
      "Train Iteration 1490: loss 0.31425926089286804, accuracy 0.9300000071525574\n",
      "Train Iteration 1500: loss 0.37646323442459106, accuracy 0.8500000238418579\n",
      "= Valid Iteration 1500: loss 0.3091428279876709, accuracy 0.9061999917030334 =\n",
      "Train Iteration 1510: loss 0.36203163862228394, accuracy 0.8899999856948853\n",
      "Train Iteration 1520: loss 0.4060918688774109, accuracy 0.8500000238418579\n",
      "Train Iteration 1530: loss 0.19321760535240173, accuracy 0.9700000286102295\n",
      "Train Iteration 1540: loss 0.21297618746757507, accuracy 0.9300000071525574\n",
      "Train Iteration 1550: loss 0.3282814919948578, accuracy 0.8899999856948853\n",
      "Train Iteration 1560: loss 0.3437645435333252, accuracy 0.8999999761581421\n",
      "Train Iteration 1570: loss 0.30038878321647644, accuracy 0.8799999952316284\n",
      "Train Iteration 1580: loss 0.20134373009204865, accuracy 0.949999988079071\n",
      "Train Iteration 1590: loss 0.25025615096092224, accuracy 0.9399999976158142\n",
      "Train Iteration 1600: loss 0.3124145269393921, accuracy 0.8899999856948853\n",
      "= Valid Iteration 1600: loss 0.3209044337272644, accuracy 0.8942000269889832 =\n",
      "Train Iteration 1610: loss 0.3330835700035095, accuracy 0.9100000262260437\n",
      "Train Iteration 1620: loss 0.30939018726348877, accuracy 0.8899999856948853\n",
      "Train Iteration 1630: loss 0.29603245854377747, accuracy 0.8999999761581421\n",
      "Train Iteration 1640: loss 0.42430129647254944, accuracy 0.8500000238418579\n",
      "Train Iteration 1650: loss 0.3064770996570587, accuracy 0.8899999856948853\n",
      "Train Iteration 1660: loss 0.2990274429321289, accuracy 0.8999999761581421\n",
      "Train Iteration 1670: loss 0.2845838963985443, accuracy 0.9200000166893005\n",
      "Train Iteration 1680: loss 0.2671510875225067, accuracy 0.8899999856948853\n",
      "Train Iteration 1690: loss 0.28177422285079956, accuracy 0.8899999856948853\n",
      "Train Iteration 1700: loss 0.38320428133010864, accuracy 0.8399999737739563\n",
      "= Valid Iteration 1700: loss 0.28668883442878723, accuracy 0.9065999984741211 =\n",
      "Train Iteration 1710: loss 0.2716538906097412, accuracy 0.9399999976158142\n",
      "Train Iteration 1720: loss 0.2611594796180725, accuracy 0.9200000166893005\n",
      "Train Iteration 1730: loss 0.36125099658966064, accuracy 0.8899999856948853\n",
      "Train Iteration 1740: loss 0.3518679141998291, accuracy 0.8899999856948853\n",
      "Train Iteration 1750: loss 0.28384608030319214, accuracy 0.9300000071525574\n",
      "Train Iteration 1760: loss 0.34145936369895935, accuracy 0.8999999761581421\n",
      "Train Iteration 1770: loss 0.25406166911125183, accuracy 0.9200000166893005\n",
      "Train Iteration 1780: loss 0.2789858877658844, accuracy 0.8999999761581421\n",
      "Train Iteration 1790: loss 0.2809382975101471, accuracy 0.8999999761581421\n",
      "Train Iteration 1800: loss 0.34186339378356934, accuracy 0.8600000143051147\n",
      "= Valid Iteration 1800: loss 0.2834162712097168, accuracy 0.9074000120162964 =\n",
      "Train Iteration 1810: loss 0.17490139603614807, accuracy 0.9599999785423279\n",
      "Train Iteration 1820: loss 0.2404809147119522, accuracy 0.9100000262260437\n",
      "Train Iteration 1830: loss 0.31630849838256836, accuracy 0.8999999761581421\n",
      "Train Iteration 1840: loss 0.22988228499889374, accuracy 0.9200000166893005\n",
      "Train Iteration 1850: loss 0.31822875142097473, accuracy 0.8899999856948853\n",
      "Train Iteration 1860: loss 0.3564091920852661, accuracy 0.8899999856948853\n",
      "Train Iteration 1870: loss 0.30502477288246155, accuracy 0.8999999761581421\n",
      "Train Iteration 1880: loss 0.23569881916046143, accuracy 0.9100000262260437\n",
      "Train Iteration 1890: loss 0.32653170824050903, accuracy 0.8500000238418579\n",
      "Train Iteration 1900: loss 0.21212884783744812, accuracy 0.9399999976158142\n",
      "= Valid Iteration 1900: loss 0.28670138120651245, accuracy 0.9101999998092651 =\n",
      "Train Iteration 1910: loss 0.20150387287139893, accuracy 0.9599999785423279\n",
      "Train Iteration 1920: loss 0.25466275215148926, accuracy 0.8999999761581421\n",
      "Train Iteration 1930: loss 0.20438534021377563, accuracy 0.949999988079071\n",
      "Train Iteration 1940: loss 0.2803198993206024, accuracy 0.8999999761581421\n",
      "Train Iteration 1950: loss 0.3255455493927002, accuracy 0.9100000262260437\n",
      "Train Iteration 1960: loss 0.24058952927589417, accuracy 0.9399999976158142\n",
      "Train Iteration 1970: loss 0.25910812616348267, accuracy 0.9300000071525574\n",
      "Train Iteration 1980: loss 0.27505484223365784, accuracy 0.9200000166893005\n",
      "Train Iteration 1990: loss 0.27343496680259705, accuracy 0.9300000071525574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Iteration 2000: loss 0.21524329483509064, accuracy 0.9300000071525574\n",
      "= Valid Iteration 2000: loss 0.2843475341796875, accuracy 0.9142000079154968 =\n",
      "Train Iteration 2010: loss 0.36429354548454285, accuracy 0.8899999856948853\n",
      "Train Iteration 2020: loss 0.2597625255584717, accuracy 0.9100000262260437\n",
      "Train Iteration 2030: loss 0.3422115445137024, accuracy 0.8899999856948853\n",
      "Train Iteration 2040: loss 0.2937374413013458, accuracy 0.9100000262260437\n",
      "Train Iteration 2050: loss 0.2952677309513092, accuracy 0.8600000143051147\n",
      "Train Iteration 2060: loss 0.2797790765762329, accuracy 0.9100000262260437\n",
      "Train Iteration 2070: loss 0.2607831060886383, accuracy 0.9399999976158142\n",
      "Train Iteration 2080: loss 0.24437494575977325, accuracy 0.9200000166893005\n",
      "Train Iteration 2090: loss 0.33426231145858765, accuracy 0.9100000262260437\n",
      "Train Iteration 2100: loss 0.256189227104187, accuracy 0.9300000071525574\n",
      "= Valid Iteration 2100: loss 0.3036945164203644, accuracy 0.9014000296592712 =\n",
      "Train Iteration 2110: loss 0.2938419580459595, accuracy 0.9300000071525574\n",
      "Train Iteration 2120: loss 0.3131331205368042, accuracy 0.8799999952316284\n",
      "Train Iteration 2130: loss 0.29266709089279175, accuracy 0.8600000143051147\n",
      "Train Iteration 2140: loss 0.20430880784988403, accuracy 0.949999988079071\n",
      "Train Iteration 2150: loss 0.24485915899276733, accuracy 0.9399999976158142\n",
      "Train Iteration 2160: loss 0.22113044559955597, accuracy 0.8999999761581421\n",
      "Train Iteration 2170: loss 0.19191515445709229, accuracy 0.9399999976158142\n",
      "Train Iteration 2180: loss 0.18759536743164062, accuracy 0.949999988079071\n",
      "Train Iteration 2190: loss 0.2610665559768677, accuracy 0.8999999761581421\n",
      "Train Iteration 2200: loss 0.2679387629032135, accuracy 0.8899999856948853\n",
      "= Valid Iteration 2200: loss 0.2757965326309204, accuracy 0.9074000120162964 =\n",
      "Train Iteration 2210: loss 0.32905253767967224, accuracy 0.8799999952316284\n",
      "Train Iteration 2220: loss 0.3435877859592438, accuracy 0.8700000047683716\n",
      "Train Iteration 2230: loss 0.24247951805591583, accuracy 0.9399999976158142\n",
      "Train Iteration 2240: loss 0.22297145426273346, accuracy 0.949999988079071\n",
      "Train Iteration 2250: loss 0.3042899966239929, accuracy 0.9100000262260437\n",
      "Train Iteration 2260: loss 0.23660913109779358, accuracy 0.9399999976158142\n",
      "Train Iteration 2270: loss 0.30123892426490784, accuracy 0.9100000262260437\n",
      "Train Iteration 2280: loss 0.2539547383785248, accuracy 0.8999999761581421\n",
      "Train Iteration 2290: loss 0.2818898856639862, accuracy 0.8899999856948853\n",
      "Train Iteration 2300: loss 0.22388853132724762, accuracy 0.9399999976158142\n",
      "= Valid Iteration 2300: loss 0.30295562744140625, accuracy 0.8999999761581421 =\n",
      "Train Iteration 2310: loss 0.26724323630332947, accuracy 0.9100000262260437\n",
      "Train Iteration 2320: loss 0.26573634147644043, accuracy 0.9200000166893005\n",
      "Train Iteration 2330: loss 0.24506080150604248, accuracy 0.9300000071525574\n",
      "Train Iteration 2340: loss 0.32798948884010315, accuracy 0.9100000262260437\n",
      "Train Iteration 2350: loss 0.2984834909439087, accuracy 0.9100000262260437\n",
      "Train Iteration 2360: loss 0.2514611780643463, accuracy 0.8999999761581421\n",
      "Train Iteration 2370: loss 0.23731312155723572, accuracy 0.9399999976158142\n",
      "Train Iteration 2380: loss 0.24907760322093964, accuracy 0.9200000166893005\n",
      "Train Iteration 2390: loss 0.2820523977279663, accuracy 0.8999999761581421\n",
      "Train Iteration 2400: loss 0.2615583539009094, accuracy 0.9200000166893005\n",
      "= Valid Iteration 2400: loss 0.27288535237312317, accuracy 0.909600019454956 =\n",
      "Train Iteration 2410: loss 0.17679880559444427, accuracy 0.9800000190734863\n",
      "Train Iteration 2420: loss 0.24456073343753815, accuracy 0.9100000262260437\n",
      "Train Iteration 2430: loss 0.2773384749889374, accuracy 0.9100000262260437\n",
      "Train Iteration 2440: loss 0.2607855200767517, accuracy 0.9399999976158142\n",
      "Train Iteration 2450: loss 0.23606963455677032, accuracy 0.9100000262260437\n",
      "Train Iteration 2460: loss 0.24165496230125427, accuracy 0.8899999856948853\n",
      "Train Iteration 2470: loss 0.1997389942407608, accuracy 0.9599999785423279\n",
      "Train Iteration 2480: loss 0.28353187441825867, accuracy 0.9200000166893005\n",
      "Train Iteration 2490: loss 0.31497809290885925, accuracy 0.9100000262260437\n",
      "Train Iteration 2500: loss 0.272859126329422, accuracy 0.9100000262260437\n",
      "= Valid Iteration 2500: loss 0.29395410418510437, accuracy 0.9028000235557556 =\n",
      "Train Iteration 2510: loss 0.2572384774684906, accuracy 0.9100000262260437\n",
      "Train Iteration 2520: loss 0.21831560134887695, accuracy 0.9300000071525574\n",
      "Train Iteration 2530: loss 0.22540876269340515, accuracy 0.949999988079071\n",
      "Train Iteration 2540: loss 0.241657555103302, accuracy 0.8999999761581421\n",
      "Train Iteration 2550: loss 0.2721826732158661, accuracy 0.9300000071525574\n",
      "Train Iteration 2560: loss 0.1745731234550476, accuracy 0.9599999785423279\n",
      "Train Iteration 2570: loss 0.2768627107143402, accuracy 0.9200000166893005\n",
      "Train Iteration 2580: loss 0.2005733996629715, accuracy 0.9399999976158142\n",
      "Train Iteration 2590: loss 0.4205280542373657, accuracy 0.8399999737739563\n",
      "Train Iteration 2600: loss 0.3187364339828491, accuracy 0.9399999976158142\n",
      "= Valid Iteration 2600: loss 0.27892786264419556, accuracy 0.9101999998092651 =\n",
      "Train Iteration 2610: loss 0.2123700976371765, accuracy 0.9100000262260437\n",
      "Train Iteration 2620: loss 0.25363293290138245, accuracy 0.9300000071525574\n",
      "Train Iteration 2630: loss 0.25491055846214294, accuracy 0.9100000262260437\n",
      "Train Iteration 2640: loss 0.3170884847640991, accuracy 0.9100000262260437\n",
      "Train Iteration 2650: loss 0.1997210681438446, accuracy 0.9399999976158142\n",
      "Train Iteration 2660: loss 0.31569087505340576, accuracy 0.8999999761581421\n",
      "Train Iteration 2670: loss 0.3572113513946533, accuracy 0.8600000143051147\n",
      "Train Iteration 2680: loss 0.31142082810401917, accuracy 0.9100000262260437\n",
      "Train Iteration 2690: loss 0.2302292287349701, accuracy 0.9100000262260437\n",
      "Train Iteration 2700: loss 0.36707550287246704, accuracy 0.8899999856948853\n",
      "= Valid Iteration 2700: loss 0.2620530128479004, accuracy 0.9100000262260437 =\n",
      "Train Iteration 2710: loss 0.24062781035900116, accuracy 0.9300000071525574\n",
      "Train Iteration 2720: loss 0.24208959937095642, accuracy 0.9300000071525574\n",
      "Train Iteration 2730: loss 0.3232008218765259, accuracy 0.8999999761581421\n",
      "Train Iteration 2740: loss 0.16415610909461975, accuracy 0.9399999976158142\n",
      "Train Iteration 2750: loss 0.21103420853614807, accuracy 0.949999988079071\n",
      "Train Iteration 2760: loss 0.23052990436553955, accuracy 0.949999988079071\n",
      "Train Iteration 2770: loss 0.2739143371582031, accuracy 0.9300000071525574\n",
      "Train Iteration 2780: loss 0.2676238417625427, accuracy 0.8700000047683716\n",
      "Train Iteration 2790: loss 0.24285602569580078, accuracy 0.9399999976158142\n",
      "Train Iteration 2800: loss 0.252952516078949, accuracy 0.9200000166893005\n",
      "= Valid Iteration 2800: loss 0.25886401534080505, accuracy 0.9124000072479248 =\n",
      "Train Iteration 2810: loss 0.22685253620147705, accuracy 0.9300000071525574\n",
      "Train Iteration 2820: loss 0.20975038409233093, accuracy 0.9300000071525574\n",
      "Train Iteration 2830: loss 0.2218545526266098, accuracy 0.9399999976158142\n",
      "Train Iteration 2840: loss 0.16551724076271057, accuracy 0.9599999785423279\n",
      "Train Iteration 2850: loss 0.2254442572593689, accuracy 0.9599999785423279\n",
      "Train Iteration 2860: loss 0.22466282546520233, accuracy 0.9399999976158142\n",
      "Train Iteration 2870: loss 0.3166961371898651, accuracy 0.8999999761581421\n",
      "Train Iteration 2880: loss 0.18922294676303864, accuracy 0.949999988079071\n",
      "Train Iteration 2890: loss 0.2222990095615387, accuracy 0.8999999761581421\n",
      "Train Iteration 2900: loss 0.16732020676136017, accuracy 0.9700000286102295\n",
      "= Valid Iteration 2900: loss 0.25761687755584717, accuracy 0.9151999950408936 =\n",
      "Train Iteration 2910: loss 0.2518652677536011, accuracy 0.8899999856948853\n",
      "Train Iteration 2920: loss 0.24086937308311462, accuracy 0.9200000166893005\n",
      "Train Iteration 2930: loss 0.23198993504047394, accuracy 0.9300000071525574\n",
      "Train Iteration 2940: loss 0.2191123366355896, accuracy 0.9300000071525574\n",
      "Train Iteration 2950: loss 0.1912270337343216, accuracy 0.949999988079071\n",
      "Train Iteration 2960: loss 0.167079359292984, accuracy 0.9599999785423279\n",
      "Train Iteration 2970: loss 0.22724060714244843, accuracy 0.9300000071525574\n",
      "Train Iteration 2980: loss 0.22994935512542725, accuracy 0.9300000071525574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Iteration 2990: loss 0.24078170955181122, accuracy 0.9300000071525574\n",
      "Train Iteration 3000: loss 0.22154812514781952, accuracy 0.9399999976158142\n",
      "= Valid Iteration 3000: loss 0.2739214599132538, accuracy 0.9128000140190125 =\n",
      "Train Iteration 3010: loss 0.2357863187789917, accuracy 0.949999988079071\n",
      "Train Iteration 3020: loss 0.239623561501503, accuracy 0.9300000071525574\n",
      "Train Iteration 3030: loss 0.17081744968891144, accuracy 0.9800000190734863\n",
      "Train Iteration 3040: loss 0.27929070591926575, accuracy 0.8899999856948853\n",
      "Train Iteration 3050: loss 0.225957989692688, accuracy 0.9300000071525574\n",
      "Train Iteration 3060: loss 0.2420121729373932, accuracy 0.8899999856948853\n",
      "Train Iteration 3070: loss 0.2425592988729477, accuracy 0.8700000047683716\n",
      "Train Iteration 3080: loss 0.264817476272583, accuracy 0.9300000071525574\n",
      "Train Iteration 3090: loss 0.1853615939617157, accuracy 0.9700000286102295\n",
      "Train Iteration 3100: loss 0.2883029878139496, accuracy 0.9200000166893005\n",
      "= Valid Iteration 3100: loss 0.2798811197280884, accuracy 0.9064000248908997 =\n",
      "Train Iteration 3110: loss 0.2518904507160187, accuracy 0.9399999976158142\n",
      "Train Iteration 3120: loss 0.2377953678369522, accuracy 0.9200000166893005\n",
      "Train Iteration 3130: loss 0.3398471176624298, accuracy 0.8899999856948853\n",
      "Train Iteration 3140: loss 0.1877053678035736, accuracy 0.949999988079071\n",
      "Train Iteration 3150: loss 0.20522187650203705, accuracy 0.949999988079071\n",
      "Train Iteration 3160: loss 0.23490871489048004, accuracy 0.949999988079071\n",
      "Train Iteration 3170: loss 0.2427794486284256, accuracy 0.9200000166893005\n",
      "Train Iteration 3180: loss 0.3229174017906189, accuracy 0.8799999952316284\n",
      "Train Iteration 3190: loss 0.14139407873153687, accuracy 0.9800000190734863\n",
      "Train Iteration 3200: loss 0.2345660775899887, accuracy 0.9300000071525574\n",
      "= Valid Iteration 3200: loss 0.27539098262786865, accuracy 0.9038000106811523 =\n",
      "Train Iteration 3210: loss 0.28099074959754944, accuracy 0.8899999856948853\n",
      "Train Iteration 3220: loss 0.18887831270694733, accuracy 0.949999988079071\n",
      "Train Iteration 3230: loss 0.25551778078079224, accuracy 0.8999999761581421\n",
      "Train Iteration 3240: loss 0.2452695071697235, accuracy 0.9100000262260437\n",
      "Train Iteration 3250: loss 0.2288365513086319, accuracy 0.9100000262260437\n",
      "Train Iteration 3260: loss 0.30167025327682495, accuracy 0.8999999761581421\n",
      "Train Iteration 3270: loss 0.28714168071746826, accuracy 0.8999999761581421\n",
      "Train Iteration 3280: loss 0.19243013858795166, accuracy 0.949999988079071\n",
      "Train Iteration 3290: loss 0.27624619007110596, accuracy 0.8999999761581421\n",
      "Train Iteration 3300: loss 0.2324090600013733, accuracy 0.9399999976158142\n",
      "= Valid Iteration 3300: loss 0.25392937660217285, accuracy 0.9164000153541565 =\n",
      "Train Iteration 3310: loss 0.1940120905637741, accuracy 0.9399999976158142\n",
      "Train Iteration 3320: loss 0.30585217475891113, accuracy 0.8999999761581421\n",
      "Train Iteration 3330: loss 0.19599179923534393, accuracy 0.9300000071525574\n",
      "Train Iteration 3340: loss 0.27591612935066223, accuracy 0.9100000262260437\n",
      "Train Iteration 3350: loss 0.1747879832983017, accuracy 0.9599999785423279\n",
      "Train Iteration 3360: loss 0.20704811811447144, accuracy 0.9700000286102295\n",
      "Train Iteration 3370: loss 0.23508712649345398, accuracy 0.9100000262260437\n",
      "Train Iteration 3380: loss 0.26553717255592346, accuracy 0.9100000262260437\n",
      "Train Iteration 3390: loss 0.2659384608268738, accuracy 0.8899999856948853\n",
      "Train Iteration 3400: loss 0.19496826827526093, accuracy 0.9700000286102295\n",
      "= Valid Iteration 3400: loss 0.26470935344696045, accuracy 0.9115999937057495 =\n",
      "Train Iteration 3410: loss 0.24150215089321136, accuracy 0.9100000262260437\n",
      "Train Iteration 3420: loss 0.22050639986991882, accuracy 0.8999999761581421\n",
      "Train Iteration 3430: loss 0.20794233679771423, accuracy 0.949999988079071\n",
      "Train Iteration 3440: loss 0.32633575797080994, accuracy 0.8799999952316284\n",
      "Train Iteration 3450: loss 0.29762542247772217, accuracy 0.8700000047683716\n",
      "Train Iteration 3460: loss 0.231800839304924, accuracy 0.9300000071525574\n",
      "Train Iteration 3470: loss 0.1647959202528, accuracy 0.949999988079071\n",
      "Train Iteration 3480: loss 0.25163185596466064, accuracy 0.8899999856948853\n",
      "Train Iteration 3490: loss 0.2040993571281433, accuracy 0.9399999976158142\n",
      "Train Iteration 3500: loss 0.20572276413440704, accuracy 0.9399999976158142\n",
      "= Valid Iteration 3500: loss 0.264919638633728, accuracy 0.9103999733924866 =\n",
      "Train Iteration 3510: loss 0.2829296886920929, accuracy 0.8999999761581421\n",
      "Train Iteration 3520: loss 0.24482578039169312, accuracy 0.8999999761581421\n",
      "Train Iteration 3530: loss 0.20455875992774963, accuracy 0.9200000166893005\n",
      "Train Iteration 3540: loss 0.2826554477214813, accuracy 0.8600000143051147\n",
      "Train Iteration 3550: loss 0.1550094187259674, accuracy 0.9800000190734863\n",
      "Train Iteration 3560: loss 0.21460990607738495, accuracy 0.9100000262260437\n",
      "Train Iteration 3570: loss 0.2403295487165451, accuracy 0.9100000262260437\n",
      "Train Iteration 3580: loss 0.24817195534706116, accuracy 0.9100000262260437\n",
      "Train Iteration 3590: loss 0.2108282893896103, accuracy 0.9399999976158142\n",
      "Train Iteration 3600: loss 0.3117159903049469, accuracy 0.8999999761581421\n",
      "= Valid Iteration 3600: loss 0.2533549964427948, accuracy 0.9147999882698059 =\n",
      "Train Iteration 3610: loss 0.2605244517326355, accuracy 0.9200000166893005\n",
      "Train Iteration 3620: loss 0.1797189861536026, accuracy 0.9399999976158142\n",
      "Train Iteration 3630: loss 0.25192761421203613, accuracy 0.9200000166893005\n",
      "Train Iteration 3640: loss 0.24391353130340576, accuracy 0.9200000166893005\n",
      "Train Iteration 3650: loss 0.21273626387119293, accuracy 0.9300000071525574\n",
      "Train Iteration 3660: loss 0.23977969586849213, accuracy 0.9200000166893005\n",
      "Train Iteration 3670: loss 0.3359284996986389, accuracy 0.8799999952316284\n",
      "Train Iteration 3680: loss 0.2014417201280594, accuracy 0.9200000166893005\n",
      "Train Iteration 3690: loss 0.23681476712226868, accuracy 0.9399999976158142\n",
      "Train Iteration 3700: loss 0.27351266145706177, accuracy 0.9200000166893005\n",
      "= Valid Iteration 3700: loss 0.2569521963596344, accuracy 0.9154000282287598 =\n",
      "Train Iteration 3710: loss 0.3176909387111664, accuracy 0.8999999761581421\n",
      "Train Iteration 3720: loss 0.2655410170555115, accuracy 0.9100000262260437\n",
      "Train Iteration 3730: loss 0.3064149022102356, accuracy 0.8700000047683716\n",
      "Train Iteration 3740: loss 0.24537065625190735, accuracy 0.9100000262260437\n",
      "Train Iteration 3750: loss 0.15708093345165253, accuracy 0.9800000190734863\n",
      "Train Iteration 3760: loss 0.22814375162124634, accuracy 0.9200000166893005\n",
      "Train Iteration 3770: loss 0.22860774397850037, accuracy 0.9399999976158142\n",
      "Train Iteration 3780: loss 0.24628855288028717, accuracy 0.9200000166893005\n",
      "Train Iteration 3790: loss 0.17318721115589142, accuracy 0.9599999785423279\n",
      "Train Iteration 3800: loss 0.2845008075237274, accuracy 0.9200000166893005\n",
      "= Valid Iteration 3800: loss 0.2523329257965088, accuracy 0.9136000275611877 =\n",
      "Train Iteration 3810: loss 0.24586254358291626, accuracy 0.8899999856948853\n",
      "Train Iteration 3820: loss 0.17619489133358002, accuracy 0.9399999976158142\n",
      "Train Iteration 3830: loss 0.2471064180135727, accuracy 0.9399999976158142\n",
      "Train Iteration 3840: loss 0.2242804765701294, accuracy 0.9599999785423279\n",
      "Train Iteration 3850: loss 0.20417402684688568, accuracy 0.9100000262260437\n",
      "Train Iteration 3860: loss 0.19906477630138397, accuracy 0.9599999785423279\n",
      "Train Iteration 3870: loss 0.21340437233448029, accuracy 0.9100000262260437\n",
      "Train Iteration 3880: loss 0.10725824534893036, accuracy 0.9800000190734863\n",
      "Train Iteration 3890: loss 0.17054958641529083, accuracy 0.9599999785423279\n",
      "Train Iteration 3900: loss 0.2652554214000702, accuracy 0.9200000166893005\n",
      "= Valid Iteration 3900: loss 0.24742034077644348, accuracy 0.9143999814987183 =\n",
      "Train Iteration 3910: loss 0.14578893780708313, accuracy 0.9599999785423279\n",
      "Train Iteration 3920: loss 0.18391188979148865, accuracy 0.949999988079071\n",
      "Train Iteration 3930: loss 0.18203376233577728, accuracy 0.949999988079071\n",
      "Train Iteration 3940: loss 0.2235327512025833, accuracy 0.9300000071525574\n",
      "Train Iteration 3950: loss 0.28241825103759766, accuracy 0.9300000071525574\n",
      "Train Iteration 3960: loss 0.21960598230361938, accuracy 0.9399999976158142\n",
      "Train Iteration 3970: loss 0.24012871086597443, accuracy 0.9399999976158142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Iteration 3980: loss 0.15645207464694977, accuracy 0.949999988079071\n",
      "Train Iteration 3990: loss 0.23886485397815704, accuracy 0.9200000166893005\n",
      "Train Iteration 4000: loss 0.18868397176265717, accuracy 0.949999988079071\n",
      "= Valid Iteration 4000: loss 0.2535839378833771, accuracy 0.9136000275611877 =\n",
      "Train Iteration 4010: loss 0.22331103682518005, accuracy 0.9300000071525574\n",
      "Train Iteration 4020: loss 0.18922770023345947, accuracy 0.9700000286102295\n",
      "Train Iteration 4030: loss 0.2463078647851944, accuracy 0.8899999856948853\n",
      "Train Iteration 4040: loss 0.21022620797157288, accuracy 0.949999988079071\n",
      "Train Iteration 4050: loss 0.2248917520046234, accuracy 0.9300000071525574\n",
      "Train Iteration 4060: loss 0.30038002133369446, accuracy 0.8799999952316284\n",
      "Train Iteration 4070: loss 0.1601504683494568, accuracy 0.9300000071525574\n",
      "Train Iteration 4080: loss 0.12206967175006866, accuracy 0.9900000095367432\n",
      "Train Iteration 4090: loss 0.1648571789264679, accuracy 0.949999988079071\n",
      "Train Iteration 4100: loss 0.1670577973127365, accuracy 0.949999988079071\n",
      "= Valid Iteration 4100: loss 0.24618320167064667, accuracy 0.9147999882698059 =\n",
      "Train Iteration 4110: loss 0.17872408032417297, accuracy 0.9599999785423279\n",
      "Train Iteration 4120: loss 0.14428339898586273, accuracy 0.9700000286102295\n",
      "Train Iteration 4130: loss 0.21643808484077454, accuracy 0.949999988079071\n",
      "Train Iteration 4140: loss 0.16186802089214325, accuracy 0.9599999785423279\n",
      "Train Iteration 4150: loss 0.22950397431850433, accuracy 0.9200000166893005\n",
      "Train Iteration 4160: loss 0.16829293966293335, accuracy 0.949999988079071\n",
      "Train Iteration 4170: loss 0.12990128993988037, accuracy 0.9700000286102295\n",
      "Train Iteration 4180: loss 0.34640875458717346, accuracy 0.9200000166893005\n",
      "Train Iteration 4190: loss 0.1927623152732849, accuracy 0.949999988079071\n",
      "Train Iteration 4200: loss 0.1738562136888504, accuracy 0.9700000286102295\n",
      "= Valid Iteration 4200: loss 0.26655668020248413, accuracy 0.907800018787384 =\n",
      "Train Iteration 4210: loss 0.23072460293769836, accuracy 0.9399999976158142\n",
      "Train Iteration 4220: loss 0.22674833238124847, accuracy 0.9300000071525574\n",
      "Train Iteration 4230: loss 0.18075303733348846, accuracy 0.9800000190734863\n",
      "Train Iteration 4240: loss 0.2127688229084015, accuracy 0.9399999976158142\n",
      "Train Iteration 4250: loss 0.23505526781082153, accuracy 0.9399999976158142\n",
      "Train Iteration 4260: loss 0.27849236130714417, accuracy 0.8999999761581421\n",
      "Train Iteration 4270: loss 0.2473558634519577, accuracy 0.9100000262260437\n",
      "Train Iteration 4280: loss 0.2666974663734436, accuracy 0.9100000262260437\n",
      "Train Iteration 4290: loss 0.26480281352996826, accuracy 0.9300000071525574\n",
      "Train Iteration 4300: loss 0.23836387693881989, accuracy 0.9300000071525574\n",
      "= Valid Iteration 4300: loss 0.24661511182785034, accuracy 0.9161999821662903 =\n",
      "Train Iteration 4310: loss 0.2187711000442505, accuracy 0.9399999976158142\n",
      "Train Iteration 4320: loss 0.20224294066429138, accuracy 0.9399999976158142\n",
      "Train Iteration 4330: loss 0.19059664011001587, accuracy 0.9300000071525574\n",
      "Train Iteration 4340: loss 0.2226758748292923, accuracy 0.9200000166893005\n",
      "Train Iteration 4350: loss 0.2416234016418457, accuracy 0.9300000071525574\n",
      "Train Iteration 4360: loss 0.16223423182964325, accuracy 0.9599999785423279\n",
      "Train Iteration 4370: loss 0.17200633883476257, accuracy 0.9300000071525574\n",
      "Train Iteration 4380: loss 0.1872968226671219, accuracy 0.9399999976158142\n",
      "Train Iteration 4390: loss 0.20417404174804688, accuracy 0.9100000262260437\n",
      "Train Iteration 4400: loss 0.3003407418727875, accuracy 0.8700000047683716\n",
      "= Valid Iteration 4400: loss 0.2632400393486023, accuracy 0.9120000004768372 =\n",
      "Train Iteration 4410: loss 0.23115505278110504, accuracy 0.9300000071525574\n",
      "Train Iteration 4420: loss 0.2698446214199066, accuracy 0.8899999856948853\n",
      "Train Iteration 4430: loss 0.2216995656490326, accuracy 0.949999988079071\n",
      "Train Iteration 4440: loss 0.18071594834327698, accuracy 0.9399999976158142\n",
      "Train Iteration 4450: loss 0.2251935601234436, accuracy 0.949999988079071\n",
      "Train Iteration 4460: loss 0.2515251636505127, accuracy 0.9300000071525574\n",
      "Train Iteration 4470: loss 0.21009674668312073, accuracy 0.9399999976158142\n",
      "Train Iteration 4480: loss 0.19891342520713806, accuracy 0.9399999976158142\n",
      "Train Iteration 4490: loss 0.15442177653312683, accuracy 0.9700000286102295\n",
      "Train Iteration 4500: loss 0.27237439155578613, accuracy 0.9399999976158142\n",
      "= Valid Iteration 4500: loss 0.2394963800907135, accuracy 0.9197999835014343 =\n",
      "Train Iteration 4510: loss 0.29051339626312256, accuracy 0.9200000166893005\n",
      "Train Iteration 4520: loss 0.1465131938457489, accuracy 0.9599999785423279\n",
      "Train Iteration 4530: loss 0.19112539291381836, accuracy 0.9399999976158142\n",
      "Train Iteration 4540: loss 0.19648486375808716, accuracy 0.8999999761581421\n",
      "Train Iteration 4550: loss 0.21481433510780334, accuracy 0.9399999976158142\n",
      "Train Iteration 4560: loss 0.2324998825788498, accuracy 0.9100000262260437\n",
      "Train Iteration 4570: loss 0.23368415236473083, accuracy 0.9399999976158142\n",
      "Train Iteration 4580: loss 0.21114540100097656, accuracy 0.9399999976158142\n",
      "Train Iteration 4590: loss 0.24745920300483704, accuracy 0.9300000071525574\n",
      "Train Iteration 4600: loss 0.31855642795562744, accuracy 0.8999999761581421\n",
      "= Valid Iteration 4600: loss 0.24431680142879486, accuracy 0.9146000146865845 =\n",
      "Train Iteration 4610: loss 0.1955009400844574, accuracy 0.9300000071525574\n",
      "Train Iteration 4620: loss 0.16855621337890625, accuracy 0.9599999785423279\n",
      "Train Iteration 4630: loss 0.13201722502708435, accuracy 0.9599999785423279\n",
      "Train Iteration 4640: loss 0.31490421295166016, accuracy 0.9100000262260437\n",
      "Train Iteration 4650: loss 0.17981654405593872, accuracy 0.949999988079071\n",
      "Train Iteration 4660: loss 0.2232302725315094, accuracy 0.9100000262260437\n",
      "Train Iteration 4670: loss 0.25092777609825134, accuracy 0.8999999761581421\n",
      "Train Iteration 4680: loss 0.2182047963142395, accuracy 0.9100000262260437\n",
      "Train Iteration 4690: loss 0.3365124464035034, accuracy 0.8999999761581421\n",
      "Train Iteration 4700: loss 0.16751839220523834, accuracy 0.9700000286102295\n",
      "= Valid Iteration 4700: loss 0.25394442677497864, accuracy 0.9110000133514404 =\n",
      "Train Iteration 4710: loss 0.23163005709648132, accuracy 0.9399999976158142\n",
      "Train Iteration 4720: loss 0.1963030844926834, accuracy 0.9399999976158142\n",
      "Train Iteration 4730: loss 0.25156304240226746, accuracy 0.9100000262260437\n",
      "Train Iteration 4740: loss 0.20243698358535767, accuracy 0.9200000166893005\n",
      "Train Iteration 4750: loss 0.16083042323589325, accuracy 0.949999988079071\n",
      "Train Iteration 4760: loss 0.187534898519516, accuracy 0.949999988079071\n",
      "Train Iteration 4770: loss 0.18696334958076477, accuracy 0.949999988079071\n",
      "Train Iteration 4780: loss 0.23994852602481842, accuracy 0.9300000071525574\n",
      "Train Iteration 4790: loss 0.27071964740753174, accuracy 0.8999999761581421\n",
      "Train Iteration 4800: loss 0.2157549262046814, accuracy 0.9399999976158142\n",
      "= Valid Iteration 4800: loss 0.24567143619060516, accuracy 0.9192000031471252 =\n",
      "Train Iteration 4810: loss 0.19461874663829803, accuracy 0.9599999785423279\n",
      "Train Iteration 4820: loss 0.2440757304430008, accuracy 0.9100000262260437\n",
      "Train Iteration 4830: loss 0.2634067237377167, accuracy 0.8899999856948853\n",
      "Train Iteration 4840: loss 0.21627360582351685, accuracy 0.9200000166893005\n",
      "Train Iteration 4850: loss 0.16624340415000916, accuracy 0.9800000190734863\n",
      "Train Iteration 4860: loss 0.16858318448066711, accuracy 0.9300000071525574\n",
      "Train Iteration 4870: loss 0.1520167738199234, accuracy 0.9700000286102295\n",
      "Train Iteration 4880: loss 0.20116783678531647, accuracy 0.9300000071525574\n",
      "Train Iteration 4890: loss 0.17526081204414368, accuracy 0.9399999976158142\n",
      "Train Iteration 4900: loss 0.2218100130558014, accuracy 0.9300000071525574\n",
      "= Valid Iteration 4900: loss 0.23663872480392456, accuracy 0.9190000295639038 =\n",
      "Train Iteration 4910: loss 0.20454365015029907, accuracy 0.9399999976158142\n",
      "Train Iteration 4920: loss 0.25117257237434387, accuracy 0.9100000262260437\n",
      "Train Iteration 4930: loss 0.24166055023670197, accuracy 0.9399999976158142\n",
      "Train Iteration 4940: loss 0.20884954929351807, accuracy 0.9300000071525574\n",
      "Train Iteration 4950: loss 0.24175262451171875, accuracy 0.9100000262260437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Iteration 4960: loss 0.2391170859336853, accuracy 0.9300000071525574\n",
      "Train Iteration 4970: loss 0.18440674245357513, accuracy 0.9300000071525574\n",
      "Train Iteration 4980: loss 0.1452552080154419, accuracy 0.9399999976158142\n",
      "Train Iteration 4990: loss 0.19584491848945618, accuracy 0.949999988079071\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "model_path = logging_meta['model_path']\n",
    "\n",
    "validation_feed_dict = {\n",
    "    images: data.validation.images, \n",
    "    labels: data.validation.labels,\n",
    "    keep_dropout_prob: 1., \n",
    "    is_training: False}\n",
    "\n",
    "session = tf.Session(graph=graph, config=config)\n",
    "session.run(initialize_vars)\n",
    "# logging_meta['saver'].restore(session, '/tensorboard_summaries/conv_image_net/experiment_1/valid/model.ckpt-4900')\n",
    "\n",
    "for iteration in range(5000):\n",
    "    ##################\n",
    "    # Training phase #\n",
    "    ##################\n",
    "    _images, _labels = data.train.next_batch(100)\n",
    "    feed_dict = {images: _images, labels: _labels, keep_dropout_prob: 0.5, is_training: True}\n",
    "    _ = session.run([train_step], feed_dict=feed_dict)\n",
    "\n",
    "    if iteration % 10 == 0:\n",
    "        feed_dict={images: _images, labels: _labels, keep_dropout_prob: 1., is_training: False}\n",
    "        _summary, _accuracy, _loss = session.run([merge_summaries, accuracy, loss],feed_dict=feed_dict)\n",
    "\n",
    "        logging_meta['train_writer'].add_summary(_summary, iteration)\n",
    "        print(\"Train Iteration {}: loss {}, accuracy {}\".format(iteration, _loss, _accuracy))\n",
    "\n",
    "    ####################\n",
    "    # Validation phase #\n",
    "    ####################\n",
    "    if iteration % 100 == 0:\n",
    "        fetches = [embedding_assignment, merge_summaries, accuracy, loss]\n",
    "        _, _summary, _accuracy, _loss = session.run(fetches, validation_feed_dict)\n",
    "\n",
    "        logging_meta['valid_writer'].add_summary(_summary, iteration)\n",
    "        logging_meta['saver'].save(session, model_path, iteration)\n",
    "        print(\"= Valid Iteration {}: loss {}, accuracy {} =\".format(iteration, _loss, _accuracy))\n",
    "\n",
    "_prediction, = session.run([prediction], feed_dict=validation_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.results_evaluation import get_info_df\n",
    "from utils.results_evaluation import get_accuracy\n",
    "from utils.results_evaluation import get_false_positives\n",
    "from utils.results_evaluation import get_info_df\n",
    "from utils.results_evaluation import get_rec_prec\n",
    "from utils.results_evaluation import plot_coocurance_matrix\n",
    "from utils.results_evaluation import plot_examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_info_df(data.validation.labels, _prediction, class_id2class_name_mapping, data.validation.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_prec(df, class_id2class_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = get_false_positives(df, 'Shirt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurance_matrix(df, use_top3=False, use_log=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
